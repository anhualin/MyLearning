{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%qtconsole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "source_urls = []\n",
    "source_urls.append('http://revistagalileu.globo.com/Ciencia/noticia/2017/08/foto-iconica-de-albert-einstein-e-leiloada-por-125-mil-dolares.html')\n",
    "source_urls.append('http://revistagalileu.globo.com/Sociedade/noticia/2017/08/dermatologista-celebridade-explica-sucesso-de-videos-de-cravos-nojentos.html')\n",
    "source_urls.append('http://revistagalileu.globo.com/Game-of-Thrones/noticia/2017/08/11-reacoes-ao-vazamento-do-novo-episodio-de-game-thrones.html')\n",
    "source_urls.append('http://revistagalileu.globo.com/Cultura/noticia/2017/08/artista-cria-algoritmo-que-faz-desenhos-partir-de-uma-unica-linha.html')\n",
    "source_urls.append('http://revistagalileu.globo.com/Cultura/noticia/2017/07/5-livros-da-agatha-christie-nao-tao-famosos-que-merecem-ser-lidos.html')\n",
    "source_urls.append('http://revistagalileu.globo.com/Cultura/noticia/2017/07/rock-and-roll-13-livros-para-quem-adora-o-estilo-musical.html')\n",
    "source_urls.append('http://revistagalileu.globo.com/Cultura/noticia/2017/08/serie-13-reasons-why-aumentou-o-interesse-por-suicidio-diz-pesquisa.html')\n",
    "source_urls.append('http://revistagalileu.globo.com/Sociedade/noticia/2016/10/por-que-o-rio-grande-do-sul-e-regiao-com-mais-suicidios-do-pais.html')\n",
    "source_urls.append('http://revistagalileu.globo.com/Sociedade/noticia/2017/05/3-razoes-para-ver-e-outras-3-para-nao-ver-13-reasons-why.html')\n",
    "source_urls.append('http://revistagalileu.globo.com/Sociedade/Comportamento/noticia/2017/07/aprenda-7-dicas-cientificamente-comprovadas-para-dormir-melhor.html')\n",
    "source_urls.append('http://revistagalileu.globo.com/Cultura/noticia/2017/08/tudo-o-que-voce-precisa-saber-sobre-mitologia-nordica.html')\n",
    "source_urls.append('http://revistagalileu.globo.com/Ciencia/noticia/2017/08/pesquisadores-estudam-morcego-de-duas-cabecas-encontrado-no-brasil.html')\n",
    "source_urls.append('http://revistagalileu.globo.com/Publicidade/HBO/noticia/2017/08/contagem-regressiva.html')\n",
    "source_urls.append('http://revistagalileu.globo.com/Publicidade/Mobile/noticia/2017/08/um-novo-modo-de-aprender-e-de-conhecer-cidade.html')\n",
    "source_urls.append('http://revistagalileu.globo.com/Game-of-Thrones/noticia/2017/08/ultimo-episodio-de-got-pode-ter-confirmado-teoria-sobre-mindinho.html')\n",
    "source_urls.append('http://revistagalileu.globo.com/Sociedade/noticia/2017/08/8-comentarios-que-provam-que-nossa-capa-sobre-hiv-e-necessaria.html')\n",
    "source_urls.append('http://revistagalileu.globo.com/Cultura/noticia/2017/08/mulher-maravilha-icone-feminista-ou-simbolo-de-opressao.html')\n",
    "source_urls.append('http://revistagalileu.globo.com/Sociedade/noticia/2017/01/meninas-acreditam-que-inteligencia-e-uma-caracteristica-masculina.html')\n",
    "source_urls.append('http://revistagalileu.globo.com/Cultura/noticia/2017/07/cartas-de-agatha-christie-revelam-verdadeiro-temperamento-da-autora.html')\n",
    "source_urls.append('http://revistagalileu.globo.com/Cultura/noticia/2017/07/veja-como-sao-capas-de-harry-potter-ao-redor-do-mundo.html')\n",
    "source_urls.append('http://revistagalileu.globo.com/Cultura/noticia/2016/06/veja-o-antes-e-depois-do-elenco-de-game-thrones.html')\n",
    "source_urls.append('http://revistagalileu.globo.com/Ciencia/Arqueologia/noticia/2017/06/cidade-islamica-e-encontrada-embaixo-de-municipio-na-etiopia.html')\n",
    "source_urls.append('http://revistagalileu.globo.com/Sociedade/noticia/2017/06/reliquias-nazistas-sao-encontradas-em-sala-secreta-na-argentina.html')\n",
    "source_urls.append('http://revistagalileu.globo.com/Ciencia/noticia/2017/06/novas-evidencias-podem-provar-existencia-da-torre-de-babel.html')\n",
    "source_urls.append('http://revistagalileu.globo.com/Ciencia/Saude/noticia/2017/07/crianca-com-hiv-consegue-controlar-virus-sem-remedio.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Raw Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_raw_text(url):\n",
    "    r = urllib.urlopen(url).read()\n",
    "    soup = BeautifulSoup(r, 'html.parser')\n",
    "    for div in soup.find_all('div'):\n",
    "        try:\n",
    "            if div['class'][0] == u'ctx_content':\n",
    "                text = div.get_text()\n",
    "                text1 = re.sub(r'\\([^\\(]+\\)', ' ', text)\n",
    "                text2 = re.sub(r'Leia mais(.+)', '', text1)\n",
    "                return text2\n",
    "        except Exception:\n",
    "            pass\n",
    "    return u''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_texts = [get_raw_text(url) for url in source_urls]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_tokens = [nltk.word_tokenize(text) for text in raw_texts]\n",
    "\n",
    "texts = [nltk.Text(rt) for rt in raw_tokens]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Character count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Character_cnts = [len(text) for text in raw_texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Raw word count including stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Word_cnts_raw = [len(text) for text in texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Word count excluding stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('portuguese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filtered_tokens = [[w.lower() for w in tokens if w not in stopwords and not w.isnumeric() and len(w) > 1] for tokens in raw_tokens]\n",
    "Word_cnts_filtered = [len(tokens) for tokens in filtered_tokens]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Number of sentences and number of sentences with >70 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_sents = [nltk.sent_tokenize(text) for text in raw_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Sent_cnts = [len(sents) for sents in raw_sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Long_sent_cnts = [sum([len(s) > 170 for s in sents]) for sents in raw_sents]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Average sentence length (by token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "avg_sent_len = [ float(Word_cnts_raw[i]) / float(Sent_cnts[i]) for i in range(len(Word_cnts_raw))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POS Tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import floresta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Tagger0 = nltk.DefaultTagger('n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def simplify_tag(t):\n",
    "...     if \"+\" in t:\n",
    "...         return t[t.index(\"+\")+1:]\n",
    "...     else:\n",
    "...         return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tsents = [[(w.lower(),simplify_tag(t)) for (w,t) in sent] for sent in floresta.tagged_sents() if sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Tagger1 = nltk.UnigramTagger(tsents, backoff=Tagger0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Tagger2 = nltk.BigramTagger(tsents, backoff=Tagger1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add unigram pos and bigram pos features\n",
    "1. Use the first k text as training data to create all unigram pos and bigram pos used\n",
    "2. For test data, only consider the unigram pos and bigram pos used in the training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = 22"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_sents = raw_sents[:k]\n",
    "test_sents = raw_sents[k:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_unigram = set()\n",
    "all_bigram = set()\n",
    "train_unigrams = []\n",
    "train_bigrams = []\n",
    "for sents in train_sents:\n",
    "    tui = {}\n",
    "    tbi = {}\n",
    "    for sent in sents:\n",
    "        tsent = Tagger2.tag(nltk.word_tokenize(sent))\n",
    "        for i in range(len(tsent) - 1):\n",
    "            t0 = tsent[i][1]\n",
    "            t1 = tsent[i+1][1]\n",
    "            all_unigram.add(t0)\n",
    "            all_bigram.add((t0, t1))\n",
    "            tui[t0] = tui[t0] + 1 if t0 in tui else 1\n",
    "            tbi[(t0, t1)] = tbi[(t0, t1)] + 1 if (t0, t1) in tbi else 1\n",
    "        t0 = tsent[len(tsent) - 1][1]\n",
    "        all_unigram.add(t0)\n",
    "        tui[t0] = tui[t0] + 1 if t0 in tui else 1\n",
    "    train_unigrams.append(tui)\n",
    "    train_bigrams.append(tbi)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only keep those grams appear in at least L documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "L = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "use_cnt = [(x, sum(x in tu for tu in train_unigrams)) for x in all_unigram]\n",
    "use_unigram = set([x for (x,y) in use_cnt if y >L])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "use_cnt = [(x, sum(x in tb for tb in train_bigrams)) for x in all_bigram]\n",
    "use_bigram = set([x for (x,y) in use_cnt if y >L])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_unigrams = []\n",
    "test_bigrams = []\n",
    "for sents in test_sents:\n",
    "    tui = {}\n",
    "    tbi = {}\n",
    "    for sent in sents:\n",
    "        tsent = Tagger2.tag(nltk.word_tokenize(sent))\n",
    "        for i in range(len(tsent) - 1):\n",
    "            t0 = tsent[i][1]\n",
    "            t1 = tsent[i+1][1]\n",
    "            if t0 in use_unigram:\n",
    "                tui[t0] = tui[t0] + 1 if t0 in tui else 1\n",
    "            if (t0, t1) in use_bigram:\n",
    "                tbi[(t0, t1)] = tbi[(t0, t1)] + 1 if (t0, t1) in tbi else 1\n",
    "        t0 = tsent[len(tsent) - 1][1]\n",
    "        if t0 in use_unigram:\n",
    "            tui[t0] = tui[t0] + 1 if t0 in tui else 1\n",
    "    test_unigrams.append(tui)\n",
    "    test_bigrams.append(tbi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to numpy matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_unigram0 = [{u: tu[u] if u in tu else 0 for u in use_unigram} for tu in train_unigrams]\n",
    "\n",
    "train_uni_mat = pd.DataFrame(train_unigram0).values\n",
    "\n",
    "test_unigram0 = [{u: tu[u] if u in tu else 0 for u in use_unigram} for tu in test_unigrams]\n",
    "\n",
    "test_uni_mat = pd.DataFrame(test_unigram0).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_bigram0 = [{u: tu[u] if u in tu else 0 for u in use_bigram} for tu in train_bigrams]\n",
    "\n",
    "train_bi_mat = pd.DataFrame(train_bigram0).values\n",
    "\n",
    "test_bigram0 = [{u: tu[u] if u in tu else 0 for u in use_bigram} for tu in test_bigrams]\n",
    "\n",
    "test_bi_mat = pd.DataFrame(test_bigram0).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = len(source_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Character_cnt_mat = np.array(Character_cnts).reshape(N,1)\n",
    "Word_cnts_raw_mat = np.array(Word_cnts_raw).reshape(N,1)\n",
    "Word_cnts_filtered_mat = np.array(Word_cnts_filtered).reshape(N,1)\n",
    "Sent_cnts_mat = np.array(Sent_cnts).reshape(N,1)\n",
    "Long_sent_cnts_mat = np.array(Long_sent_cnts).reshape(N,1)\n",
    "avg_sent_len_mat = np.array(avg_sent_len).reshape(N,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Feature_mat1 = np.concatenate((Character_cnt_mat, Word_cnts_raw_mat, Word_cnts_filtered_mat,\n",
    "                              Sent_cnts_mat, Long_sent_cnts_mat, avg_sent_len_mat), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_mat1 = Feature_mat1[:k,]\n",
    "test_mat1 = Feature_mat1[k:,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_X_raw = np.concatenate((train_mat1, train_uni_mat, train_bi_mat), axis = 1)\n",
    "test_X_raw = np.concatenate((test_mat1, test_uni_mat, test_bi_mat), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_filtered_tokens = filtered_tokens[:k]\n",
    "test_filtered_tokens = filtered_tokens[k:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_tf = [dict(nltk.FreqDist(tokens)) for tokens in train_filtered_tokens]\n",
    "test_tf = [dict(nltk.FreqDist(tokens)) for tokens in test_filtered_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "#product = reduce((lambda x, y: x * y), [1, 2, 3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "use_tokens = reduce(lambda x, y: set(x).union(set(y)), train_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_tf0 = [{u: tf[u] if u in tf else 0 for u in use_tokens} for tf in train_tf]\n",
    "\n",
    "train_tf_mat = pd.DataFrame(train_tf0).values\n",
    "\n",
    "test_tf0 = [{u: tf[u] if u in tf else 0 for u in use_tokens} for tf in test_tf]\n",
    "\n",
    "test_tf_mat = pd.DataFrame(test_tf0).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = [sum([u in tf for tf in train_tf]) for u in use_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idf = np.array([1.0/d for d in df]).reshape(1, len(use_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_tf_idf = train_tf_mat * np.repeat(idf, train_tf_mat.shape[0], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_tf_idf = test_tf_mat * np.repeat(idf, test_tf_mat.shape[0], axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create random labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = np.random.randn(train_X_raw.shape[0])\n",
    "y_test = np.random.randn(test_X_raw.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try with the extracted feature first"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(train_X_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_X = scaler.transform(train_X_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_X = scaler.transform(test_X_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### random forest from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = RandomForestRegressor(n_estimators=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = clf.fit(train_X, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_predict_rf1 = clf.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "err_rf1 = mean_squared_error(y_test, y_predict_rf1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### try h2o gbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import h2o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321. connected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime:</td>\n",
       "<td>53 mins 18 secs</td></tr>\n",
       "<tr><td>H2O cluster version:</td>\n",
       "<td>3.10.5.4</td></tr>\n",
       "<tr><td>H2O cluster version age:</td>\n",
       "<td>22 days </td></tr>\n",
       "<tr><td>H2O cluster name:</td>\n",
       "<td>alin</td></tr>\n",
       "<tr><td>H2O cluster total nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster free memory:</td>\n",
       "<td>3.538 Gb</td></tr>\n",
       "<tr><td>H2O cluster total cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O cluster allowed cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O cluster status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O connection url:</td>\n",
       "<td>http://localhost:54321</td></tr>\n",
       "<tr><td>H2O connection proxy:</td>\n",
       "<td>None</td></tr>\n",
       "<tr><td>H2O internal security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>Python version:</td>\n",
       "<td>2.7.11 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ----------------------\n",
       "H2O cluster uptime:         53 mins 18 secs\n",
       "H2O cluster version:        3.10.5.4\n",
       "H2O cluster version age:    22 days\n",
       "H2O cluster name:           alin\n",
       "H2O cluster total nodes:    1\n",
       "H2O cluster free memory:    3.538 Gb\n",
       "H2O cluster total cores:    4\n",
       "H2O cluster allowed cores:  4\n",
       "H2O cluster status:         locked, healthy\n",
       "H2O connection url:         http://localhost:54321\n",
       "H2O connection proxy:\n",
       "H2O internal security:      False\n",
       "Python version:             2.7.11 final\n",
       "--------------------------  ----------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h2o.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_y = y_train.reshape(k,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = np.concatenate((train_X, train_y), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "train_hex = h2o.H2OFrame(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from h2o.estimators.gbm import H2OGradientBoostingEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gbm = H2OGradientBoostingEstimator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm Model Build progress: |███████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "gbm.train(x = range(90), y = 91, training_frame=train_hex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "test_y = y_test.reshape(N-k,1)\n",
    "test = np.concatenate((test_X, test_y), axis = 1)\n",
    "test_hex = h2o.H2OFrame(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm prediction progress: |████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "y_predict_gbm = gbm.predict(test_hex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th style=\"text-align: right;\">  predict</th></tr>\n",
       "<tr><td style=\"text-align: right;\">-0.227226</td></tr>\n",
       "<tr><td style=\"text-align: right;\">-0.411691</td></tr>\n",
       "<tr><td style=\"text-align: right;\"> 0.895856</td></tr>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict_gbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
