{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%qtconsole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "source_urls = []\n",
    "source_urls.append('http://revistagalileu.globo.com/Ciencia/noticia/2017/08/foto-iconica-de-albert-einstein-e-leiloada-por-125-mil-dolares.html')\n",
    "source_urls.append('http://revistagalileu.globo.com/Sociedade/noticia/2017/08/dermatologista-celebridade-explica-sucesso-de-videos-de-cravos-nojentos.html')\n",
    "source_urls.append('http://revistagalileu.globo.com/Game-of-Thrones/noticia/2017/08/11-reacoes-ao-vazamento-do-novo-episodio-de-game-thrones.html')\n",
    "source_urls.append('http://revistagalileu.globo.com/Cultura/noticia/2017/08/artista-cria-algoritmo-que-faz-desenhos-partir-de-uma-unica-linha.html')\n",
    "source_urls.append('http://revistagalileu.globo.com/Cultura/noticia/2017/07/5-livros-da-agatha-christie-nao-tao-famosos-que-merecem-ser-lidos.html')\n",
    "source_urls.append('http://revistagalileu.globo.com/Cultura/noticia/2017/07/rock-and-roll-13-livros-para-quem-adora-o-estilo-musical.html')\n",
    "source_urls.append('http://revistagalileu.globo.com/Cultura/noticia/2017/08/serie-13-reasons-why-aumentou-o-interesse-por-suicidio-diz-pesquisa.html')\n",
    "source_urls.append('http://revistagalileu.globo.com/Sociedade/noticia/2016/10/por-que-o-rio-grande-do-sul-e-regiao-com-mais-suicidios-do-pais.html')\n",
    "source_urls.append('http://revistagalileu.globo.com/Sociedade/noticia/2017/05/3-razoes-para-ver-e-outras-3-para-nao-ver-13-reasons-why.html')\n",
    "source_urls.append('http://revistagalileu.globo.com/Sociedade/Comportamento/noticia/2017/07/aprenda-7-dicas-cientificamente-comprovadas-para-dormir-melhor.html')\n",
    "source_urls.append('http://revistagalileu.globo.com/Cultura/noticia/2017/08/tudo-o-que-voce-precisa-saber-sobre-mitologia-nordica.html')\n",
    "source_urls.append('http://revistagalileu.globo.com/Ciencia/noticia/2017/08/pesquisadores-estudam-morcego-de-duas-cabecas-encontrado-no-brasil.html')\n",
    "source_urls.append('http://revistagalileu.globo.com/Publicidade/HBO/noticia/2017/08/contagem-regressiva.html')\n",
    "source_urls.append('http://revistagalileu.globo.com/Publicidade/Mobile/noticia/2017/08/um-novo-modo-de-aprender-e-de-conhecer-cidade.html')\n",
    "source_urls.append('http://revistagalileu.globo.com/Game-of-Thrones/noticia/2017/08/ultimo-episodio-de-got-pode-ter-confirmado-teoria-sobre-mindinho.html')\n",
    "source_urls.append('http://revistagalileu.globo.com/Sociedade/noticia/2017/08/8-comentarios-que-provam-que-nossa-capa-sobre-hiv-e-necessaria.html')\n",
    "source_urls.append('http://revistagalileu.globo.com/Cultura/noticia/2017/08/mulher-maravilha-icone-feminista-ou-simbolo-de-opressao.html')\n",
    "source_urls.append('http://revistagalileu.globo.com/Sociedade/noticia/2017/01/meninas-acreditam-que-inteligencia-e-uma-caracteristica-masculina.html')\n",
    "source_urls.append('http://revistagalileu.globo.com/Cultura/noticia/2017/07/cartas-de-agatha-christie-revelam-verdadeiro-temperamento-da-autora.html')\n",
    "source_urls.append('http://revistagalileu.globo.com/Cultura/noticia/2017/07/veja-como-sao-capas-de-harry-potter-ao-redor-do-mundo.html')\n",
    "source_urls.append('http://revistagalileu.globo.com/Cultura/noticia/2016/06/veja-o-antes-e-depois-do-elenco-de-game-thrones.html')\n",
    "source_urls.append('http://revistagalileu.globo.com/Ciencia/Arqueologia/noticia/2017/06/cidade-islamica-e-encontrada-embaixo-de-municipio-na-etiopia.html')\n",
    "source_urls.append('http://revistagalileu.globo.com/Sociedade/noticia/2017/06/reliquias-nazistas-sao-encontradas-em-sala-secreta-na-argentina.html')\n",
    "source_urls.append('http://revistagalileu.globo.com/Ciencia/noticia/2017/06/novas-evidencias-podem-provar-existencia-da-torre-de-babel.html')\n",
    "source_urls.append('http://revistagalileu.globo.com/Ciencia/Saude/noticia/2017/07/crianca-com-hiv-consegue-controlar-virus-sem-remedio.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Raw Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_raw_text(url):\n",
    "    r = urllib.urlopen(url).read()\n",
    "    soup = BeautifulSoup(r, 'html.parser')\n",
    "    for div in soup.find_all('div'):\n",
    "        try:\n",
    "            if div['class'][0] == u'ctx_content':\n",
    "                text = div.get_text()\n",
    "                text1 = re.sub(r'\\([^\\(]+\\)', ' ', text)\n",
    "                text2 = re.sub(r'Leia mais(.+)', '', text1)\n",
    "                return text2\n",
    "        except Exception:\n",
    "            pass\n",
    "    return u''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_texts = [get_raw_text(url) for url in source_urls]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_tokens = [nltk.word_tokenize(text) for text in raw_texts]\n",
    "\n",
    "texts = [nltk.Text(rt) for rt in raw_tokens]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Character count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Character_cnts = [len(text) for text in raw_texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Raw word count including stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Word_cnts_raw = [len(text) for text in texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Word count excluding stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('portuguese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filtered_tokens = [[w.lower() for w in tokens if w not in stopwords and not w.isnumeric() and len(w) > 1] for tokens in raw_tokens]\n",
    "Word_cnts_filtered = [len(tokens) for tokens in filtered_tokens]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Number of sentences and number of sentences with >70 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_sents = [nltk.sent_tokenize(text) for text in raw_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Sent_cnts = [len(sents) for sents in raw_sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Long_sent_cnts = [sum([len(s) > 170 for s in sents]) for sents in raw_sents]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Average sentence length (by token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "avg_sent_len = [ float(Word_cnts_raw[i]) / float(Sent_cnts[i]) for i in range(len(Word_cnts_raw))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POS Tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import floresta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Tagger0 = nltk.DefaultTagger('n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def simplify_tag(t):\n",
    "...     if \"+\" in t:\n",
    "...         return t[t.index(\"+\")+1:]\n",
    "...     else:\n",
    "...         return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tsents = [[(w.lower(),simplify_tag(t)) for (w,t) in sent] for sent in floresta.tagged_sents() if sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Tagger1 = nltk.UnigramTagger(tsents, backoff=Tagger0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Tagger2 = nltk.BigramTagger(tsents, backoff=Tagger1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add unigram pos and bigram pos features\n",
    "1. Use the first k text as training data to create all unigram pos and bigram pos used\n",
    "2. For test data, only consider the unigram pos and bigram pos used in the training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = 22"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_sents = raw_sents[:k]\n",
    "test_sents = raw_sents[k:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_unigram = set()\n",
    "all_bigram = set()\n",
    "train_unigrams = []\n",
    "train_bigrams = []\n",
    "for sents in train_sents:\n",
    "    tui = {}\n",
    "    tbi = {}\n",
    "    for sent in sents:\n",
    "        tsent = Tagger2.tag(nltk.word_tokenize(sent))\n",
    "        for i in range(len(tsent) - 1):\n",
    "            t0 = tsent[i][1]\n",
    "            t1 = tsent[i+1][1]\n",
    "            all_unigram.add(t0)\n",
    "            all_bigram.add((t0, t1))\n",
    "            tui[t0] = tui[t0] + 1 if t0 in tui else 1\n",
    "            tbi[(t0, t1)] = tbi[(t0, t1)] + 1 if (t0, t1) in tbi else 1\n",
    "        t0 = tsent[len(tsent) - 1][1]\n",
    "        all_unigram.add(t0)\n",
    "        tui[t0] = tui[t0] + 1 if t0 in tui else 1\n",
    "    train_unigrams.append(tui)\n",
    "    train_bigrams.append(tbi)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only keep those grams appear in at least L documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "L = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "use_cnt = [(x, sum(x in tu for tu in train_unigrams)) for x in all_unigram]\n",
    "use_unigram = set([x for (x,y) in use_cnt if y >L])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "use_cnt = [(x, sum(x in tb for tb in train_bigrams)) for x in all_bigram]\n",
    "use_bigram = set([x for (x,y) in use_cnt if y >L])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_unigrams = []\n",
    "test_bigrams = []\n",
    "for sents in test_sents:\n",
    "    tui = {}\n",
    "    tbi = {}\n",
    "    for sent in sents:\n",
    "        tsent = Tagger2.tag(nltk.word_tokenize(sent))\n",
    "        for i in range(len(tsent) - 1):\n",
    "            t0 = tsent[i][1]\n",
    "            t1 = tsent[i+1][1]\n",
    "            if t0 in use_unigram:\n",
    "                tui[t0] = tui[t0] + 1 if t0 in tui else 1\n",
    "            if (t0, t1) in use_bigram:\n",
    "                tbi[(t0, t1)] = tbi[(t0, t1)] + 1 if (t0, t1) in tbi else 1\n",
    "        t0 = tsent[len(tsent) - 1][1]\n",
    "        if t0 in use_unigram:\n",
    "            tui[t0] = tui[t0] + 1 if t0 in tui else 1\n",
    "    test_unigrams.append(tui)\n",
    "    test_bigrams.append(tbi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to numpy matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_unigram0 = [{u: tu[u] if u in tu else 0 for u in use_unigram} for tu in train_unigrams]\n",
    "\n",
    "train_uni_mat = pd.DataFrame(train_unigram0).values\n",
    "\n",
    "test_unigram0 = [{u: tu[u] if u in tu else 0 for u in use_unigram} for tu in test_unigrams]\n",
    "\n",
    "test_uni_mat = pd.DataFrame(test_unigram0).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_bigram0 = [{u: tu[u] if u in tu else 0 for u in use_bigram} for tu in train_bigrams]\n",
    "\n",
    "train_bi_mat = pd.DataFrame(train_bigram0).values\n",
    "\n",
    "test_bigram0 = [{u: tu[u] if u in tu else 0 for u in use_bigram} for tu in test_bigrams]\n",
    "\n",
    "test_bi_mat = pd.DataFrame(test_bigram0).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = len(source_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Character_cnt_mat = np.array(Character_cnts).reshape(N,1)\n",
    "Word_cnts_raw_mat = np.array(Word_cnts_raw).reshape(N,1)\n",
    "Word_cnts_filtered_mat = np.array(Word_cnts_filtered).reshape(N,1)\n",
    "Sent_cnts_mat = np.array(Sent_cnts).reshape(N,1)\n",
    "Long_sent_cnts_mat = np.array(Long_sent_cnts).reshape(N,1)\n",
    "avg_sent_len_mat = np.array(avg_sent_len).reshape(N,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Feature_mat1 = np.concatenate((Character_cnt_mat, Word_cnts_raw_mat, Word_cnts_filtered_mat,\n",
    "                              Sent_cnts_mat, Long_sent_cnts_mat, avg_sent_len_mat), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_mat1 = Feature_mat1[:k,]\n",
    "test_mat1 = Feature_mat1[k:,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_X_raw = np.concatenate((train_mat1, train_uni_mat, train_bi_mat), axis = 1)\n",
    "test_X_raw = np.concatenate((test_mat1, test_uni_mat, test_bi_mat), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_filtered_tokens = filtered_tokens[:k]\n",
    "test_filtered_tokens = filtered_tokens[k:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_tf = [dict(nltk.FreqDist(tokens)) for tokens in train_filtered_tokens]\n",
    "test_tf = [dict(nltk.FreqDist(tokens)) for tokens in test_filtered_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "#product = reduce((lambda x, y: x * y), [1, 2, 3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "use_tokens = reduce(lambda x, y: set(x).union(set(y)), train_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_tf0 = [{u: tf[u] if u in tf else 0 for u in use_tokens} for tf in train_tf]\n",
    "\n",
    "train_tf_mat = pd.DataFrame(train_tf0).values\n",
    "\n",
    "test_tf0 = [{u: tf[u] if u in tf else 0 for u in use_tokens} for tf in test_tf]\n",
    "\n",
    "test_tf_mat = pd.DataFrame(test_tf0).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = [sum([u in tf for tf in train_tf]) for u in use_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idf = np.array([1.0/d for d in df]).reshape(1, len(use_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_tf_idf = train_tf_mat * np.repeat(idf, train_tf_mat.shape[0], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_tf_idf = test_tf_mat * np.repeat(idf, test_tf_mat.shape[0], axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create random labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = np.random.randn(train_X_raw.shape[0])\n",
    "y_test = np.random.randn(test_X_raw.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try with the extracted feature first"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(train_X_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_X = scaler.transform(train_X_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_X = scaler.transform(test_X_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### random forest from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = RandomForestRegressor(n_estimators=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = clf.fit(train_X, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_predict_rf1 = clf.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "err_rf1 = mean_squared_error(y_test, y_predict_rf1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### try h2o gbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import h2o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321. connected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime:</td>\n",
       "<td>29 mins 59 secs</td></tr>\n",
       "<tr><td>H2O cluster version:</td>\n",
       "<td>3.10.5.4</td></tr>\n",
       "<tr><td>H2O cluster version age:</td>\n",
       "<td>23 days </td></tr>\n",
       "<tr><td>H2O cluster name:</td>\n",
       "<td>alin</td></tr>\n",
       "<tr><td>H2O cluster total nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster free memory:</td>\n",
       "<td>3.538 Gb</td></tr>\n",
       "<tr><td>H2O cluster total cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O cluster allowed cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O cluster status:</td>\n",
       "<td>accepting new members, healthy</td></tr>\n",
       "<tr><td>H2O connection url:</td>\n",
       "<td>http://localhost:54321</td></tr>\n",
       "<tr><td>H2O connection proxy:</td>\n",
       "<td>None</td></tr>\n",
       "<tr><td>H2O internal security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>Python version:</td>\n",
       "<td>2.7.11 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ------------------------------\n",
       "H2O cluster uptime:         29 mins 59 secs\n",
       "H2O cluster version:        3.10.5.4\n",
       "H2O cluster version age:    23 days\n",
       "H2O cluster name:           alin\n",
       "H2O cluster total nodes:    1\n",
       "H2O cluster free memory:    3.538 Gb\n",
       "H2O cluster total cores:    4\n",
       "H2O cluster allowed cores:  4\n",
       "H2O cluster status:         accepting new members, healthy\n",
       "H2O connection url:         http://localhost:54321\n",
       "H2O connection proxy:\n",
       "H2O internal security:      False\n",
       "Python version:             2.7.11 final\n",
       "--------------------------  ------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h2o.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_y = y_train.reshape(k,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = np.concatenate((train_X, train_y), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "train_hex = h2o.H2OFrame(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from h2o.estimators.gbm import H2OGradientBoostingEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gbm = H2OGradientBoostingEstimator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm Model Build progress: |███████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "gbm.train(x = range(90), y = 91, training_frame=train_hex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "#test_y = y_test.reshape(N-k,1)\n",
    "#test = np.concatenate((test_X, test_y), axis = 1)\n",
    "test_hex = h2o.H2OFrame(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm prediction progress: |████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "y_predict_gbm = gbm.predict(test_hex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th style=\"text-align: right;\">  predict</th></tr>\n",
       "<tr><td style=\"text-align: right;\">-0.227226</td></tr>\n",
       "<tr><td style=\"text-align: right;\">-0.411691</td></tr>\n",
       "<tr><td style=\"text-align: right;\"> 0.895856</td></tr>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict_gbm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### try h2o feed forward network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = np.concatenate((train_tf_idf, train_y), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "train_hex = h2o.H2OFrame(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "test_hex = h2o.H2OFrame(test_tf_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from h2o.estimators.deeplearning import H2ODeepLearningEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = H2ODeepLearningEstimator(distribution=\"gaussian\",\n",
    "                                 activation=\"tanh\",\n",
    "                                 hidden=[32,32,32],\n",
    "                                 input_dropout_ratio=0.2,\n",
    "                                 sparse=True,\n",
    "                                 l1=1e-5,\n",
    "                                 epochs= 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deeplearning Model Build progress: |██████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "model.train(x=range(train.shape[1]-1), y=train.shape[1]-1, training_frame=train_hex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ModelMetricsRegression: deeplearning\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 1.05373414731\n",
      "RMSE: 1.02651553681\n",
      "MAE: 0.563138875383\n",
      "RMSLE: NaN\n",
      "Mean Residual Deviance: 1.05373414731\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model_performance(train = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deeplearning prediction progress: |███████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "y_pred_dl = model.predict(test_hex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th style=\"text-align: right;\">  predict</th></tr>\n",
       "<tr><td style=\"text-align: right;\"> 0.609419</td></tr>\n",
       "<tr><td style=\"text-align: right;\">-0.538336</td></tr>\n",
       "<tr><td style=\"text-align: right;\">-0.181047</td></tr>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class H2ODeepLearningEstimator in module h2o.estimators.deeplearning:\n",
      "\n",
      "class H2ODeepLearningEstimator(h2o.estimators.estimator_base.H2OEstimator)\n",
      " |  Deep Learning\n",
      " |  \n",
      " |  Build a Deep Neural Network model using CPUs\n",
      " |  Builds a feed-forward multilayer artificial neural network on an H2OFrame\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |    >>> import h2o\n",
      " |    >>> from h2o.estimators.deeplearning import H2ODeepLearningEstimator\n",
      " |    >>> h2o.connect()\n",
      " |    >>> rows = [[1,2,3,4,0], [2,1,2,4,1], [2,1,4,2,1], [0,1,2,34,1], [2,3,4,1,0]] * 50\n",
      " |    >>> fr = h2o.H2OFrame(rows)\n",
      " |    >>> fr[4] = fr[4].asfactor()\n",
      " |    >>> model = H2ODeepLearningEstimator()\n",
      " |    >>> model.train(x=range(4), y=4, training_frame=fr)\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      H2ODeepLearningEstimator\n",
      " |      h2o.estimators.estimator_base.H2OEstimator\n",
      " |      h2o.model.model_base.ModelBase\n",
      " |      h2o.utils.backward_compatibility.BackwardsCompatibleBase\n",
      " |      __builtin__.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, **kwargs)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  activation\n",
      " |      Activation function.\n",
      " |      \n",
      " |      One of: ``\"tanh\"``, ``\"tanh_with_dropout\"``, ``\"rectifier\"``, ``\"rectifier_with_dropout\"``, ``\"maxout\"``,\n",
      " |      ``\"maxout_with_dropout\"``  (default: ``\"rectifier\"``).\n",
      " |  \n",
      " |  adaptive_rate\n",
      " |      Adaptive learning rate.\n",
      " |      \n",
      " |      Type: ``bool``  (default: ``True``).\n",
      " |  \n",
      " |  autoencoder\n",
      " |      Auto-Encoder.\n",
      " |      \n",
      " |      Type: ``bool``  (default: ``False``).\n",
      " |  \n",
      " |  average_activation\n",
      " |      Average activation for sparse auto-encoder. #Experimental\n",
      " |      \n",
      " |      Type: ``float``  (default: ``0``).\n",
      " |  \n",
      " |  balance_classes\n",
      " |      Balance training data class counts via over/under-sampling (for imbalanced data).\n",
      " |      \n",
      " |      Type: ``bool``  (default: ``False``).\n",
      " |  \n",
      " |  categorical_encoding\n",
      " |      Encoding scheme for categorical features\n",
      " |      \n",
      " |      One of: ``\"auto\"``, ``\"enum\"``, ``\"one_hot_internal\"``, ``\"one_hot_explicit\"``, ``\"binary\"``, ``\"eigen\"``,\n",
      " |      ``\"label_encoder\"``, ``\"sort_by_response\"``, ``\"enum_limited\"``  (default: ``\"auto\"``).\n",
      " |  \n",
      " |  checkpoint\n",
      " |      Model checkpoint to resume training with.\n",
      " |      \n",
      " |      Type: ``str``.\n",
      " |  \n",
      " |  class_sampling_factors\n",
      " |      Desired over/under-sampling ratios per class (in lexicographic order). If not specified, sampling factors will\n",
      " |      be automatically computed to obtain class balance during training. Requires balance_classes.\n",
      " |      \n",
      " |      Type: ``List[float]``.\n",
      " |  \n",
      " |  classification_stop\n",
      " |      Stopping criterion for classification error fraction on training data (-1 to disable).\n",
      " |      \n",
      " |      Type: ``float``  (default: ``0``).\n",
      " |  \n",
      " |  col_major\n",
      " |      #DEPRECATED Use a column major weight matrix for input layer. Can speed up forward propagation, but might slow\n",
      " |      down backpropagation.\n",
      " |      \n",
      " |      Type: ``bool``  (default: ``False``).\n",
      " |  \n",
      " |  diagnostics\n",
      " |      Enable diagnostics for hidden layers.\n",
      " |      \n",
      " |      Type: ``bool``  (default: ``True``).\n",
      " |  \n",
      " |  distribution\n",
      " |      Distribution function\n",
      " |      \n",
      " |      One of: ``\"auto\"``, ``\"bernoulli\"``, ``\"multinomial\"``, ``\"gaussian\"``, ``\"poisson\"``, ``\"gamma\"``,\n",
      " |      ``\"tweedie\"``, ``\"laplace\"``, ``\"quantile\"``, ``\"huber\"``  (default: ``\"auto\"``).\n",
      " |  \n",
      " |  elastic_averaging\n",
      " |      Elastic averaging between compute nodes can improve distributed model convergence. #Experimental\n",
      " |      \n",
      " |      Type: ``bool``  (default: ``False``).\n",
      " |  \n",
      " |  elastic_averaging_moving_rate\n",
      " |      Elastic averaging moving rate (only if elastic averaging is enabled).\n",
      " |      \n",
      " |      Type: ``float``  (default: ``0.9``).\n",
      " |  \n",
      " |  elastic_averaging_regularization\n",
      " |      Elastic averaging regularization strength (only if elastic averaging is enabled).\n",
      " |      \n",
      " |      Type: ``float``  (default: ``0.001``).\n",
      " |  \n",
      " |  epochs\n",
      " |      How many times the dataset should be iterated (streamed), can be fractional.\n",
      " |      \n",
      " |      Type: ``float``  (default: ``10``).\n",
      " |  \n",
      " |  epsilon\n",
      " |      Adaptive learning rate smoothing factor (to avoid divisions by zero and allow progress).\n",
      " |      \n",
      " |      Type: ``float``  (default: ``1e-08``).\n",
      " |  \n",
      " |  export_weights_and_biases\n",
      " |      Whether to export Neural Network weights and biases to H2O Frames.\n",
      " |      \n",
      " |      Type: ``bool``  (default: ``False``).\n",
      " |  \n",
      " |  fast_mode\n",
      " |      Enable fast mode (minor approximation in back-propagation).\n",
      " |      \n",
      " |      Type: ``bool``  (default: ``True``).\n",
      " |  \n",
      " |  fold_assignment\n",
      " |      Cross-validation fold assignment scheme, if fold_column is not specified. The 'Stratified' option will stratify\n",
      " |      the folds based on the response variable, for classification problems.\n",
      " |      \n",
      " |      One of: ``\"auto\"``, ``\"random\"``, ``\"modulo\"``, ``\"stratified\"``  (default: ``\"auto\"``).\n",
      " |  \n",
      " |  fold_column\n",
      " |      Column with cross-validation fold index assignment per observation.\n",
      " |      \n",
      " |      Type: ``str``.\n",
      " |  \n",
      " |  force_load_balance\n",
      " |      Force extra load balancing to increase training speed for small datasets (to keep all cores busy).\n",
      " |      \n",
      " |      Type: ``bool``  (default: ``True``).\n",
      " |  \n",
      " |  hidden\n",
      " |      Hidden layer sizes (e.g. [100, 100]).\n",
      " |      \n",
      " |      Type: ``List[int]``  (default: ``[200, 200]``).\n",
      " |  \n",
      " |  hidden_dropout_ratios\n",
      " |      Hidden layer dropout ratios (can improve generalization), specify one value per hidden layer, defaults to 0.5.\n",
      " |      \n",
      " |      Type: ``List[float]``.\n",
      " |  \n",
      " |  huber_alpha\n",
      " |      Desired quantile for Huber/M-regression (threshold between quadratic and linear loss, must be between 0 and 1).\n",
      " |      \n",
      " |      Type: ``float``  (default: ``0.9``).\n",
      " |  \n",
      " |  ignore_const_cols\n",
      " |      Ignore constant columns.\n",
      " |      \n",
      " |      Type: ``bool``  (default: ``True``).\n",
      " |  \n",
      " |  ignored_columns\n",
      " |      Names of columns to ignore for training.\n",
      " |      \n",
      " |      Type: ``List[str]``.\n",
      " |  \n",
      " |  initial_biases\n",
      " |      A list of H2OFrame ids to initialize the bias vectors of this model with.\n",
      " |      \n",
      " |      Type: ``List[H2OFrame]``.\n",
      " |  \n",
      " |  initial_weight_distribution\n",
      " |      Initial weight distribution.\n",
      " |      \n",
      " |      One of: ``\"uniform_adaptive\"``, ``\"uniform\"``, ``\"normal\"``  (default: ``\"uniform_adaptive\"``).\n",
      " |  \n",
      " |  initial_weight_scale\n",
      " |      Uniform: -value...value, Normal: stddev.\n",
      " |      \n",
      " |      Type: ``float``  (default: ``1``).\n",
      " |  \n",
      " |  initial_weights\n",
      " |      A list of H2OFrame ids to initialize the weight matrices of this model with.\n",
      " |      \n",
      " |      Type: ``List[H2OFrame]``.\n",
      " |  \n",
      " |  input_dropout_ratio\n",
      " |      Input layer dropout ratio (can improve generalization, try 0.1 or 0.2).\n",
      " |      \n",
      " |      Type: ``float``  (default: ``0``).\n",
      " |  \n",
      " |  keep_cross_validation_fold_assignment\n",
      " |      Whether to keep the cross-validation fold assignment.\n",
      " |      \n",
      " |      Type: ``bool``  (default: ``False``).\n",
      " |  \n",
      " |  keep_cross_validation_predictions\n",
      " |      Whether to keep the predictions of the cross-validation models.\n",
      " |      \n",
      " |      Type: ``bool``  (default: ``False``).\n",
      " |  \n",
      " |  l1\n",
      " |      L1 regularization (can add stability and improve generalization, causes many weights to become 0).\n",
      " |      \n",
      " |      Type: ``float``  (default: ``0``).\n",
      " |  \n",
      " |  l2\n",
      " |      L2 regularization (can add stability and improve generalization, causes many weights to be small.\n",
      " |      \n",
      " |      Type: ``float``  (default: ``0``).\n",
      " |  \n",
      " |  loss\n",
      " |      Loss function.\n",
      " |      \n",
      " |      One of: ``\"automatic\"``, ``\"cross_entropy\"``, ``\"quadratic\"``, ``\"huber\"``, ``\"absolute\"``, ``\"quantile\"``\n",
      " |      (default: ``\"automatic\"``).\n",
      " |  \n",
      " |  max_after_balance_size\n",
      " |      Maximum relative size of the training data after balancing class counts (can be less than 1.0). Requires\n",
      " |      balance_classes.\n",
      " |      \n",
      " |      Type: ``float``  (default: ``5``).\n",
      " |  \n",
      " |  max_categorical_features\n",
      " |      Max. number of categorical features, enforced via hashing. #Experimental\n",
      " |      \n",
      " |      Type: ``int``  (default: ``2147483647``).\n",
      " |  \n",
      " |  max_confusion_matrix_size\n",
      " |      [Deprecated] Maximum size (# classes) for confusion matrices to be printed in the Logs.\n",
      " |      \n",
      " |      Type: ``int``  (default: ``20``).\n",
      " |  \n",
      " |  max_hit_ratio_k\n",
      " |      Max. number (top K) of predictions to use for hit ratio computation (for multi-class only, 0 to disable).\n",
      " |      \n",
      " |      Type: ``int``  (default: ``0``).\n",
      " |  \n",
      " |  max_runtime_secs\n",
      " |      Maximum allowed runtime in seconds for model training. Use 0 to disable.\n",
      " |      \n",
      " |      Type: ``float``  (default: ``0``).\n",
      " |  \n",
      " |  max_w2\n",
      " |      Constraint for squared sum of incoming weights per unit (e.g. for Rectifier).\n",
      " |      \n",
      " |      Type: ``float``  (default: ``3.4028235e+38``).\n",
      " |  \n",
      " |  mini_batch_size\n",
      " |      Mini-batch size (smaller leads to better fit, larger can speed up and generalize better).\n",
      " |      \n",
      " |      Type: ``int``  (default: ``1``).\n",
      " |  \n",
      " |  missing_values_handling\n",
      " |      Handling of missing values. Either MeanImputation or Skip.\n",
      " |      \n",
      " |      One of: ``\"mean_imputation\"``, ``\"skip\"``  (default: ``\"mean_imputation\"``).\n",
      " |  \n",
      " |  momentum_ramp\n",
      " |      Number of training samples for which momentum increases.\n",
      " |      \n",
      " |      Type: ``float``  (default: ``1000000``).\n",
      " |  \n",
      " |  momentum_stable\n",
      " |      Final momentum after the ramp is over (try 0.99).\n",
      " |      \n",
      " |      Type: ``float``  (default: ``0``).\n",
      " |  \n",
      " |  momentum_start\n",
      " |      Initial momentum at the beginning of training (try 0.5).\n",
      " |      \n",
      " |      Type: ``float``  (default: ``0``).\n",
      " |  \n",
      " |  nesterov_accelerated_gradient\n",
      " |      Use Nesterov accelerated gradient (recommended).\n",
      " |      \n",
      " |      Type: ``bool``  (default: ``True``).\n",
      " |  \n",
      " |  nfolds\n",
      " |      Number of folds for N-fold cross-validation (0 to disable or >= 2).\n",
      " |      \n",
      " |      Type: ``int``  (default: ``0``).\n",
      " |  \n",
      " |  offset_column\n",
      " |      Offset column. This will be added to the combination of columns before applying the link function.\n",
      " |      \n",
      " |      Type: ``str``.\n",
      " |  \n",
      " |  overwrite_with_best_model\n",
      " |      If enabled, override the final model with the best model found during training.\n",
      " |      \n",
      " |      Type: ``bool``  (default: ``True``).\n",
      " |  \n",
      " |  pretrained_autoencoder\n",
      " |      Pretrained autoencoder model to initialize this model with.\n",
      " |      \n",
      " |      Type: ``str``.\n",
      " |  \n",
      " |  quantile_alpha\n",
      " |      Desired quantile for Quantile regression, must be between 0 and 1.\n",
      " |      \n",
      " |      Type: ``float``  (default: ``0.5``).\n",
      " |  \n",
      " |  quiet_mode\n",
      " |      Enable quiet mode for less output to standard output.\n",
      " |      \n",
      " |      Type: ``bool``  (default: ``False``).\n",
      " |  \n",
      " |  rate\n",
      " |      Learning rate (higher => less stable, lower => slower convergence).\n",
      " |      \n",
      " |      Type: ``float``  (default: ``0.005``).\n",
      " |  \n",
      " |  rate_annealing\n",
      " |      Learning rate annealing: rate / (1 + rate_annealing * samples).\n",
      " |      \n",
      " |      Type: ``float``  (default: ``1e-06``).\n",
      " |  \n",
      " |  rate_decay\n",
      " |      Learning rate decay factor between layers (N-th layer: rate * rate_decay ^ (n - 1).\n",
      " |      \n",
      " |      Type: ``float``  (default: ``1``).\n",
      " |  \n",
      " |  regression_stop\n",
      " |      Stopping criterion for regression error (MSE) on training data (-1 to disable).\n",
      " |      \n",
      " |      Type: ``float``  (default: ``1e-06``).\n",
      " |  \n",
      " |  replicate_training_data\n",
      " |      Replicate the entire training dataset onto every node for faster training on small datasets.\n",
      " |      \n",
      " |      Type: ``bool``  (default: ``True``).\n",
      " |  \n",
      " |  reproducible\n",
      " |      Force reproducibility on small data (will be slow - only uses 1 thread).\n",
      " |      \n",
      " |      Type: ``bool``  (default: ``False``).\n",
      " |  \n",
      " |  response_column\n",
      " |      Response variable column.\n",
      " |      \n",
      " |      Type: ``str``.\n",
      " |  \n",
      " |  rho\n",
      " |      Adaptive learning rate time decay factor (similarity to prior updates).\n",
      " |      \n",
      " |      Type: ``float``  (default: ``0.99``).\n",
      " |  \n",
      " |  score_duty_cycle\n",
      " |      Maximum duty cycle fraction for scoring (lower: more training, higher: more scoring).\n",
      " |      \n",
      " |      Type: ``float``  (default: ``0.1``).\n",
      " |  \n",
      " |  score_each_iteration\n",
      " |      Whether to score during each iteration of model training.\n",
      " |      \n",
      " |      Type: ``bool``  (default: ``False``).\n",
      " |  \n",
      " |  score_interval\n",
      " |      Shortest time interval (in seconds) between model scoring.\n",
      " |      \n",
      " |      Type: ``float``  (default: ``5``).\n",
      " |  \n",
      " |  score_training_samples\n",
      " |      Number of training set samples for scoring (0 for all).\n",
      " |      \n",
      " |      Type: ``int``  (default: ``10000``).\n",
      " |  \n",
      " |  score_validation_samples\n",
      " |      Number of validation set samples for scoring (0 for all).\n",
      " |      \n",
      " |      Type: ``int``  (default: ``0``).\n",
      " |  \n",
      " |  score_validation_sampling\n",
      " |      Method used to sample validation dataset for scoring.\n",
      " |      \n",
      " |      One of: ``\"uniform\"``, ``\"stratified\"``  (default: ``\"uniform\"``).\n",
      " |  \n",
      " |  seed\n",
      " |      Seed for random numbers (affects sampling) - Note: only reproducible when running single threaded.\n",
      " |      \n",
      " |      Type: ``int``  (default: ``-1``).\n",
      " |  \n",
      " |  shuffle_training_data\n",
      " |      Enable shuffling of training data (recommended if training data is replicated and train_samples_per_iteration is\n",
      " |      close to #nodes x #rows, of if using balance_classes).\n",
      " |      \n",
      " |      Type: ``bool``  (default: ``False``).\n",
      " |  \n",
      " |  single_node_mode\n",
      " |      Run on a single node for fine-tuning of model parameters.\n",
      " |      \n",
      " |      Type: ``bool``  (default: ``False``).\n",
      " |  \n",
      " |  sparse\n",
      " |      Sparse data handling (more efficient for data with lots of 0 values).\n",
      " |      \n",
      " |      Type: ``bool``  (default: ``False``).\n",
      " |  \n",
      " |  sparsity_beta\n",
      " |      Sparsity regularization. #Experimental\n",
      " |      \n",
      " |      Type: ``float``  (default: ``0``).\n",
      " |  \n",
      " |  standardize\n",
      " |      If enabled, automatically standardize the data. If disabled, the user must provide properly scaled input data.\n",
      " |      \n",
      " |      Type: ``bool``  (default: ``True``).\n",
      " |  \n",
      " |  stopping_metric\n",
      " |      Metric to use for early stopping (AUTO: logloss for classification, deviance for regression)\n",
      " |      \n",
      " |      One of: ``\"auto\"``, ``\"deviance\"``, ``\"logloss\"``, ``\"mse\"``, ``\"rmse\"``, ``\"mae\"``, ``\"rmsle\"``, ``\"auc\"``,\n",
      " |      ``\"lift_top_group\"``, ``\"misclassification\"``, ``\"mean_per_class_error\"``  (default: ``\"auto\"``).\n",
      " |  \n",
      " |  stopping_rounds\n",
      " |      Early stopping based on convergence of stopping_metric. Stop if simple moving average of length k of the\n",
      " |      stopping_metric does not improve for k:=stopping_rounds scoring events (0 to disable)\n",
      " |      \n",
      " |      Type: ``int``  (default: ``5``).\n",
      " |  \n",
      " |  stopping_tolerance\n",
      " |      Relative tolerance for metric-based stopping criterion (stop if relative improvement is not at least this much)\n",
      " |      \n",
      " |      Type: ``float``  (default: ``0``).\n",
      " |  \n",
      " |  target_ratio_comm_to_comp\n",
      " |      Target ratio of communication overhead to computation. Only for multi-node operation and\n",
      " |      train_samples_per_iteration = -2 (auto-tuning).\n",
      " |      \n",
      " |      Type: ``float``  (default: ``0.05``).\n",
      " |  \n",
      " |  train_samples_per_iteration\n",
      " |      Number of training samples (globally) per MapReduce iteration. Special values are 0: one epoch, -1: all\n",
      " |      available data (e.g., replicated training data), -2: automatic.\n",
      " |      \n",
      " |      Type: ``int``  (default: ``-2``).\n",
      " |  \n",
      " |  training_frame\n",
      " |      Id of the training data frame (Not required, to allow initial validation of model parameters).\n",
      " |      \n",
      " |      Type: ``H2OFrame``.\n",
      " |  \n",
      " |  tweedie_power\n",
      " |      Tweedie power for Tweedie regression, must be between 1 and 2.\n",
      " |      \n",
      " |      Type: ``float``  (default: ``1.5``).\n",
      " |  \n",
      " |  use_all_factor_levels\n",
      " |      Use all factor levels of categorical variables. Otherwise, the first factor level is omitted (without loss of\n",
      " |      accuracy). Useful for variable importances and auto-enabled for autoencoder.\n",
      " |      \n",
      " |      Type: ``bool``  (default: ``True``).\n",
      " |  \n",
      " |  validation_frame\n",
      " |      Id of the validation data frame.\n",
      " |      \n",
      " |      Type: ``H2OFrame``.\n",
      " |  \n",
      " |  variable_importances\n",
      " |      Compute variable importances for input features (Gedeon method) - can be slow for large networks.\n",
      " |      \n",
      " |      Type: ``bool``  (default: ``True``).\n",
      " |  \n",
      " |  weights_column\n",
      " |      Column with observation weights. Giving some observation a weight of zero is equivalent to excluding it from the\n",
      " |      dataset; giving an observation a relative weight of 2 is equivalent to repeating that row twice. Negative\n",
      " |      weights are not allowed.\n",
      " |      \n",
      " |      Type: ``str``.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  algo = u'deeplearning'\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from h2o.estimators.estimator_base.H2OEstimator:\n",
      " |  \n",
      " |  fit(self, x, y=None, **params)\n",
      " |      Fit an H2O model as part of a scikit-learn pipeline or grid search.\n",
      " |      \n",
      " |      A warning will be issued if a caller other than sklearn attempts to use this method.\n",
      " |      \n",
      " |      :param H2OFrame x: An H2OFrame consisting of the predictor variables.\n",
      " |      :param H2OFrame y: An H2OFrame consisting of the response variable.\n",
      " |      :param params: Extra arguments.\n",
      " |      :returns: The current instance of H2OEstimator for method chaining.\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Obtain parameters for this estimator.\n",
      " |      \n",
      " |      Used primarily for sklearn Pipelines and sklearn grid search.\n",
      " |      \n",
      " |      :param deep: If True, return parameters of all sub-objects that are estimators.\n",
      " |      \n",
      " |      :returns: A dict of parameters\n",
      " |  \n",
      " |  join(self)\n",
      " |      Wait until job's completion.\n",
      " |  \n",
      " |  set_params(self, **parms)\n",
      " |      Used by sklearn for updating parameters during grid search.\n",
      " |      \n",
      " |      :param parms: A dictionary of parameters that will be set on this model.\n",
      " |      :returns: self, the current estimator object with the parameters all set as desired.\n",
      " |  \n",
      " |  start(self, x, y=None, training_frame=None, offset_column=None, fold_column=None, weights_column=None, validation_frame=None, **params)\n",
      " |      Train the model asynchronously (to block for results call :meth:`join`).\n",
      " |      \n",
      " |      :param x: A list of column names or indices indicating the predictor columns.\n",
      " |      :param y: An index or a column name indicating the response column.\n",
      " |      :param H2OFrame training_frame: The H2OFrame having the columns indicated by x and y (as well as any\n",
      " |          additional columns specified by fold, offset, and weights).\n",
      " |      :param offset_column: The name or index of the column in training_frame that holds the offsets.\n",
      " |      :param fold_column: The name or index of the column in training_frame that holds the per-row fold\n",
      " |          assignments.\n",
      " |      :param weights_column: The name or index of the column in training_frame that holds the per-row weights.\n",
      " |      :param validation_frame: H2OFrame with validation data to be scored on while training.\n",
      " |  \n",
      " |  train(self, x=None, y=None, training_frame=None, offset_column=None, fold_column=None, weights_column=None, validation_frame=None, max_runtime_secs=None, ignored_columns=None, model_id=None)\n",
      " |      Train the H2O model.\n",
      " |      \n",
      " |      :param x: A list of column names or indices indicating the predictor columns.\n",
      " |      :param y: An index or a column name indicating the response column.\n",
      " |      :param H2OFrame training_frame: The H2OFrame having the columns indicated by x and y (as well as any\n",
      " |          additional columns specified by fold, offset, and weights).\n",
      " |      :param offset_column: The name or index of the column in training_frame that holds the offsets.\n",
      " |      :param fold_column: The name or index of the column in training_frame that holds the per-row fold\n",
      " |          assignments.\n",
      " |      :param weights_column: The name or index of the column in training_frame that holds the per-row weights.\n",
      " |      :param validation_frame: H2OFrame with validation data to be scored on while training.\n",
      " |      :param float max_runtime_secs: Maximum allowed runtime in seconds for model training. Use 0 to disable.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods inherited from h2o.estimators.estimator_base.H2OEstimator:\n",
      " |  \n",
      " |  mixin(obj, cls)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from h2o.model.model_base.ModelBase:\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |  \n",
      " |  aic(self, train=False, valid=False, xval=False)\n",
      " |      Get the AIC (Akaike Information Criterium).\n",
      " |      \n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
      " |      \"valid\", and \"xval\".\n",
      " |      \n",
      " |      :param bool train: If train is True, then return the AIC value for the training data.\n",
      " |      :param bool valid: If valid is True, then return the AIC value for the validation data.\n",
      " |      :param bool xval:  If xval is True, then return the AIC value for the validation data.\n",
      " |      \n",
      " |      :returns: The AIC.\n",
      " |  \n",
      " |  auc(self, train=False, valid=False, xval=False)\n",
      " |      Get the AUC (Area Under Curve).\n",
      " |      \n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
      " |      \"valid\", and \"xval\".\n",
      " |      \n",
      " |      :param bool train: If train is True, then return the AUC value for the training data.\n",
      " |      :param bool valid: If valid is True, then return the AUC value for the validation data.\n",
      " |      :param bool xval:  If xval is True, then return the AUC value for the validation data.\n",
      " |      \n",
      " |      :returns: The AUC.\n",
      " |  \n",
      " |  biases(self, vector_id=0)\n",
      " |      Return the frame for the respective bias vector.\n",
      " |      \n",
      " |      :param: vector_id: an integer, ranging from 0 to number of layers, that specifies the bias vector to return.\n",
      " |      \n",
      " |      :returns: an H2OFrame which represents the bias vector identified by vector_id\n",
      " |  \n",
      " |  catoffsets(self)\n",
      " |      Categorical offsets for one-hot encoding.\n",
      " |  \n",
      " |  coef(self)\n",
      " |      Return the coefficients which can be applied to the non-standardized data.\n",
      " |      \n",
      " |      Note: standardize = True by default, if set to False then coef() return the coefficients which are fit directly.\n",
      " |  \n",
      " |  coef_norm(self)\n",
      " |      Return coefficients fitted on the standardized data (requires standardize = True, which is on by default).\n",
      " |      \n",
      " |      These coefficients can be used to evaluate variable importance.\n",
      " |  \n",
      " |  cross_validation_fold_assignment(self)\n",
      " |      Obtain the cross-validation fold assignment for all rows in the training data.\n",
      " |      \n",
      " |      :returns: H2OFrame\n",
      " |  \n",
      " |  cross_validation_holdout_predictions(self)\n",
      " |      Obtain the (out-of-sample) holdout predictions of all cross-validation models on the training data.\n",
      " |      \n",
      " |      This is equivalent to summing up all H2OFrames returned by cross_validation_predictions.\n",
      " |      \n",
      " |      :returns: H2OFrame\n",
      " |  \n",
      " |  cross_validation_metrics_summary(self)\n",
      " |      Retrieve Cross-Validation Metrics Summary.\n",
      " |      \n",
      " |      :returns: The cross-validation metrics summary as an H2OTwoDimTable\n",
      " |  \n",
      " |  cross_validation_models(self)\n",
      " |      Obtain a list of cross-validation models.\n",
      " |      \n",
      " |      :returns: list of H2OModel objects.\n",
      " |  \n",
      " |  cross_validation_predictions(self)\n",
      " |      Obtain the (out-of-sample) holdout predictions of all cross-validation models on their holdout data.\n",
      " |      \n",
      " |      Note that the predictions are expanded to the full number of rows of the training data, with 0 fill-in.\n",
      " |      \n",
      " |      :returns: list of H2OFrame objects.\n",
      " |  \n",
      " |  deepfeatures(self, test_data, layer)\n",
      " |      Return hidden layer details.\n",
      " |      \n",
      " |      :param test_data: Data to create a feature space on\n",
      " |      :param layer: 0 index hidden layer\n",
      " |  \n",
      " |  download_mojo(self, path=u'.', get_genmodel_jar=False, genmodel_name=u'')\n",
      " |      Download the model in MOJO format.\n",
      " |      \n",
      " |      :param path: the path where MOJO file should be saved.\n",
      " |      :param get_genmodel_jar: if True, then also download h2o-genmodel.jar and store it in folder ``path``.\n",
      " |      :param genmodel_name Custom name of genmodel jar\n",
      " |      :returns: name of the MOJO file written.\n",
      " |  \n",
      " |  download_pojo(self, path=u'', get_genmodel_jar=False, genmodel_name=u'')\n",
      " |      Download the POJO for this model to the directory specified by path.\n",
      " |      \n",
      " |      If path is an empty string, then dump the output to screen.\n",
      " |      \n",
      " |      :param path:  An absolute path to the directory where POJO should be saved.\n",
      " |      :param get_genmodel_jar: if True, then also download h2o-genmodel.jar and store it in folder ``path``.\n",
      " |      :param genmodel_name Custom name of genmodel jar\n",
      " |      :returns: name of the POJO file written.\n",
      " |  \n",
      " |  get_xval_models(self, key=None)\n",
      " |      Return a Model object.\n",
      " |      \n",
      " |      :param key: If None, return all cross-validated models; otherwise return the model that key points to.\n",
      " |      \n",
      " |      :returns: A model or list of models.\n",
      " |  \n",
      " |  gini(self, train=False, valid=False, xval=False)\n",
      " |      Get the Gini coefficient.\n",
      " |      \n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
      " |      \"valid\", and \"xval\"\n",
      " |      \n",
      " |      :param bool train: If train is True, then return the Gini Coefficient value for the training data.\n",
      " |      :param bool valid: If valid is True, then return the Gini Coefficient value for the validation data.\n",
      " |      :param bool xval:  If xval is True, then return the Gini Coefficient value for the cross validation data.\n",
      " |      \n",
      " |      :returns: The Gini Coefficient for this binomial model.\n",
      " |  \n",
      " |  is_cross_validated(self)\n",
      " |      Return True if the model was cross-validated.\n",
      " |  \n",
      " |  logloss(self, train=False, valid=False, xval=False)\n",
      " |      Get the Log Loss.\n",
      " |      \n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
      " |      \"valid\", and \"xval\".\n",
      " |      \n",
      " |      :param bool train: If train is True, then return the log loss value for the training data.\n",
      " |      :param bool valid: If valid is True, then return the log loss value for the validation data.\n",
      " |      :param bool xval:  If xval is True, then return the log loss value for the cross validation data.\n",
      " |      \n",
      " |      :returns: The log loss for this regression model.\n",
      " |  \n",
      " |  mae(self, train=False, valid=False, xval=False)\n",
      " |      Get the Mean Absolute Error.\n",
      " |      \n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
      " |      \"valid\", and \"xval\".\n",
      " |      \n",
      " |      :param bool train: If train is True, then return the MAE value for the training data.\n",
      " |      :param bool valid: If valid is True, then return the MAE value for the validation data.\n",
      " |      :param bool xval:  If xval is True, then return the MAE value for the cross validation data.\n",
      " |      \n",
      " |      :returns: The MAE for this regression model.\n",
      " |  \n",
      " |  mean_residual_deviance(self, train=False, valid=False, xval=False)\n",
      " |      Get the Mean Residual Deviances.\n",
      " |      \n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
      " |      \"valid\", and \"xval\".\n",
      " |      \n",
      " |      :param bool train: If train is True, then return the Mean Residual Deviance value for the training data.\n",
      " |      :param bool valid: If valid is True, then return the Mean Residual Deviance value for the validation data.\n",
      " |      :param bool xval:  If xval is True, then return the Mean Residual Deviance value for the cross validation data.\n",
      " |      \n",
      " |      :returns: The Mean Residual Deviance for this regression model.\n",
      " |  \n",
      " |  metalearner(self)\n",
      " |      Print the metalearner for the model, if any.  Currently only used by H2OStackedEnsembleEstimator.\n",
      " |  \n",
      " |  model_performance(self, test_data=None, train=False, valid=False, xval=False)\n",
      " |      Generate model metrics for this model on test_data.\n",
      " |      \n",
      " |      :param H2OFrame test_data: Data set for which model metrics shall be computed against. All three of train,\n",
      " |          valid and xval arguments are ignored if test_data is not None.\n",
      " |      :param bool train: Report the training metrics for the model.\n",
      " |      :param bool valid: Report the validation metrics for the model.\n",
      " |      :param bool xval: Report the cross-validation metrics for the model. If train and valid are True, then it\n",
      " |          defaults to True.\n",
      " |      \n",
      " |      :returns: An object of class H2OModelMetrics.\n",
      " |  \n",
      " |  mse(self, train=False, valid=False, xval=False)\n",
      " |      Get the Mean Square Error.\n",
      " |      \n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
      " |      \"valid\", and \"xval\".\n",
      " |      \n",
      " |      :param bool train: If train is True, then return the MSE value for the training data.\n",
      " |      :param bool valid: If valid is True, then return the MSE value for the validation data.\n",
      " |      :param bool xval:  If xval is True, then return the MSE value for the cross validation data.\n",
      " |      \n",
      " |      :returns: The MSE for this regression model.\n",
      " |  \n",
      " |  normmul(self)\n",
      " |      Normalization/Standardization multipliers for numeric predictors.\n",
      " |  \n",
      " |  normsub(self)\n",
      " |      Normalization/Standardization offsets for numeric predictors.\n",
      " |  \n",
      " |  null_degrees_of_freedom(self, train=False, valid=False, xval=False)\n",
      " |      Retreive the null degress of freedom if this model has the attribute, or None otherwise.\n",
      " |      \n",
      " |      :param bool train: Get the null dof for the training set. If both train and valid are False, then train is\n",
      " |          selected by default.\n",
      " |      :param bool valid: Get the null dof for the validation set. If both train and valid are True, then train is\n",
      " |          selected by default.\n",
      " |      \n",
      " |      :returns: Return the null dof, or None if it is not present.\n",
      " |  \n",
      " |  null_deviance(self, train=False, valid=False, xval=False)\n",
      " |      Retreive the null deviance if this model has the attribute, or None otherwise.\n",
      " |      \n",
      " |      :param bool train: Get the null deviance for the training set. If both train and valid are False, then train\n",
      " |          is selected by default.\n",
      " |      :param bool valid: Get the null deviance for the validation set. If both train and valid are True, then train\n",
      " |          is selected by default.\n",
      " |      \n",
      " |      :returns: Return the null deviance, or None if it is not present.\n",
      " |  \n",
      " |  partial_plot(self, data, cols, destination_key=None, nbins=20, plot=True, plot_stddev=True, figsize=(7, 10), server=False)\n",
      " |      Create partial dependence plot which gives a graphical depiction of the marginal effect of a variable on the\n",
      " |      response. The effect of a variable is measured in change in the mean response.\n",
      " |      \n",
      " |      :param H2OFrame data: An H2OFrame object used for scoring and constructing the plot.\n",
      " |      :param cols: Feature(s) for which partial dependence will be calculated.\n",
      " |      :param destination_key: An key reference to the created partial dependence tables in H2O.\n",
      " |      :param nbins: Number of bins used. For categorical columns make sure the number of bins exceed the level count.\n",
      " |      :param plot: A boolean specifying whether to plot partial dependence table.\n",
      " |      :param plot_stddev: A boolean specifying whether to add std err to partial dependence plot.\n",
      " |      :param figsize: Dimension/size of the returning plots, adjust to fit your output cells.\n",
      " |      :param server: ?\n",
      " |      :returns: Plot and list of calculated mean response tables for each feature requested.\n",
      " |  \n",
      " |  pprint_coef(self)\n",
      " |      Pretty print the coefficents table (includes normalized coefficients).\n",
      " |  \n",
      " |  predict(self, test_data)\n",
      " |      Predict on a dataset.\n",
      " |      \n",
      " |      :param H2OFrame test_data: Data on which to make predictions.\n",
      " |      \n",
      " |      :returns: A new H2OFrame of predictions.\n",
      " |  \n",
      " |  predict_leaf_node_assignment(self, test_data)\n",
      " |      Predict on a dataset and return the leaf node assignment (only for tree-based models).\n",
      " |      \n",
      " |      :param H2OFrame test_data: Data on which to make predictions.\n",
      " |      \n",
      " |      :returns: A new H2OFrame of predictions.\n",
      " |  \n",
      " |  r2(self, train=False, valid=False, xval=False)\n",
      " |      Return the R squared for this regression model.\n",
      " |      \n",
      " |      Will return R^2 for GLM Models and will return NaN otherwise.\n",
      " |      \n",
      " |      The R^2 value is defined to be 1 - MSE/var, where var is computed as sigma*sigma.\n",
      " |      \n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
      " |      \"valid\", and \"xval\".\n",
      " |      \n",
      " |      :param bool train: If train is True, then return the R^2 value for the training data.\n",
      " |      :param bool valid: If valid is True, then return the R^2 value for the validation data.\n",
      " |      :param bool xval:  If xval is True, then return the R^2 value for the cross validation data.\n",
      " |      \n",
      " |      :returns: The R squared for this regression model.\n",
      " |  \n",
      " |  residual_degrees_of_freedom(self, train=False, valid=False, xval=False)\n",
      " |      Retreive the residual degress of freedom if this model has the attribute, or None otherwise.\n",
      " |      \n",
      " |      :param bool train: Get the residual dof for the training set. If both train and valid are False, then train\n",
      " |          is selected by default.\n",
      " |      :param bool valid: Get the residual dof for the validation set. If both train and valid are True, then train\n",
      " |          is selected by default.\n",
      " |      \n",
      " |      :returns: Return the residual dof, or None if it is not present.\n",
      " |  \n",
      " |  residual_deviance(self, train=False, valid=False, xval=None)\n",
      " |      Retreive the residual deviance if this model has the attribute, or None otherwise.\n",
      " |      \n",
      " |      :param bool train: Get the residual deviance for the training set. If both train and valid are False, then\n",
      " |          train is selected by default.\n",
      " |      :param bool valid: Get the residual deviance for the validation set. If both train and valid are True, then\n",
      " |          train is selected by default.\n",
      " |      \n",
      " |      :returns: Return the residual deviance, or None if it is not present.\n",
      " |  \n",
      " |  respmul(self)\n",
      " |      Normalization/Standardization multipliers for numeric response.\n",
      " |  \n",
      " |  respsub(self)\n",
      " |      Normalization/Standardization offsets for numeric response.\n",
      " |  \n",
      " |  rmse(self, train=False, valid=False, xval=False)\n",
      " |      Get the Root Mean Square Error.\n",
      " |      \n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
      " |      \"valid\", and \"xval\".\n",
      " |      \n",
      " |      :param bool train: If train is True, then return the RMSE value for the training data.\n",
      " |      :param bool valid: If valid is True, then return the RMSE value for the validation data.\n",
      " |      :param bool xval:  If xval is True, then return the RMSE value for the cross validation data.\n",
      " |      \n",
      " |      :returns: The RMSE for this regression model.\n",
      " |  \n",
      " |  rmsle(self, train=False, valid=False, xval=False)\n",
      " |      Get the Root Mean Squared Logarithmic Error.\n",
      " |      \n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
      " |      \"valid\", and \"xval\".\n",
      " |      \n",
      " |      :param bool train: If train is True, then return the RMSLE value for the training data.\n",
      " |      :param bool valid: If valid is True, then return the RMSLE value for the validation data.\n",
      " |      :param bool xval:  If xval is True, then return the RMSLE value for the cross validation data.\n",
      " |      \n",
      " |      :returns: The RMSLE for this regression model.\n",
      " |  \n",
      " |  rotation(self)\n",
      " |      Obtain the rotations (eigenvectors) for a PCA model\n",
      " |      \n",
      " |      :return: H2OFrame\n",
      " |  \n",
      " |  save_model_details(self, path=u'', force=False)\n",
      " |      Save Model Details of an H2O Model in JSON Format to disk.\n",
      " |      \n",
      " |      :param model: The model object to save.\n",
      " |      :param path: a path to save the model details at (hdfs, s3, local)\n",
      " |      :param force: if True overwrite destination directory in case it exists, or throw exception if set to False.\n",
      " |      \n",
      " |      :returns str: the path of the saved model details\n",
      " |  \n",
      " |  save_mojo(self, path=u'', force=False)\n",
      " |      Save an H2O Model as MOJO (Model Object, Optimized) to disk.\n",
      " |      \n",
      " |      :param model: The model object to save.\n",
      " |      :param path: a path to save the model at (hdfs, s3, local)\n",
      " |      :param force: if True overwrite destination directory in case it exists, or throw exception if set to False.\n",
      " |      \n",
      " |      :returns str: the path of the saved model\n",
      " |  \n",
      " |  score_history(self)\n",
      " |      DEPRECATED. Use :meth:`scoring_history` instead.\n",
      " |  \n",
      " |  scoring_history(self)\n",
      " |      Retrieve Model Score History.\n",
      " |      \n",
      " |      :returns: The score history as an H2OTwoDimTable or a Pandas DataFrame.\n",
      " |  \n",
      " |  show(self)\n",
      " |      Print innards of model, without regards to type.\n",
      " |  \n",
      " |  std_coef_plot(self, num_of_features=None, server=False)\n",
      " |      Plot a GLM model\"s standardized coefficient magnitudes.\n",
      " |      \n",
      " |      :param num_of_features: the number of features shown in the plot.\n",
      " |      :param server: ?\n",
      " |      \n",
      " |      :returns: None.\n",
      " |  \n",
      " |  summary(self)\n",
      " |      Print a detailed summary of the model.\n",
      " |  \n",
      " |  varimp(self, use_pandas=False)\n",
      " |      Pretty print the variable importances, or return them in a list.\n",
      " |      \n",
      " |      :param use_pandas: If True, then the variable importances will be returned as a pandas data frame.\n",
      " |      \n",
      " |      :returns: A list or Pandas DataFrame.\n",
      " |  \n",
      " |  varimp_plot(self, num_of_features=None, server=False)\n",
      " |      Plot the variable importance for a trained model.\n",
      " |      \n",
      " |      :param num_of_features: the number of features shown in the plot (default is 10 or all if less than 10).\n",
      " |      :param server: ?\n",
      " |      \n",
      " |      :returns: None.\n",
      " |  \n",
      " |  weights(self, matrix_id=0)\n",
      " |      Return the frame for the respective weight matrix.\n",
      " |      \n",
      " |      :param: matrix_id: an integer, ranging from 0 to number of layers, that specifies the weight matrix to return.\n",
      " |      \n",
      " |      :returns: an H2OFrame which represents the weight matrix identified by matrix_id\n",
      " |  \n",
      " |  xval_keys(self)\n",
      " |      Return model keys for the cross-validated model.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from h2o.model.model_base.ModelBase:\n",
      " |  \n",
      " |  actual_params\n",
      " |      Dictionary of actual parameters of the model.\n",
      " |  \n",
      " |  default_params\n",
      " |      Dictionary of the default parameters of the model.\n",
      " |  \n",
      " |  full_parameters\n",
      " |      Dictionary of the full specification of all parameters.\n",
      " |  \n",
      " |  model_id\n",
      " |      Model identifier.\n",
      " |  \n",
      " |  params\n",
      " |      Get the parameters and the actual/default values only.\n",
      " |      \n",
      " |      :returns: A dictionary of parameters used to build this model.\n",
      " |  \n",
      " |  type\n",
      " |      The type of model built: ``\"classifier\"`` or ``\"regressor\"`` or ``\"unsupervised\"``\n",
      " |  \n",
      " |  xvals\n",
      " |      Return a list of the cross-validated models.\n",
      " |      \n",
      " |      :returns: A list of models.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from h2o.utils.backward_compatibility.BackwardsCompatibleBase:\n",
      " |  \n",
      " |  __getattr__(self, item)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from h2o.utils.backward_compatibility.BackwardsCompatibleBase:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(H2ODeepLearningEstimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another tagger:\n",
    "1. http://rdrpostagger.sourceforge.net/\n",
    "2. http://aelius.sourceforge.net/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
