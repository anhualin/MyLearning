{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project we explore how to use basic natural languate processing and machine learning techniques to automatically grade essays (AES) in Brazilian Portuguese. In general, AES is a very difficult problem even in English. The available tools that can be used for Portuguese are even less. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%qtconsole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Essay Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "question = pd.read_excel(io=\"C:/Users/alin/Documents/ORAnalytics/AES/data/Brazil_essay.xlsx\", sheetname=\"Essay Question\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "question = question.Original[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conforme apresentado no vídeo da Revista Exame, o comportamento é muito importante no trabalho, nas organizações. Em sua opinião, o comportamento é responsabilidade da própria pessoa ou da empresa em que trabalha? O que as organizações podem fazer para ajudar seus colaboradores a desenvolverem comportamentos melhores e mais adequados às necessidades do trabalho?\n"
     ]
    }
   ],
   "source": [
    "print question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Essays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "essay_df = pd.read_excel(io=\"C:/Users/alin/Documents/ORAnalytics/AES/data/Brazil_essay.xlsx\", sheetname=\"result\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "essay_df.columns = essay_df.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>pk1</th>\n",
       "      <th>title</th>\n",
       "      <th>average_score</th>\n",
       "      <th>resposta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.071078</td>\n",
       "      <td>2500</td>\n",
       "      <td>ATIVIDADE 1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>&lt;p&gt; Em minha opinião que quando se trata de co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.081038</td>\n",
       "      <td>4817</td>\n",
       "      <td>ATIVIDADE 1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>&lt;p&gt;Olá Patricia,&lt;/p&gt; \\n&lt;p&gt;Concordo com sua col...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.081924</td>\n",
       "      <td>7253</td>\n",
       "      <td>ATIVIDADE 1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>&lt;p&gt;O comportamento do profissional dentro da e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.091905</td>\n",
       "      <td>11815</td>\n",
       "      <td>ATIVIDADE 1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>&lt;p&gt;&lt;span style=\"font-family: georgia , palatin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.101049</td>\n",
       "      <td>704153</td>\n",
       "      <td>ATIVIDADE 1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>&lt;p&gt;&lt;span style=\"font-size: 10.0pt;font-family:...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id     pk1        title  average_score  \\\n",
       "0  1.071078    2500  ATIVIDADE 1            2.5   \n",
       "1  1.081038    4817  ATIVIDADE 1            2.5   \n",
       "2  1.081924    7253  ATIVIDADE 1            2.5   \n",
       "3  1.091905   11815  ATIVIDADE 1            2.5   \n",
       "4  1.101049  704153  ATIVIDADE 1            1.5   \n",
       "\n",
       "                                            resposta  \n",
       "0  <p> Em minha opinião que quando se trata de co...  \n",
       "1  <p>Olá Patricia,</p> \\n<p>Concordo com sua col...  \n",
       "2  <p>O comportamento do profissional dentro da e...  \n",
       "3  <p><span style=\"font-family: georgia , palatin...  \n",
       "4  <p><span style=\"font-size: 10.0pt;font-family:...  "
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essay_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count # of paragraphs and remove html tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "essay_df['paragraphs'] = essay_df.apply(lambda r: len(re.findall(r'<p', r['resposta'])), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "essay_df['text'] = essay_df.apply(lambda r: re.sub(r'<[^<>]*>', ' ', r['resposta']), axis = 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>pk1</th>\n",
       "      <th>title</th>\n",
       "      <th>average_score</th>\n",
       "      <th>resposta</th>\n",
       "      <th>paragraphs</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.071078</td>\n",
       "      <td>2500</td>\n",
       "      <td>ATIVIDADE 1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>&lt;p&gt; Em minha opinião que quando se trata de co...</td>\n",
       "      <td>6</td>\n",
       "      <td>Em minha opinião que quando se trata de comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.081038</td>\n",
       "      <td>4817</td>\n",
       "      <td>ATIVIDADE 1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>&lt;p&gt;Olá Patricia,&lt;/p&gt; \\n&lt;p&gt;Concordo com sua col...</td>\n",
       "      <td>4</td>\n",
       "      <td>Olá Patricia,  \\n Concordo com sua colocação ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.081924</td>\n",
       "      <td>7253</td>\n",
       "      <td>ATIVIDADE 1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>&lt;p&gt;O comportamento do profissional dentro da e...</td>\n",
       "      <td>2</td>\n",
       "      <td>O comportamento do profissional dentro da emp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.091905</td>\n",
       "      <td>11815</td>\n",
       "      <td>ATIVIDADE 1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>&lt;p&gt;&lt;span style=\"font-family: georgia , palatin...</td>\n",
       "      <td>4</td>\n",
       "      <td>\\n  Em um primeiro momento o comportamen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.101049</td>\n",
       "      <td>704153</td>\n",
       "      <td>ATIVIDADE 1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>&lt;p&gt;&lt;span style=\"font-size: 10.0pt;font-family:...</td>\n",
       "      <td>2</td>\n",
       "      <td>Questões comportamentais estão relacionadas ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id     pk1        title  average_score  \\\n",
       "0  1.071078    2500  ATIVIDADE 1            2.5   \n",
       "1  1.081038    4817  ATIVIDADE 1            2.5   \n",
       "2  1.081924    7253  ATIVIDADE 1            2.5   \n",
       "3  1.091905   11815  ATIVIDADE 1            2.5   \n",
       "4  1.101049  704153  ATIVIDADE 1            1.5   \n",
       "\n",
       "                                            resposta  paragraphs  \\\n",
       "0  <p> Em minha opinião que quando se trata de co...           6   \n",
       "1  <p>Olá Patricia,</p> \\n<p>Concordo com sua col...           4   \n",
       "2  <p>O comportamento do profissional dentro da e...           2   \n",
       "3  <p><span style=\"font-family: georgia , palatin...           4   \n",
       "4  <p><span style=\"font-size: 10.0pt;font-family:...           2   \n",
       "\n",
       "                                                text  \n",
       "0    Em minha opinião que quando se trata de comp...  \n",
       "1   Olá Patricia,  \\n Concordo com sua colocação ...  \n",
       "2   O comportamento do profissional dentro da emp...  \n",
       "3        \\n  Em um primeiro momento o comportamen...  \n",
       "4    Questões comportamentais estão relacionadas ...  "
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essay_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create some basic features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "essay_df['tokens'] = essay_df.apply(lambda r: nltk.wordpunct_tokenize(r['text']), axis = 1)\n",
    "essay_df['nlp_text'] = essay_df.apply(lambda r: nltk.Text(r['tokens']), axis = 1) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>pk1</th>\n",
       "      <th>title</th>\n",
       "      <th>average_score</th>\n",
       "      <th>resposta</th>\n",
       "      <th>paragraphs</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>nlp_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.071078</td>\n",
       "      <td>2500</td>\n",
       "      <td>ATIVIDADE 1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>&lt;p&gt; Em minha opinião que quando se trata de co...</td>\n",
       "      <td>6</td>\n",
       "      <td>Em minha opinião que quando se trata de comp...</td>\n",
       "      <td>[Em, minha, opinião, que, quando, se, trata, d...</td>\n",
       "      <td>(Em, minha, opinião, que, quando, se, trata, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.081038</td>\n",
       "      <td>4817</td>\n",
       "      <td>ATIVIDADE 1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>&lt;p&gt;Olá Patricia,&lt;/p&gt; \\n&lt;p&gt;Concordo com sua col...</td>\n",
       "      <td>4</td>\n",
       "      <td>Olá Patricia,  \\n Concordo com sua colocação ...</td>\n",
       "      <td>[Olá, Patricia, ,, Concordo, com, sua, colocaç...</td>\n",
       "      <td>(Olá, Patricia, ,, Concordo, com, sua, colocaç...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.081924</td>\n",
       "      <td>7253</td>\n",
       "      <td>ATIVIDADE 1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>&lt;p&gt;O comportamento do profissional dentro da e...</td>\n",
       "      <td>2</td>\n",
       "      <td>O comportamento do profissional dentro da emp...</td>\n",
       "      <td>[O, comportamento, do, profissional, dentro, d...</td>\n",
       "      <td>(O, comportamento, do, profissional, dentro, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.091905</td>\n",
       "      <td>11815</td>\n",
       "      <td>ATIVIDADE 1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>&lt;p&gt;&lt;span style=\"font-family: georgia , palatin...</td>\n",
       "      <td>4</td>\n",
       "      <td>\\n  Em um primeiro momento o comportamen...</td>\n",
       "      <td>[Em, um, primeiro, momento, o, comportamento, ...</td>\n",
       "      <td>(Em, um, primeiro, momento, o, comportamento, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.101049</td>\n",
       "      <td>704153</td>\n",
       "      <td>ATIVIDADE 1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>&lt;p&gt;&lt;span style=\"font-size: 10.0pt;font-family:...</td>\n",
       "      <td>2</td>\n",
       "      <td>Questões comportamentais estão relacionadas ...</td>\n",
       "      <td>[Questões, comportamentais, estão, relacionada...</td>\n",
       "      <td>(Questões, comportamentais, estão, relacionada...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id     pk1        title  average_score  \\\n",
       "0  1.071078    2500  ATIVIDADE 1            2.5   \n",
       "1  1.081038    4817  ATIVIDADE 1            2.5   \n",
       "2  1.081924    7253  ATIVIDADE 1            2.5   \n",
       "3  1.091905   11815  ATIVIDADE 1            2.5   \n",
       "4  1.101049  704153  ATIVIDADE 1            1.5   \n",
       "\n",
       "                                            resposta  paragraphs  \\\n",
       "0  <p> Em minha opinião que quando se trata de co...           6   \n",
       "1  <p>Olá Patricia,</p> \\n<p>Concordo com sua col...           4   \n",
       "2  <p>O comportamento do profissional dentro da e...           2   \n",
       "3  <p><span style=\"font-family: georgia , palatin...           4   \n",
       "4  <p><span style=\"font-size: 10.0pt;font-family:...           2   \n",
       "\n",
       "                                                text  \\\n",
       "0    Em minha opinião que quando se trata de comp...   \n",
       "1   Olá Patricia,  \\n Concordo com sua colocação ...   \n",
       "2   O comportamento do profissional dentro da emp...   \n",
       "3        \\n  Em um primeiro momento o comportamen...   \n",
       "4    Questões comportamentais estão relacionadas ...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [Em, minha, opinião, que, quando, se, trata, d...   \n",
       "1  [Olá, Patricia, ,, Concordo, com, sua, colocaç...   \n",
       "2  [O, comportamento, do, profissional, dentro, d...   \n",
       "3  [Em, um, primeiro, momento, o, comportamento, ...   \n",
       "4  [Questões, comportamentais, estão, relacionada...   \n",
       "\n",
       "                                            nlp_text  \n",
       "0  (Em, minha, opinião, que, quando, se, trata, d...  \n",
       "1  (Olá, Patricia, ,, Concordo, com, sua, colocaç...  \n",
       "2  (O, comportamento, do, profissional, dentro, d...  \n",
       "3  (Em, um, primeiro, momento, o, comportamento, ...  \n",
       "4  (Questões, comportamentais, estão, relacionada...  "
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essay_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Character counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "essay_df['chr_cnt'] = essay_df.apply(lambda r: len(r['text']), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Token counts (including stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "essay_df['token_cnt'] = essay_df.apply(lambda r: len(r['tokens']), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Token counts (excluding stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('portuguese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "essay_df['tokens_fld'] = essay_df.apply(lambda r: [w.lower() for w in r['tokens'] \n",
    "                                                   if w not in stopwords and not w.isnumeric() and len(w) > 1], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "essay_df['token_cnt_fld'] = essay_df.apply(lambda r: len(r['tokens_fld']), axis = 1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of sentences and number of sentences longer than 250 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "essay_df['sentences'] = essay_df.apply(lambda r: nltk.sent_tokenize(r['text']), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "essay_df['sent_cnt'] = essay_df.apply(lambda r: len(r['sentences']), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "essay_df['long_sent_cnt'] = essay_df.apply(lambda r: len([s for s in r['sentences'] if len(s) > 250]), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Average length (# of tokens) of sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "essay_df['avg_sent_len'] = essay_df.apply(lambda r: float(r['token_cnt'] / r['sent_cnt']), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of words  that appear both in the question and the essay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "question_token = set([w.lower() for w in nltk.wordpunct_tokenize(question) \n",
    "                      if w not in stopwords and not w.isnumeric() and len(w) > 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "essay_df['question_tokens'] = essay_df.apply(lambda r: len(set(r['tokens_fld']).intersection(question_token)), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "essay_df['pass'] = np.where(essay_df['average_score'] >= 2, 1,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/test split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df, test_df, _, _ = train_test_split(essay_df, essay_df['pass'], test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = train_df['pass']\n",
    "z_train = train_df['average_score']\n",
    "y_test = test_df['pass']\n",
    "z_test = test_df['average_score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features from above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = ['chr_cnt', 'token_cnt', 'token_cnt_fld', 'sent_cnt', 'long_sent_cnt', 'avg_sent_len', 'question_tokens']\n",
    "X_train_1 = train_df[features].values\n",
    "X_test_1 = test_df[features].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_1lst = [X_train_1[:,i] for i in range(X_train_1.shape[1])]\n",
    "X_test_1lst = [X_test_1[:,i] for  i in range(X_test_1.shape[1])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features from POS Tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a tagger "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import floresta\n",
    "Tagger0 = nltk.DefaultTagger('n')\n",
    "def simplify_tag(t):\n",
    "    if \"+\" in t:\n",
    "        return t[t.index(\"+\")+1:]\n",
    "    else:\n",
    "        return t\n",
    "tsents = [[(w.lower(),simplify_tag(t)) for (w,t) in sent] for sent in floresta.tagged_sents() if sent]\n",
    "Tagger1 = nltk.UnigramTagger(tsents, backoff=Tagger0)\n",
    "Tagger2 = nltk.BigramTagger(tsents, backoff=Tagger1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add unigram and bigram pos tag features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_unigram = set()\n",
    "all_bigram = set()\n",
    "train_unigrams = []\n",
    "train_bigrams = []\n",
    "for sents in train_df.sentences:\n",
    "    tui = {}\n",
    "    tbi = {}\n",
    "    for sent in sents:\n",
    "        tsent = Tagger2.tag(nltk.word_tokenize(sent))\n",
    "        for i in range(len(tsent) - 1):\n",
    "            t0 = tsent[i][1]\n",
    "            t1 = tsent[i+1][1]\n",
    "            all_unigram.add(t0)\n",
    "            all_bigram.add((t0, t1))\n",
    "            tui[t0] = tui[t0] + 1 if t0 in tui else 1\n",
    "            tbi[(t0, t1)] = tbi[(t0, t1)] + 1 if (t0, t1) in tbi else 1\n",
    "        t0 = tsent[len(tsent) - 1][1]\n",
    "        all_unigram.add(t0)\n",
    "        tui[t0] = tui[t0] + 1 if t0 in tui else 1\n",
    "    train_unigrams.append(tui)\n",
    "    train_bigrams.append(tbi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only keep those tag grams appear in at least 5 documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "L = 5\n",
    "use_cnt = [(x, sum(x in tu for tu in train_unigrams)) for x in all_unigram]\n",
    "use_unigram = set([x for (x,y) in use_cnt if y >L])\n",
    "use_cnt = [(x, sum(x in tb for tb in train_bigrams)) for x in all_bigram]\n",
    "use_bigram = set([x for (x,y) in use_cnt if y >L])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pos tag features of test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_unigrams = []\n",
    "test_bigrams = []\n",
    "for sents in test_df.sentences:\n",
    "    tui = {}\n",
    "    tbi = {}\n",
    "    for sent in sents:\n",
    "        tsent = Tagger2.tag(nltk.word_tokenize(sent))\n",
    "        for i in range(len(tsent) - 1):\n",
    "            t0 = tsent[i][1]\n",
    "            t1 = tsent[i+1][1]\n",
    "            if t0 in use_unigram:\n",
    "                tui[t0] = tui[t0] + 1 if t0 in tui else 1\n",
    "            if (t0, t1) in use_bigram:\n",
    "                tbi[(t0, t1)] = tbi[(t0, t1)] + 1 if (t0, t1) in tbi else 1\n",
    "        t0 = tsent[len(tsent) - 1][1]\n",
    "        if t0 in use_unigram:\n",
    "            tui[t0] = tui[t0] + 1 if t0 in tui else 1\n",
    "    test_unigrams.append(tui)\n",
    "    test_bigrams.append(tbi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### unigram pos tag features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_unigram0 = [{u: tu[u] if u in tu else 0 for u in use_unigram} for tu in train_unigrams]\n",
    "\n",
    "train_uni_mat = pd.DataFrame(train_unigram0).values\n",
    "\n",
    "test_unigram0 = [{u: tu[u] if u in tu else 0 for u in use_unigram} for tu in test_unigrams]\n",
    "\n",
    "test_uni_mat = pd.DataFrame(test_unigram0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_2 = train_uni_mat\n",
    "X_test_2 = test_uni_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### bigram pos tag features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_bigram0 = [{u: tu[u] if u in tu else 0 for u in use_bigram} for tu in train_bigrams]\n",
    "\n",
    "train_bi_mat = pd.DataFrame(train_bigram0).values\n",
    "\n",
    "test_bigram0 = [{u: tu[u] if u in tu else 0 for u in use_bigram} for tu in test_bigrams]\n",
    "\n",
    "test_bi_mat = pd.DataFrame(test_bigram0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_3 = train_bi_mat\n",
    "X_test_3 = test_bi_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create term-document matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_text = np.array(train_df['text'])\n",
    "test_text = np.array(test_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count vector  ignoring tokens with doc-frequency < 5 and excluding stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vect = CountVectorizer(min_df=5, stop_words = stopwords).fit(train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_4 = vect.transform(train_text)\n",
    "X_test_4 = vect.transform(test_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tfidf ignoring tokens with doc-frequency < 5 and excluding stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer(min_df=5, stop_words=stopwords).fit(train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_5 = vect.transform(train_text)\n",
    "X_test_5 = vect.transform(test_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_123 = np.concatenate((X_train_1, X_train_2, X_train_3), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_123 = np.concatenate((X_test_1, X_test_2, X_test_3), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(X_train_1)\n",
    "X_train_1n = scaler.transform(X_train_1)\n",
    "X_test_1n = scaler.transform(X_test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(X_train_123)\n",
    "X_train_123n = scaler.transform(X_train_123)\n",
    "X_test_123n = scaler.transform(X_test_123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_feature(X, feature_to_add):\n",
    "    \"\"\"\n",
    "    Returns sparse feature matrix with added feature.\n",
    "    feature_to_add can also be a list of features.\n",
    "    \"\"\"\n",
    "    from scipy.sparse import csr_matrix, hstack\n",
    "    return hstack([X, csr_matrix(feature_to_add).T], 'csr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_1lst = [X_train_1[:,i] for i in range(X_train_1n.shape[1])]\n",
    "X_test_1lst = [X_test_1[:,i] for  i in range(X_test_1n.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_14 = add_feature(X_train_4, X_train_1lst)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_14 = add_feature(X_test_4, X_test_1lst)\n",
    "X_train_15 = add_feature(X_train_5, X_train_1lst)\n",
    "X_test_15 = add_feature(X_test_5, X_test_1lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try some basic models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### constant model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn`.metrics import accuracy_score, mean_squared_error, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.916666666667\n",
      "0.288675134595\n"
     ]
    }
   ],
   "source": [
    "z_predict_b = np.ones(y_test.shape[0])*2.5\n",
    "y_predict_b = np.ones(y_test.shape[0])\n",
    "print accuracy_score(y_test, y_predict_b)\n",
    "print np.sqrt(mean_squared_error(y_test, y_predict_b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression(class_weight={1:1.0, 0:3.8}, C=100.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### use feature set 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_result(y_true, y_predict):\n",
    "    print accuracy_score(y_true, y_predict)\n",
    "    print f1_score(y_true, y_predict)\n",
    "    print confusion_matrix(y_true, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.906666666667\n",
      "0.951048951049\n",
      "[[  0  25]\n",
      " [  3 272]]\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train_1n, y_train)\n",
    "predictions1 = model.predict(X_test_1n)\n",
    "check_result(y_test, predictions1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### use feature set 123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression(class_weight={1:1.0, 0:2}, C=1000.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n",
      "0.854932301741\n",
      "[[  4  21]\n",
      " [ 54 221]]\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train_123n, y_train)\n",
    "predictions2 = model.predict(X_test_123n)\n",
    "check_result(y_test, predictions2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### use feature set X4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [1009, 700]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-293-9e94e5739669>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mpredictions3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mcheck_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictions3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\alin\\envs\\datascience\\lib\\site-packages\\sklearn\\linear_model\\logistic.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1173\u001b[0m         X, y = check_X_y(X, y, accept_sparse='csr', dtype=np.float64,\n\u001b[1;32m-> 1174\u001b[1;33m                          order=\"C\")\n\u001b[0m\u001b[0;32m   1175\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1176\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\alin\\envs\\datascience\\lib\\site-packages\\sklearn\\utils\\validation.pyc\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    529\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 531\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    532\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\alin\\envs\\datascience\\lib\\site-packages\\sklearn\\utils\\validation.pyc\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    179\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[1;32m--> 181\u001b[1;33m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[0;32m    182\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [1009, 700]"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(class_weight={1:1.0, 0:5}, C=1000.0)\n",
    "model.fit(X_train_4, y_train)\n",
    "predictions3 = model.predict(X_test_4)\n",
    "check_result(y_test, predictions3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### use feature set X5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.833718244804\n",
      "0.908163265306\n",
      "[[  5  47]\n",
      " [ 25 356]]\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(class_weight={1:1.0, 0:1}, C=1000.0)\n",
    "model.fit(X_train_5, y_train)\n",
    "predictions3 = model.predict(X_test_5)\n",
    "check_result(y_test, predictions3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### use feature set X14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.817551963048\n",
      "0.897001303781\n",
      "[[ 10  42]\n",
      " [ 37 344]]\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(class_weight={1:1.0, 0:1}, C=1000.0)\n",
    "model.fit(X_train_14, y_train)\n",
    "predictions4 = model.predict(X_test_14)\n",
    "check_result(y_test, predictions4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### use feature set X15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.826789838337\n",
      "0.903969270166\n",
      "[[  5  47]\n",
      " [ 28 353]]\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(class_weight={1:1.0, 0:2.5}, C=1000.0)\n",
    "model.fit(X_train_15, y_train)\n",
    "predictions5 = model.predict(X_test_15)\n",
    "check_result(y_test, predictions5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### use feature set 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.913333333333\n",
      "0.954703832753\n",
      "[[  0  25]\n",
      " [  1 274]]\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=500, class_weight = {1:1, 0:20})\n",
    "model.fit(X_train_1n, y_train)\n",
    "predictions6 = model.predict(X_test_1n)\n",
    "check_result(y_test, predictions6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.336921536452\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestRegressor(n_estimators=500)\n",
    "model.fit(X_train_1n, z_train)\n",
    "pred = model.predict(X_test_1n)\n",
    "print np.sqrt(mean_squared_error(z_test, pred))\n",
    "\n",
    "#check_result(y_test, predictions6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.849884526559\n",
      "0.917825537295\n",
      "[[  5  47]\n",
      " [ 18 363]]\n"
     ]
    }
   ],
   "source": [
    "predictions7 = np.array([1 if x >= 2 else 0 for x in pred])\n",
    "check_result(y_test, predictions7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use feature set 123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.879907621247\n",
      "0.936117936118\n",
      "[[  0  52]\n",
      " [  0 381]]\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=500, class_weight = {1:1, 0:10})\n",
    "model.fit(X_train_123n, y_train)\n",
    "predictions8 = model.predict(X_test_123n)\n",
    "check_result(y_test, predictions8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.356999391385\n",
      "0.879907621247\n",
      "0.936117936118\n",
      "[[  0  52]\n",
      " [  0 381]]\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestRegressor(n_estimators=500)\n",
    "model.fit(X_train_123n, z_train)\n",
    "pred = model.predict(X_test_123n)\n",
    "print np.sqrt(mean_squared_error(z_test, pred))\n",
    "predictions8 = np.array([1 if x >= 2 else 0 for x in pred])\n",
    "check_result(y_test, predictions8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### use feature 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.877598152425\n",
      "0.934648581998\n",
      "[[  1  51]\n",
      " [  2 379]]\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=500, class_weight = {1:1, 0:10})\n",
    "model.fit(X_train_14, y_train)\n",
    "predictions9 = model.predict(X_test_14)\n",
    "check_result(y_test, predictions9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.365751545531\n",
      "0.877598152425\n",
      "0.934809348093\n",
      "[[  0  52]\n",
      " [  1 380]]\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestRegressor(n_estimators=500)\n",
    "model.fit(X_train_14, z_train)\n",
    "pred = model.predict(X_test_14)\n",
    "print np.sqrt(mean_squared_error(z_test, pred))\n",
    "predictions10 = np.array([1 if x >= 2 else 0 for x in pred])\n",
    "check_result(y_test, predictions10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### use feature 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.875288683603\n",
      "0.933497536946\n",
      "[[  0  52]\n",
      " [  2 379]]\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=500, class_weight = {1:1, 0:10})\n",
    "model.fit(X_train_15, y_train)\n",
    "predictions11 = model.predict(X_test_15)\n",
    "check_result(y_test, predictions11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.357219999833\n",
      "0.863741339492\n",
      "0.926889714994\n",
      "[[  0  52]\n",
      " [  7 374]]\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestRegressor(n_estimators=500)\n",
    "model.fit(X_train_15, z_train)\n",
    "pred = model.predict(X_test_15)\n",
    "print np.sqrt(mean_squared_error(z_test, pred))\n",
    "predictions12 = np.array([1 if x >= 2 else 0 for x in pred])\n",
    "check_result(y_test, predictions12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import h2o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321. connected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime:</td>\n",
       "<td>2 mins 33 secs</td></tr>\n",
       "<tr><td>H2O cluster version:</td>\n",
       "<td>3.10.5.4</td></tr>\n",
       "<tr><td>H2O cluster version age:</td>\n",
       "<td>1 month and 1 day </td></tr>\n",
       "<tr><td>H2O cluster name:</td>\n",
       "<td>alin</td></tr>\n",
       "<tr><td>H2O cluster total nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster free memory:</td>\n",
       "<td>3.538 Gb</td></tr>\n",
       "<tr><td>H2O cluster total cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O cluster allowed cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O cluster status:</td>\n",
       "<td>accepting new members, healthy</td></tr>\n",
       "<tr><td>H2O connection url:</td>\n",
       "<td>http://localhost:54321</td></tr>\n",
       "<tr><td>H2O connection proxy:</td>\n",
       "<td>None</td></tr>\n",
       "<tr><td>H2O internal security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>Python version:</td>\n",
       "<td>2.7.11 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ------------------------------\n",
       "H2O cluster uptime:         2 mins 33 secs\n",
       "H2O cluster version:        3.10.5.4\n",
       "H2O cluster version age:    1 month and 1 day\n",
       "H2O cluster name:           alin\n",
       "H2O cluster total nodes:    1\n",
       "H2O cluster free memory:    3.538 Gb\n",
       "H2O cluster total cores:    4\n",
       "H2O cluster allowed cores:  4\n",
       "H2O cluster status:         accepting new members, healthy\n",
       "H2O connection url:         http://localhost:54321\n",
       "H2O connection proxy:\n",
       "H2O internal security:      False\n",
       "Python version:             2.7.11 final\n",
       "--------------------------  ------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h2o.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use feature set 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from h2o.estimators.gbm import H2OGradientBoostingEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train0 = y_train.reshape(y_train.shape[0],1)\n",
    "z_train0 = z_train.reshape(z_train.shape[0],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "gbm Model Build progress: |███████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "gbm prediction progress: |████████████████████████████████████████████████| 100%\n",
      "0.875288683603\n",
      "0.933497536946\n",
      "[[  0  52]\n",
      " [  2 379]]\n"
     ]
    }
   ],
   "source": [
    "train = np.concatenate((X_train_1n, y_train0), axis = 1)\n",
    "train_hex = h2o.H2OFrame(train)\n",
    "gbm = H2OGradientBoostingEstimator()\n",
    "gbm.train(x = range(train.shape[1]-1), y = train.shape[1]-1, training_frame=train_hex)\n",
    "\n",
    "test_hex = h2o.H2OFrame(X_test_1n)\n",
    "\n",
    "pred = gbm.predict(test_hex)\n",
    "\n",
    "pred1 = np.array([pred[i, 0] for i in range(y_test.shape[0])])\n",
    "\n",
    "predictions13 = [1 if x > 0.5 else 0 for x in pred1]\n",
    "check_result(y_test, predictions13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "gbm Model Build progress: |███████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "gbm prediction progress: |████████████████████████████████████████████████| 100%\n",
      "0.363471146243\n",
      "0.866050808314\n",
      "0.928217821782\n",
      "[[  0  52]\n",
      " [  6 375]]\n"
     ]
    }
   ],
   "source": [
    "train = np.concatenate((X_train_1n, z_train0), axis = 1)\n",
    "train_hex = h2o.H2OFrame(train)\n",
    "gbm = H2OGradientBoostingEstimator()\n",
    "gbm.train(x = range(train.shape[1]-1), y = train.shape[1]-1, training_frame=train_hex)\n",
    "\n",
    "test_hex = h2o.H2OFrame(X_test_1n)\n",
    "\n",
    "pred = gbm.predict(test_hex)\n",
    "\n",
    "pred1 = np.array([pred[i, 0] for i in range(y_test.shape[0])])\n",
    "print np.sqrt(mean_squared_error(z_test, pred1))\n",
    "predictions14 = [1 if x >= 2 else 0 for x in pred1]\n",
    "check_result(y_test, predictions14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use feature 123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "gbm Model Build progress: |███████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "gbm prediction progress: |████████████████████████████████████████████████| 100%\n",
      "0.879907621247\n",
      "0.936117936118\n",
      "[[  0  52]\n",
      " [  0 381]]\n"
     ]
    }
   ],
   "source": [
    "train = np.concatenate((X_train_123n, y_train0), axis = 1)\n",
    "train_hex = h2o.H2OFrame(train)\n",
    "gbm = H2OGradientBoostingEstimator()\n",
    "gbm.train(x = range(train.shape[1]-1), y = train.shape[1]-1, training_frame=train_hex)\n",
    "\n",
    "test_hex = h2o.H2OFrame(X_test_123n)\n",
    "\n",
    "pred = gbm.predict(test_hex)\n",
    "\n",
    "pred1 = np.array([pred[i, 0] for i in range(y_test.shape[0])])\n",
    "\n",
    "predictions15 = [1 if x > 0.5 else 0 for x in pred1]\n",
    "check_result(y_test, predictions15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "gbm Model Build progress: |███████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "gbm prediction progress: |████████████████████████████████████████████████| 100%\n",
      "0.376590871913\n",
      "0.854503464203\n",
      "0.92095357591\n",
      "[[  3  49]\n",
      " [ 14 367]]\n"
     ]
    }
   ],
   "source": [
    "train = np.concatenate((X_train_123n, z_train0), axis = 1)\n",
    "train_hex = h2o.H2OFrame(train)\n",
    "gbm = H2OGradientBoostingEstimator()\n",
    "gbm.train(x = range(train.shape[1]-1), y = train.shape[1]-1, training_frame=train_hex)\n",
    "\n",
    "test_hex = h2o.H2OFrame(X_test_123n)\n",
    "\n",
    "pred = gbm.predict(test_hex)\n",
    "\n",
    "pred1 = np.array([pred[i, 0] for i in range(y_test.shape[0])])\n",
    "print np.sqrt(mean_squared_error(z_test, pred1))\n",
    "predictions16 = [1 if x >= 2 else 0 for x in pred1]\n",
    "check_result(y_test, predictions16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use feature 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_4a = X_train_4.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_4a = X_test_4.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "gbm Model Build progress: |███████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "gbm prediction progress: |████████████████████████████████████████████████| 100%\n",
      "0.877598152425\n",
      "0.934809348093\n",
      "[[  0  52]\n",
      " [  1 380]]\n"
     ]
    }
   ],
   "source": [
    "train = np.concatenate((X_train_4a, y_train0), axis = 1)\n",
    "train_hex = h2o.H2OFrame(train)\n",
    "gbm = H2OGradientBoostingEstimator()\n",
    "gbm.train(x = range(train.shape[1]-1), y = train.shape[1]-1, training_frame=train_hex)\n",
    "\n",
    "test_hex = h2o.H2OFrame(X_test_4a)\n",
    "\n",
    "pred = gbm.predict(test_hex)\n",
    "\n",
    "pred1 = np.array([pred[i, 0] for i in range(y_test.shape[0])])\n",
    "\n",
    "predictions16 = [1 if x > 0.5 else 0 for x in pred1]\n",
    "check_result(y_test, predictions16)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
