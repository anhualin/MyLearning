{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project we explore how to use basic natural languate processing and machine learning techniques to automatically grade essays (AES) in Brazilian Portuguese. In general, AES is a very difficult problem even in English. The available tools that can be used for Portuguese are even less. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%qtconsole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Essay Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "question = pd.read_excel(io=\"C:/Users/alin/Documents/ORAnalytics/AES/data/Brazil_essay.xlsx\", sheetname=\"Essay Question\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "question = question.Original[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conforme apresentado no vídeo da Revista Exame, o comportamento é muito importante no trabalho, nas organizações. Em sua opinião, o comportamento é responsabilidade da própria pessoa ou da empresa em que trabalha? O que as organizações podem fazer para ajudar seus colaboradores a desenvolverem comportamentos melhores e mais adequados às necessidades do trabalho?\n"
     ]
    }
   ],
   "source": [
    "print question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Essays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "essay_df = pd.read_excel(io=\"C:/Users/alin/Documents/ORAnalytics/AES/data/Brazil_essay.xlsx\", sheetname=\"result\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "essay_df.columns = essay_df.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>pk1</th>\n",
       "      <th>title</th>\n",
       "      <th>average_score</th>\n",
       "      <th>resposta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.071078</td>\n",
       "      <td>2500</td>\n",
       "      <td>ATIVIDADE 1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>&lt;p&gt; Em minha opinião que quando se trata de co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.081038</td>\n",
       "      <td>4817</td>\n",
       "      <td>ATIVIDADE 1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>&lt;p&gt;Olá Patricia,&lt;/p&gt; \\n&lt;p&gt;Concordo com sua col...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.081924</td>\n",
       "      <td>7253</td>\n",
       "      <td>ATIVIDADE 1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>&lt;p&gt;O comportamento do profissional dentro da e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.091905</td>\n",
       "      <td>11815</td>\n",
       "      <td>ATIVIDADE 1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>&lt;p&gt;&lt;span style=\"font-family: georgia , palatin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.101049</td>\n",
       "      <td>704153</td>\n",
       "      <td>ATIVIDADE 1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>&lt;p&gt;&lt;span style=\"font-size: 10.0pt;font-family:...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id     pk1        title  average_score  \\\n",
       "0  1.071078    2500  ATIVIDADE 1            2.5   \n",
       "1  1.081038    4817  ATIVIDADE 1            2.5   \n",
       "2  1.081924    7253  ATIVIDADE 1            2.5   \n",
       "3  1.091905   11815  ATIVIDADE 1            2.5   \n",
       "4  1.101049  704153  ATIVIDADE 1            1.5   \n",
       "\n",
       "                                            resposta  \n",
       "0  <p> Em minha opinião que quando se trata de co...  \n",
       "1  <p>Olá Patricia,</p> \\n<p>Concordo com sua col...  \n",
       "2  <p>O comportamento do profissional dentro da e...  \n",
       "3  <p><span style=\"font-family: georgia , palatin...  \n",
       "4  <p><span style=\"font-size: 10.0pt;font-family:...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essay_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count # of paragraphs and remove html tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "essay_df['paragraphs'] = essay_df.apply(lambda r: len(re.findall(r'<p', r['resposta'])), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "essay_df['text'] = essay_df.apply(lambda r: re.sub(r'<[^<>]*>', ' ', r['resposta']), axis = 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>pk1</th>\n",
       "      <th>title</th>\n",
       "      <th>average_score</th>\n",
       "      <th>resposta</th>\n",
       "      <th>paragraphs</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.071078</td>\n",
       "      <td>2500</td>\n",
       "      <td>ATIVIDADE 1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>&lt;p&gt; Em minha opinião que quando se trata de co...</td>\n",
       "      <td>6</td>\n",
       "      <td>Em minha opinião que quando se trata de comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.081038</td>\n",
       "      <td>4817</td>\n",
       "      <td>ATIVIDADE 1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>&lt;p&gt;Olá Patricia,&lt;/p&gt; \\n&lt;p&gt;Concordo com sua col...</td>\n",
       "      <td>4</td>\n",
       "      <td>Olá Patricia,  \\n Concordo com sua colocação ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.081924</td>\n",
       "      <td>7253</td>\n",
       "      <td>ATIVIDADE 1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>&lt;p&gt;O comportamento do profissional dentro da e...</td>\n",
       "      <td>2</td>\n",
       "      <td>O comportamento do profissional dentro da emp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.091905</td>\n",
       "      <td>11815</td>\n",
       "      <td>ATIVIDADE 1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>&lt;p&gt;&lt;span style=\"font-family: georgia , palatin...</td>\n",
       "      <td>4</td>\n",
       "      <td>\\n  Em um primeiro momento o comportamen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.101049</td>\n",
       "      <td>704153</td>\n",
       "      <td>ATIVIDADE 1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>&lt;p&gt;&lt;span style=\"font-size: 10.0pt;font-family:...</td>\n",
       "      <td>2</td>\n",
       "      <td>Questões comportamentais estão relacionadas ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id     pk1        title  average_score  \\\n",
       "0  1.071078    2500  ATIVIDADE 1            2.5   \n",
       "1  1.081038    4817  ATIVIDADE 1            2.5   \n",
       "2  1.081924    7253  ATIVIDADE 1            2.5   \n",
       "3  1.091905   11815  ATIVIDADE 1            2.5   \n",
       "4  1.101049  704153  ATIVIDADE 1            1.5   \n",
       "\n",
       "                                            resposta  paragraphs  \\\n",
       "0  <p> Em minha opinião que quando se trata de co...           6   \n",
       "1  <p>Olá Patricia,</p> \\n<p>Concordo com sua col...           4   \n",
       "2  <p>O comportamento do profissional dentro da e...           2   \n",
       "3  <p><span style=\"font-family: georgia , palatin...           4   \n",
       "4  <p><span style=\"font-size: 10.0pt;font-family:...           2   \n",
       "\n",
       "                                                text  \n",
       "0    Em minha opinião que quando se trata de comp...  \n",
       "1   Olá Patricia,  \\n Concordo com sua colocação ...  \n",
       "2   O comportamento do profissional dentro da emp...  \n",
       "3        \\n  Em um primeiro momento o comportamen...  \n",
       "4    Questões comportamentais estão relacionadas ...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essay_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create some basic features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "essay_df['tokens'] = essay_df.apply(lambda r: nltk.wordpunct_tokenize(r['text']), axis = 1)\n",
    "essay_df['nlp_text'] = essay_df.apply(lambda r: nltk.Text(r['tokens']), axis = 1) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>pk1</th>\n",
       "      <th>title</th>\n",
       "      <th>average_score</th>\n",
       "      <th>resposta</th>\n",
       "      <th>paragraphs</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>nlp_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.071078</td>\n",
       "      <td>2500</td>\n",
       "      <td>ATIVIDADE 1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>&lt;p&gt; Em minha opinião que quando se trata de co...</td>\n",
       "      <td>6</td>\n",
       "      <td>Em minha opinião que quando se trata de comp...</td>\n",
       "      <td>[Em, minha, opinião, que, quando, se, trata, d...</td>\n",
       "      <td>(Em, minha, opinião, que, quando, se, trata, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.081038</td>\n",
       "      <td>4817</td>\n",
       "      <td>ATIVIDADE 1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>&lt;p&gt;Olá Patricia,&lt;/p&gt; \\n&lt;p&gt;Concordo com sua col...</td>\n",
       "      <td>4</td>\n",
       "      <td>Olá Patricia,  \\n Concordo com sua colocação ...</td>\n",
       "      <td>[Olá, Patricia, ,, Concordo, com, sua, colocaç...</td>\n",
       "      <td>(Olá, Patricia, ,, Concordo, com, sua, colocaç...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.081924</td>\n",
       "      <td>7253</td>\n",
       "      <td>ATIVIDADE 1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>&lt;p&gt;O comportamento do profissional dentro da e...</td>\n",
       "      <td>2</td>\n",
       "      <td>O comportamento do profissional dentro da emp...</td>\n",
       "      <td>[O, comportamento, do, profissional, dentro, d...</td>\n",
       "      <td>(O, comportamento, do, profissional, dentro, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.091905</td>\n",
       "      <td>11815</td>\n",
       "      <td>ATIVIDADE 1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>&lt;p&gt;&lt;span style=\"font-family: georgia , palatin...</td>\n",
       "      <td>4</td>\n",
       "      <td>\\n  Em um primeiro momento o comportamen...</td>\n",
       "      <td>[Em, um, primeiro, momento, o, comportamento, ...</td>\n",
       "      <td>(Em, um, primeiro, momento, o, comportamento, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.101049</td>\n",
       "      <td>704153</td>\n",
       "      <td>ATIVIDADE 1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>&lt;p&gt;&lt;span style=\"font-size: 10.0pt;font-family:...</td>\n",
       "      <td>2</td>\n",
       "      <td>Questões comportamentais estão relacionadas ...</td>\n",
       "      <td>[Questões, comportamentais, estão, relacionada...</td>\n",
       "      <td>(Questões, comportamentais, estão, relacionada...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id     pk1        title  average_score  \\\n",
       "0  1.071078    2500  ATIVIDADE 1            2.5   \n",
       "1  1.081038    4817  ATIVIDADE 1            2.5   \n",
       "2  1.081924    7253  ATIVIDADE 1            2.5   \n",
       "3  1.091905   11815  ATIVIDADE 1            2.5   \n",
       "4  1.101049  704153  ATIVIDADE 1            1.5   \n",
       "\n",
       "                                            resposta  paragraphs  \\\n",
       "0  <p> Em minha opinião que quando se trata de co...           6   \n",
       "1  <p>Olá Patricia,</p> \\n<p>Concordo com sua col...           4   \n",
       "2  <p>O comportamento do profissional dentro da e...           2   \n",
       "3  <p><span style=\"font-family: georgia , palatin...           4   \n",
       "4  <p><span style=\"font-size: 10.0pt;font-family:...           2   \n",
       "\n",
       "                                                text  \\\n",
       "0    Em minha opinião que quando se trata de comp...   \n",
       "1   Olá Patricia,  \\n Concordo com sua colocação ...   \n",
       "2   O comportamento do profissional dentro da emp...   \n",
       "3        \\n  Em um primeiro momento o comportamen...   \n",
       "4    Questões comportamentais estão relacionadas ...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [Em, minha, opinião, que, quando, se, trata, d...   \n",
       "1  [Olá, Patricia, ,, Concordo, com, sua, colocaç...   \n",
       "2  [O, comportamento, do, profissional, dentro, d...   \n",
       "3  [Em, um, primeiro, momento, o, comportamento, ...   \n",
       "4  [Questões, comportamentais, estão, relacionada...   \n",
       "\n",
       "                                            nlp_text  \n",
       "0  (Em, minha, opinião, que, quando, se, trata, d...  \n",
       "1  (Olá, Patricia, ,, Concordo, com, sua, colocaç...  \n",
       "2  (O, comportamento, do, profissional, dentro, d...  \n",
       "3  (Em, um, primeiro, momento, o, comportamento, ...  \n",
       "4  (Questões, comportamentais, estão, relacionada...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essay_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Character counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "essay_df['chr_cnt'] = essay_df.apply(lambda r: len(r['text']), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Token counts (including stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "essay_df['token_cnt'] = essay_df.apply(lambda r: len(r['tokens']), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Token counts (excluding stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('portuguese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "essay_df['tokens_fld'] = essay_df.apply(lambda r: [w.lower() for w in r['tokens'] \n",
    "                                                   if w not in stopwords and not w.isnumeric() and len(w) > 1], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "essay_df['token_cnt_fld'] = essay_df.apply(lambda r: len(r['tokens_fld']), axis = 1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of sentences and number of sentences longer than 250 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "essay_df['sentences'] = essay_df.apply(lambda r: nltk.sent_tokenize(r['text']), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "essay_df['sent_cnt'] = essay_df.apply(lambda r: len(r['sentences']), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "essay_df['long_sent_cnt'] = essay_df.apply(lambda r: len([s for s in r['sentences'] if len(s) > 250]), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Average length (# of tokens) of sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "essay_df['avg_sent_len'] = essay_df.apply(lambda r: float(r['token_cnt'] / r['sent_cnt']), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of words  that appear both in the question and the essay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "question_token = set([w.lower() for w in nltk.wordpunct_tokenize(question) \n",
    "                      if w not in stopwords and not w.isnumeric() and len(w) > 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "essay_df['question_tokens'] = essay_df.apply(lambda r: len(set(r['tokens_fld']).intersection(question_token)), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "essay_df['pass'] = np.where(essay_df['average_score'] >= 2, 1,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/test split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df, test_df, _, _ = train_test_split(essay_df, essay_df['pass'], test_size = 0.3, random_state = 2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = train_df['pass']\n",
    "z_train = train_df['average_score']\n",
    "y_test = test_df['pass']\n",
    "z_test = test_df['average_score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features from above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = ['chr_cnt', 'token_cnt', 'token_cnt_fld', 'sent_cnt', 'long_sent_cnt', 'avg_sent_len', 'question_tokens']\n",
    "X_train_1 = train_df[features].values\n",
    "X_test_1 = test_df[features].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_1lst = [X_train_1[:,i] for i in range(X_train_1.shape[1])]\n",
    "X_test_1lst = [X_test_1[:,i] for  i in range(X_test_1.shape[1])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features from POS Tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a tagger "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import floresta\n",
    "Tagger0 = nltk.DefaultTagger('n')\n",
    "def simplify_tag(t):\n",
    "    if \"+\" in t:\n",
    "        return t[t.index(\"+\")+1:]\n",
    "    else:\n",
    "        return t\n",
    "tsents = [[(w.lower(),simplify_tag(t)) for (w,t) in sent] for sent in floresta.tagged_sents() if sent]\n",
    "Tagger1 = nltk.UnigramTagger(tsents, backoff=Tagger0)\n",
    "Tagger2 = nltk.BigramTagger(tsents, backoff=Tagger1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add unigram and bigram pos tag features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_unigram = set()\n",
    "all_bigram = set()\n",
    "train_unigrams = []\n",
    "train_bigrams = []\n",
    "for sents in train_df.sentences:\n",
    "    tui = {}\n",
    "    tbi = {}\n",
    "    for sent in sents:\n",
    "        tsent = Tagger2.tag(nltk.word_tokenize(sent))\n",
    "        for i in range(len(tsent) - 1):\n",
    "            t0 = tsent[i][1]\n",
    "            t1 = tsent[i+1][1]\n",
    "            all_unigram.add(t0)\n",
    "            all_bigram.add((t0, t1))\n",
    "            tui[t0] = tui[t0] + 1 if t0 in tui else 1\n",
    "            tbi[(t0, t1)] = tbi[(t0, t1)] + 1 if (t0, t1) in tbi else 1\n",
    "        t0 = tsent[len(tsent) - 1][1]\n",
    "        all_unigram.add(t0)\n",
    "        tui[t0] = tui[t0] + 1 if t0 in tui else 1\n",
    "    train_unigrams.append(tui)\n",
    "    train_bigrams.append(tbi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only keep those tag grams appear in at least 5 documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "L = 5\n",
    "use_cnt = [(x, sum(x in tu for tu in train_unigrams)) for x in all_unigram]\n",
    "use_unigram = set([x for (x,y) in use_cnt if y >L])\n",
    "use_cnt = [(x, sum(x in tb for tb in train_bigrams)) for x in all_bigram]\n",
    "use_bigram = set([x for (x,y) in use_cnt if y >L])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pos tag features of test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_unigrams = []\n",
    "test_bigrams = []\n",
    "for sents in test_df.sentences:\n",
    "    tui = {}\n",
    "    tbi = {}\n",
    "    for sent in sents:\n",
    "        tsent = Tagger2.tag(nltk.word_tokenize(sent))\n",
    "        for i in range(len(tsent) - 1):\n",
    "            t0 = tsent[i][1]\n",
    "            t1 = tsent[i+1][1]\n",
    "            if t0 in use_unigram:\n",
    "                tui[t0] = tui[t0] + 1 if t0 in tui else 1\n",
    "            if (t0, t1) in use_bigram:\n",
    "                tbi[(t0, t1)] = tbi[(t0, t1)] + 1 if (t0, t1) in tbi else 1\n",
    "        t0 = tsent[len(tsent) - 1][1]\n",
    "        if t0 in use_unigram:\n",
    "            tui[t0] = tui[t0] + 1 if t0 in tui else 1\n",
    "    test_unigrams.append(tui)\n",
    "    test_bigrams.append(tbi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### unigram pos tag features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_unigram0 = [{u: tu[u] if u in tu else 0 for u in use_unigram} for tu in train_unigrams]\n",
    "\n",
    "train_uni_mat = pd.DataFrame(train_unigram0).values\n",
    "\n",
    "test_unigram0 = [{u: tu[u] if u in tu else 0 for u in use_unigram} for tu in test_unigrams]\n",
    "\n",
    "test_uni_mat = pd.DataFrame(test_unigram0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_2 = train_uni_mat\n",
    "X_test_2 = test_uni_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### bigram pos tag features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_bigram0 = [{u: tu[u] if u in tu else 0 for u in use_bigram} for tu in train_bigrams]\n",
    "\n",
    "train_bi_mat = pd.DataFrame(train_bigram0).values\n",
    "\n",
    "test_bigram0 = [{u: tu[u] if u in tu else 0 for u in use_bigram} for tu in test_bigrams]\n",
    "\n",
    "test_bi_mat = pd.DataFrame(test_bigram0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_3 = train_bi_mat\n",
    "X_test_3 = test_bi_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create term-document matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_text = np.array(train_df['text'])\n",
    "test_text = np.array(test_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count vector  ignoring tokens with doc-frequency < 5 and excluding stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vect = CountVectorizer(min_df=5, stop_words = stopwords).fit(train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_4 = vect.transform(train_text)\n",
    "X_test_4 = vect.transform(test_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tfidf ignoring tokens with doc-frequency < 5 and excluding stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer(min_df=5, stop_words=stopwords).fit(train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_5 = vect.transform(train_text)\n",
    "X_test_5 = vect.transform(test_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_123 = np.concatenate((X_train_1, X_train_2, X_train_3), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_123 = np.concatenate((X_test_1, X_test_2, X_test_3), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(X_train_1)\n",
    "X_train_1n = scaler.transform(X_train_1)\n",
    "X_test_1n = scaler.transform(X_test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(X_train_123)\n",
    "X_train_123n = scaler.transform(X_train_123)\n",
    "X_test_123n = scaler.transform(X_test_123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_feature(X, feature_to_add):\n",
    "    \"\"\"\n",
    "    Returns sparse feature matrix with added feature.\n",
    "    feature_to_add can also be a list of features.\n",
    "    \"\"\"\n",
    "    from scipy.sparse import csr_matrix, hstack\n",
    "    return hstack([X, csr_matrix(feature_to_add).T], 'csr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_1lst = [X_train_1[:,i] for i in range(X_train_1n.shape[1])]\n",
    "X_test_1lst = [X_test_1[:,i] for  i in range(X_test_1n.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_14 = add_feature(X_train_4, X_train_1lst)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_14 = add_feature(X_test_4, X_test_1lst)\n",
    "X_train_15 = add_feature(X_train_5, X_train_1lst)\n",
    "X_test_15 = add_feature(X_test_5, X_test_1lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_1235 = add_feature(X_train_5, [np.array(x) for x in X_train_123.T.tolist()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_1235 = add_feature(X_test_5, [np.array(x) for x in X_test_123.T.tolist()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try some basic models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### constant model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, mean_squared_error, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.847575057737\n",
      "0.390416370383\n"
     ]
    }
   ],
   "source": [
    "z_predict_b = np.ones(y_test.shape[0])*2.5\n",
    "y_predict_b = np.ones(y_test.shape[0])\n",
    "print accuracy_score(y_test, y_predict_b)\n",
    "print np.sqrt(mean_squared_error(y_test, y_predict_b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression(class_weight={1:1.0, 0:3.8}, C=100.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### use feature set 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_result(y_true, y_predict):\n",
    "    print accuracy_score(y_true, y_predict)\n",
    "    print f1_score(y_true, y_predict)\n",
    "    print confusion_matrix(y_true, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.812933025404\n",
      "0.892998678996\n",
      "[[ 14  52]\n",
      " [ 29 338]]\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train_1n, y_train)\n",
    "predictions1 = model.predict(X_test_1n)\n",
    "check_result(y_test, predictions1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### use feature set 123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression(class_weight={1:1.0, 0:2}, C=1000.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.732101616628\n",
      "0.843243243243\n",
      "[[  5  61]\n",
      " [ 55 312]]\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train_123n, y_train)\n",
    "predictions2 = model.predict(X_test_123n)\n",
    "check_result(y_test, predictions2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### use feature set X4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.775981524249\n",
      "0.870838881491\n",
      "[[  9  57]\n",
      " [ 40 327]]\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(class_weight={1:1.0, 0:5}, C=1000.0)\n",
    "model.fit(X_train_4, y_train)\n",
    "predictions3 = model.predict(X_test_4)\n",
    "check_result(y_test, predictions3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### use feature set X5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.789838337182\n",
      "0.881355932203\n",
      "[[  4  62]\n",
      " [ 29 338]]\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(class_weight={1:1.0, 0:1}, C=1000.0)\n",
    "model.fit(X_train_5, y_train)\n",
    "predictions3 = model.predict(X_test_5)\n",
    "check_result(y_test, predictions3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### use feature set X14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.80831408776\n",
      "0.89121887287\n",
      "[[ 10  56]\n",
      " [ 27 340]]\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(class_weight={1:1.0, 0:1}, C=1000.0)\n",
    "model.fit(X_train_14, y_train)\n",
    "predictions4 = model.predict(X_test_14)\n",
    "check_result(y_test, predictions4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### use feature set X15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.792147806005\n",
      "0.88188976378\n",
      "[[  7  59]\n",
      " [ 31 336]]\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(class_weight={1:1.0, 0:2.5}, C=1000.0)\n",
    "model.fit(X_train_15, y_train)\n",
    "predictions5 = model.predict(X_test_15)\n",
    "check_result(y_test, predictions5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### use feature set 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.838337182448\n",
      "0.911838790932\n",
      "[[  1  65]\n",
      " [  5 362]]\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=500, class_weight = {1:1, 0:20})\n",
    "model.fit(X_train_1n, y_train)\n",
    "predictions6 = model.predict(X_test_1n)\n",
    "check_result(y_test, predictions6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.402651564589\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestRegressor(n_estimators=500)\n",
    "model.fit(X_train_1n, z_train)\n",
    "pred = model.predict(X_test_1n)\n",
    "print np.sqrt(mean_squared_error(z_test, pred))\n",
    "\n",
    "#check_result(y_test, predictions6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.815242494226\n",
      "0.897698209719\n",
      "[[  2  64]\n",
      " [ 16 351]]\n"
     ]
    }
   ],
   "source": [
    "predictions7 = np.array([1 if x >= 2 else 0 for x in pred])\n",
    "check_result(y_test, predictions7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use feature set 123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.847575057737\n",
      "0.9175\n",
      "[[  0  66]\n",
      " [  0 367]]\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=500, class_weight = {1:1, 0:1})\n",
    "model.fit(X_train_123n, y_train)\n",
    "predictions8 = model.predict(X_test_123n)\n",
    "check_result(y_test, predictions8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.393703827127\n",
      "0.849884526559\n",
      "0.918648310388\n",
      "[[  1  65]\n",
      " [  0 367]]\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestRegressor(n_estimators=500)\n",
    "model.fit(X_train_123n, z_train)\n",
    "pred = model.predict(X_test_123n)\n",
    "print np.sqrt(mean_squared_error(z_test, pred))\n",
    "predictions8 = np.array([1 if x >= 2 else 0 for x in pred])\n",
    "check_result(y_test, predictions8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### use feature 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.845265588915\n",
      "0.915934755332\n",
      "[[  1  65]\n",
      " [  2 365]]\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=500, class_weight = {1:1, 0:10})\n",
    "model.fit(X_train_14, y_train)\n",
    "predictions9 = model.predict(X_test_14)\n",
    "check_result(y_test, predictions9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.407113424484\n",
      "0.847575057737\n",
      "0.9175\n",
      "[[  0  66]\n",
      " [  0 367]]\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestRegressor(n_estimators=500)\n",
    "model.fit(X_train_14, z_train)\n",
    "pred = model.predict(X_test_14)\n",
    "print np.sqrt(mean_squared_error(z_test, pred))\n",
    "predictions10 = np.array([1 if x >= 2 else 0 for x in pred])\n",
    "check_result(y_test, predictions10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### use feature 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.842956120092\n",
      "0.914141414141\n",
      "[[  3  63]\n",
      " [  5 362]]\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=500, class_weight = {1:1, 0:100})\n",
    "model.fit(X_train_15, y_train)\n",
    "predictions11 = model.predict(X_test_15)\n",
    "check_result(y_test, predictions11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.358633844767\n",
      "0.863741339492\n",
      "0.926889714994\n",
      "[[  0  52]\n",
      " [  7 374]]\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestRegressor(n_estimators=500)\n",
    "model.fit(X_train_15, z_train)\n",
    "pred = model.predict(X_test_15)\n",
    "print np.sqrt(mean_squared_error(z_test, pred))\n",
    "predictions12 = np.array([1 if x >= 2 else 0 for x in pred])\n",
    "check_result(y_test, predictions12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### use feature 1235  (use this?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.845265588915\n",
      "0.91572327044\n",
      "[[  2  64]\n",
      " [  3 364]]\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=500, class_weight = {1:1, 0:100})\n",
    "model.fit(X_train_1235, y_train)\n",
    "predictions11 = model.predict(X_test_1235)\n",
    "check_result(y_test, predictions11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output = pd.DataFrame({'prediction': predictions11, 'pk1': test_df.pk1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output.to_csv(\"C:/Users/alin/Documents/ORAnalytics/AES/data/output.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import h2o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321. connected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime:</td>\n",
       "<td>19 mins 20 secs</td></tr>\n",
       "<tr><td>H2O cluster version:</td>\n",
       "<td>3.10.5.4</td></tr>\n",
       "<tr><td>H2O cluster version age:</td>\n",
       "<td>1 month and 1 day </td></tr>\n",
       "<tr><td>H2O cluster name:</td>\n",
       "<td>alin</td></tr>\n",
       "<tr><td>H2O cluster total nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster free memory:</td>\n",
       "<td>3.538 Gb</td></tr>\n",
       "<tr><td>H2O cluster total cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O cluster allowed cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O cluster status:</td>\n",
       "<td>accepting new members, healthy</td></tr>\n",
       "<tr><td>H2O connection url:</td>\n",
       "<td>http://localhost:54321</td></tr>\n",
       "<tr><td>H2O connection proxy:</td>\n",
       "<td>None</td></tr>\n",
       "<tr><td>H2O internal security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>Python version:</td>\n",
       "<td>2.7.11 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ------------------------------\n",
       "H2O cluster uptime:         19 mins 20 secs\n",
       "H2O cluster version:        3.10.5.4\n",
       "H2O cluster version age:    1 month and 1 day\n",
       "H2O cluster name:           alin\n",
       "H2O cluster total nodes:    1\n",
       "H2O cluster free memory:    3.538 Gb\n",
       "H2O cluster total cores:    4\n",
       "H2O cluster allowed cores:  4\n",
       "H2O cluster status:         accepting new members, healthy\n",
       "H2O connection url:         http://localhost:54321\n",
       "H2O connection proxy:\n",
       "H2O internal security:      False\n",
       "Python version:             2.7.11 final\n",
       "--------------------------  ------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h2o.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use feature set 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from h2o.estimators.gbm import H2OGradientBoostingEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train0 = y_train.reshape(y_train.shape[0],1)\n",
    "z_train0 = z_train.reshape(z_train.shape[0],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "gbm Model Build progress: |███████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "gbm prediction progress: |████████████████████████████████████████████████| 100%\n",
      "0.875288683603\n",
      "0.933497536946\n",
      "[[  0  52]\n",
      " [  2 379]]\n"
     ]
    }
   ],
   "source": [
    "train = np.concatenate((X_train_1n, y_train0), axis = 1)\n",
    "train_hex = h2o.H2OFrame(train)\n",
    "gbm = H2OGradientBoostingEstimator()\n",
    "gbm.train(x = range(train.shape[1]-1), y = train.shape[1]-1, training_frame=train_hex)\n",
    "\n",
    "test_hex = h2o.H2OFrame(X_test_1n)\n",
    "\n",
    "pred = gbm.predict(test_hex)\n",
    "\n",
    "pred1 = np.array([pred[i, 0] for i in range(y_test.shape[0])])\n",
    "\n",
    "predictions13 = [1 if x > 0.5 else 0 for x in pred1]\n",
    "check_result(y_test, predictions13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "gbm Model Build progress: |███████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "gbm prediction progress: |████████████████████████████████████████████████| 100%\n",
      "0.363471146243\n",
      "0.866050808314\n",
      "0.928217821782\n",
      "[[  0  52]\n",
      " [  6 375]]\n"
     ]
    }
   ],
   "source": [
    "train = np.concatenate((X_train_1n, z_train0), axis = 1)\n",
    "train_hex = h2o.H2OFrame(train)\n",
    "gbm = H2OGradientBoostingEstimator()\n",
    "gbm.train(x = range(train.shape[1]-1), y = train.shape[1]-1, training_frame=train_hex)\n",
    "\n",
    "test_hex = h2o.H2OFrame(X_test_1n)\n",
    "\n",
    "pred = gbm.predict(test_hex)\n",
    "\n",
    "pred1 = np.array([pred[i, 0] for i in range(y_test.shape[0])])\n",
    "print np.sqrt(mean_squared_error(z_test, pred1))\n",
    "predictions14 = [1 if x >= 2 else 0 for x in pred1]\n",
    "check_result(y_test, predictions14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use feature 123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "gbm Model Build progress: |███████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "gbm prediction progress: |████████████████████████████████████████████████| 100%\n",
      "0.879907621247\n",
      "0.936117936118\n",
      "[[  0  52]\n",
      " [  0 381]]\n"
     ]
    }
   ],
   "source": [
    "train = np.concatenate((X_train_123n, y_train0), axis = 1)\n",
    "train_hex = h2o.H2OFrame(train)\n",
    "gbm = H2OGradientBoostingEstimator()\n",
    "gbm.train(x = range(train.shape[1]-1), y = train.shape[1]-1, training_frame=train_hex)\n",
    "\n",
    "test_hex = h2o.H2OFrame(X_test_123n)\n",
    "\n",
    "pred = gbm.predict(test_hex)\n",
    "\n",
    "pred1 = np.array([pred[i, 0] for i in range(y_test.shape[0])])\n",
    "\n",
    "predictions15 = [1 if x > 0.5 else 0 for x in pred1]\n",
    "check_result(y_test, predictions15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "gbm Model Build progress: |███████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "gbm prediction progress: |████████████████████████████████████████████████| 100%\n",
      "0.376590871913\n",
      "0.854503464203\n",
      "0.92095357591\n",
      "[[  3  49]\n",
      " [ 14 367]]\n"
     ]
    }
   ],
   "source": [
    "train = np.concatenate((X_train_123n, z_train0), axis = 1)\n",
    "train_hex = h2o.H2OFrame(train)\n",
    "gbm = H2OGradientBoostingEstimator()\n",
    "gbm.train(x = range(train.shape[1]-1), y = train.shape[1]-1, training_frame=train_hex)\n",
    "\n",
    "test_hex = h2o.H2OFrame(X_test_123n)\n",
    "\n",
    "pred = gbm.predict(test_hex)\n",
    "\n",
    "pred1 = np.array([pred[i, 0] for i in range(y_test.shape[0])])\n",
    "print np.sqrt(mean_squared_error(z_test, pred1))\n",
    "predictions16 = [1 if x >= 2 else 0 for x in pred1]\n",
    "check_result(y_test, predictions16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use feature 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_14a = X_train_14.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_14a = X_test_14.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "gbm Model Build progress: |███████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "gbm prediction progress: |████████████████████████████████████████████████| 100%\n",
      "0.879907621247\n",
      "0.936117936118\n",
      "[[  0  52]\n",
      " [  0 381]]\n"
     ]
    }
   ],
   "source": [
    "train = np.concatenate((X_train_14a, y_train0), axis = 1)\n",
    "train_hex = h2o.H2OFrame(train)\n",
    "gbm = H2OGradientBoostingEstimator()\n",
    "gbm.train(x = range(train.shape[1]-1), y = train.shape[1]-1, training_frame=train_hex)\n",
    "\n",
    "test_hex = h2o.H2OFrame(X_test_14a)\n",
    "\n",
    "pred = gbm.predict(test_hex)\n",
    "\n",
    "pred1 = np.array([pred[i, 0] for i in range(y_test.shape[0])])\n",
    "\n",
    "predictions16 = [1 if x > 0.5 else 0 for x in pred1]\n",
    "check_result(y_test, predictions16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from h2o.estimators.deeplearning import H2ODeepLearningEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "train = np.concatenate((X_train_14a, z_train0), axis = 1)\n",
    "train_hex = h2o.H2OFrame(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = H2ODeepLearningEstimator(distribution=\"gaussian\",\n",
    "                                 activation=\"tanh\",\n",
    "                                 hidden=[32,32,32],\n",
    "                                 input_dropout_ratio=0.2,\n",
    "                                 sparse=True,\n",
    "                                 l1=1e-5,\n",
    "                                 epochs= 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deeplearning Model Build progress: |██████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "model.train(x=range(train.shape[1]-1), y=train.shape[1]-1, training_frame=train_hex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "deeplearning prediction progress: |███████████████████████████████████████| 100%\n",
      "0.856812933025\n",
      "0.921914357683\n",
      "[[  5  47]\n",
      " [ 15 366]]\n"
     ]
    }
   ],
   "source": [
    "test_hex = h2o.H2OFrame(X_test_14a)\n",
    "\n",
    "pred = model.predict(test_hex)\n",
    "\n",
    "pred1 = np.array([pred[i, 0] for i in range(y_test.shape[0])])\n",
    "\n",
    "predictions16 = [1 if x > 2 else 0 for x in pred1]\n",
    "check_result(y_test, predictions16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output = pd.DataFrame(data = {'pred1': predictions1,  'pk1': test_df.pk1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pk1</th>\n",
       "      <th>pred1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1432</th>\n",
       "      <td>604784</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>614030</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1240</th>\n",
       "      <td>706801</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>567512</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>591678</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         pk1  pred1\n",
       "1432  604784      1\n",
       "590   614030      1\n",
       "1240  706801      1\n",
       "364   567512      1\n",
       "432   591678      1"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>pk1</th>\n",
       "      <th>title</th>\n",
       "      <th>average_score</th>\n",
       "      <th>resposta</th>\n",
       "      <th>paragraphs</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>nlp_text</th>\n",
       "      <th>chr_cnt</th>\n",
       "      <th>token_cnt</th>\n",
       "      <th>tokens_fld</th>\n",
       "      <th>token_cnt_fld</th>\n",
       "      <th>sentences</th>\n",
       "      <th>sent_cnt</th>\n",
       "      <th>long_sent_cnt</th>\n",
       "      <th>avg_sent_len</th>\n",
       "      <th>question_tokens</th>\n",
       "      <th>pass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1432</th>\n",
       "      <td>1.610127</td>\n",
       "      <td>604784</td>\n",
       "      <td>ATIVIDADE 1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>&lt;p&gt;Olá,&lt;/p&gt; \\n&lt;p&gt;Acredito que 90% da responsab...</td>\n",
       "      <td>4</td>\n",
       "      <td>Olá,  \\n Acredito que 90% da responsabilidade...</td>\n",
       "      <td>[Olá, ,, Acredito, que, 90, %, da, responsabil...</td>\n",
       "      <td>(Olá, ,, Acredito, que, 90, %, da, responsabil...</td>\n",
       "      <td>1307</td>\n",
       "      <td>223</td>\n",
       "      <td>[olá, acredito, responsabilidade, comportament...</td>\n",
       "      <td>112</td>\n",
       "      <td>[ Olá,  \\n Acredito que 90% da responsabilidad...</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>1.209834</td>\n",
       "      <td>614030</td>\n",
       "      <td>ATIVIDADE 1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>&lt;p&gt;tbm concordo com a importancia que tem a mo...</td>\n",
       "      <td>1</td>\n",
       "      <td>tbm concordo com a importancia que tem a moti...</td>\n",
       "      <td>[tbm, concordo, com, a, importancia, que, tem,...</td>\n",
       "      <td>(tbm, concordo, com, a, importancia, que, tem,...</td>\n",
       "      <td>137</td>\n",
       "      <td>26</td>\n",
       "      <td>[tbm, concordo, importancia, motivação, ambien...</td>\n",
       "      <td>10</td>\n",
       "      <td>[ tbm concordo com a importancia que tem a mot...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1240</th>\n",
       "      <td>1.210197</td>\n",
       "      <td>706801</td>\n",
       "      <td>ATIVIDADE 1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>&lt;p&gt;Podemos ver diversas empresas percebendo a ...</td>\n",
       "      <td>2</td>\n",
       "      <td>Podemos ver diversas empresas percebendo a ne...</td>\n",
       "      <td>[Podemos, ver, diversas, empresas, percebendo,...</td>\n",
       "      <td>(Podemos, ver, diversas, empresas, percebendo,...</td>\n",
       "      <td>510</td>\n",
       "      <td>86</td>\n",
       "      <td>[podemos, ver, diversas, empresas, percebendo,...</td>\n",
       "      <td>47</td>\n",
       "      <td>[ Podemos ver diversas empresas percebendo a n...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>43.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>1.209087</td>\n",
       "      <td>567512</td>\n",
       "      <td>ATIVIDADE 1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>&lt;p&gt; O comportamento é de resposanbilidade da p...</td>\n",
       "      <td>2</td>\n",
       "      <td>O comportamento é de resposanbilidade da pes...</td>\n",
       "      <td>[O, comportamento, é, de, resposanbilidade, da...</td>\n",
       "      <td>(O, comportamento, é, de, resposanbilidade, da...</td>\n",
       "      <td>530</td>\n",
       "      <td>93</td>\n",
       "      <td>[comportamento, resposanbilidade, pessoa, form...</td>\n",
       "      <td>44</td>\n",
       "      <td>[  O comportamento é de resposanbilidade da pe...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>1.209182</td>\n",
       "      <td>591678</td>\n",
       "      <td>ATIVIDADE 1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>&lt;p&gt;Na minha opinião, o comportamento é unicame...</td>\n",
       "      <td>3</td>\n",
       "      <td>Na minha opinião, o comportamento é unicament...</td>\n",
       "      <td>[Na, minha, opinião, ,, o, comportamento, é, u...</td>\n",
       "      <td>(Na, minha, opinião, ,, o, comportamento, é, u...</td>\n",
       "      <td>464</td>\n",
       "      <td>81</td>\n",
       "      <td>[na, opinião, comportamento, unicamente, respo...</td>\n",
       "      <td>35</td>\n",
       "      <td>[ Na minha opinião, o comportamento é unicamen...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id     pk1        title  average_score  \\\n",
       "1432  1.610127  604784  ATIVIDADE 1            2.5   \n",
       "590   1.209834  614030  ATIVIDADE 1            2.5   \n",
       "1240  1.210197  706801  ATIVIDADE 1            2.5   \n",
       "364   1.209087  567512  ATIVIDADE 1            2.5   \n",
       "432   1.209182  591678  ATIVIDADE 1            2.0   \n",
       "\n",
       "                                               resposta  paragraphs  \\\n",
       "1432  <p>Olá,</p> \\n<p>Acredito que 90% da responsab...           4   \n",
       "590   <p>tbm concordo com a importancia que tem a mo...           1   \n",
       "1240  <p>Podemos ver diversas empresas percebendo a ...           2   \n",
       "364   <p> O comportamento é de resposanbilidade da p...           2   \n",
       "432   <p>Na minha opinião, o comportamento é unicame...           3   \n",
       "\n",
       "                                                   text  \\\n",
       "1432   Olá,  \\n Acredito que 90% da responsabilidade...   \n",
       "590    tbm concordo com a importancia que tem a moti...   \n",
       "1240   Podemos ver diversas empresas percebendo a ne...   \n",
       "364     O comportamento é de resposanbilidade da pes...   \n",
       "432    Na minha opinião, o comportamento é unicament...   \n",
       "\n",
       "                                                 tokens  \\\n",
       "1432  [Olá, ,, Acredito, que, 90, %, da, responsabil...   \n",
       "590   [tbm, concordo, com, a, importancia, que, tem,...   \n",
       "1240  [Podemos, ver, diversas, empresas, percebendo,...   \n",
       "364   [O, comportamento, é, de, resposanbilidade, da...   \n",
       "432   [Na, minha, opinião, ,, o, comportamento, é, u...   \n",
       "\n",
       "                                               nlp_text  chr_cnt  token_cnt  \\\n",
       "1432  (Olá, ,, Acredito, que, 90, %, da, responsabil...     1307        223   \n",
       "590   (tbm, concordo, com, a, importancia, que, tem,...      137         26   \n",
       "1240  (Podemos, ver, diversas, empresas, percebendo,...      510         86   \n",
       "364   (O, comportamento, é, de, resposanbilidade, da...      530         93   \n",
       "432   (Na, minha, opinião, ,, o, comportamento, é, u...      464         81   \n",
       "\n",
       "                                             tokens_fld  token_cnt_fld  \\\n",
       "1432  [olá, acredito, responsabilidade, comportament...            112   \n",
       "590   [tbm, concordo, importancia, motivação, ambien...             10   \n",
       "1240  [podemos, ver, diversas, empresas, percebendo,...             47   \n",
       "364   [comportamento, resposanbilidade, pessoa, form...             44   \n",
       "432   [na, opinião, comportamento, unicamente, respo...             35   \n",
       "\n",
       "                                              sentences  sent_cnt  \\\n",
       "1432  [ Olá,  \\n Acredito que 90% da responsabilidad...         8   \n",
       "590   [ tbm concordo com a importancia que tem a mot...         1   \n",
       "1240  [ Podemos ver diversas empresas percebendo a n...         2   \n",
       "364   [  O comportamento é de resposanbilidade da pe...         3   \n",
       "432   [ Na minha opinião, o comportamento é unicamen...         3   \n",
       "\n",
       "      long_sent_cnt  avg_sent_len  question_tokens  pass  \n",
       "1432              1          27.0                6     1  \n",
       "590               0          26.0                1     1  \n",
       "1240              1          43.0                2     1  \n",
       "364               0          31.0                2     1  \n",
       "432               0          27.0                7     1  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
