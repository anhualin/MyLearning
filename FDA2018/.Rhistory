dtab <- setZebraStyle(dtab, odd = '#eeeeee', even = 'white')
#dtab <-  bg(dtab, bg = "#E4C994", part = "header")
#dtab <- align(dtab, align = "center", part = "all" )
doc <- addFlexTable(doc, dtab)
doc  <- addParagraph(doc,
value = c('Treatment: new students in June 2017',
'Control: new students in June 2016',
'Goal: improve second term retention',
'Not real data'
),
par.properties = parProperties(list.style = 'ordered', level = 1)
)
# Slide : Data
# +++++++++++++++++++++
doc <- addSlide(doc, "Title and Content")
doc <- addTitle(doc, "Data")
dtab <- vanilla.table(dat[1:10,c('id', xvars[1:4])])
dtab <- setZebraStyle(dtab, odd = '#eeeeee', even = 'white')
#dtab <-  bg(dtab, bg = "#E4C994", part = "header")
#dtab <- align(dtab, align = "center", part = "all" )
doc <- addFlexTable(doc, dtab)
# Slide : Data
# +++++++++++++++++++++
doc <- addSlide(doc, "Title and Content")
doc <- addTitle(doc, "Data")
dtab <- vanilla.table(dat[1:10,c('id', xvars[5:8])])
dtab <- setZebraStyle(dtab, odd = '#eeeeee', even = 'white')
#dtab <-  bg(dtab, bg = "#E4C994", part = "header")
#dtab <- align(dtab, align = "center", part = "all" )
doc <- addFlexTable(doc, dtab)
# Slide : Data
# +++++++++++++++++++++
doc <- addSlide(doc, "Title and Content")
doc <- addTitle(doc, "Data")
dtab <- vanilla.table(dat[1:10,c('id', xvars[9:12])])
dtab <- setZebraStyle(dtab, odd = '#eeeeee', even = 'white')
#dtab <-  bg(dtab, bg = "#E4C994", part = "header")
#dtab <- align(dtab, align = "center", part = "all" )
doc <- addFlexTable(doc, dtab)
# Slide : Other confounders
# +++++++++++++++++++++
doc <- addSlide(doc, "Title and Content")
doc <- addTitle(doc, "Risk")
doc  <- addParagraph(doc,
value = c('Ignore other potential confounders'
),
par.properties = parProperties(list.style = 'ordered', level = 1)
)
# Silde  : Check balance
doc <- addSlide(doc, "Title and Content")
doc <- addTitle(doc, "Check Balance Before Matching")
doc <- addPlot(doc, function() print(display_prop(df = dat, target = 'prog',
category = c('Management', 'EDD'))))
# Slide: Check balance
doc <- addSlide(doc, "Title and Content")
doc <- addTitle(doc, "Check Balance Before Matching")
raw_text <- capture.output(check_balance(d = dat, fld_name = 'prog'))
my_text <- pot(trimws(paste(raw_text, collapse = '\n')))
doc <- addParagraph(doc, value = set_of_paragraphs(my_text),
par.properties=parProperties(text.align="justify"))
# Silde  : Check balance
doc <- addSlide(doc, "Title and Content")
doc <- addTitle(doc, "Check Blance Before Matching")
doc <- addPlot(doc, function() print(display_prop(df = dat, target = 'pay_plan',
category = c('1_installment', '3_installment'))))
# Slide: Check balance
doc <- addSlide(doc, "Title and Content")
doc <- addTitle(doc, "Check Balance Before Matching")
raw_text <- capture.output(check_balance(d = dat, fld_name = 'pay_plan'))
my_text <- pot(trimws(paste(raw_text, collapse = '\n')))
doc <- addParagraph(doc, value = set_of_paragraphs(my_text),
par.properties=parProperties(text.align="justify"))
# Silde  : Check balance
doc <- addSlide(doc, "Title and Content")
doc <- addTitle(doc, "Check Balance Before Matching")
doc <- addPlot(doc, function() print(display_prop(df = dat, target = 'honesty',
category = c('No', 'Yes'))))
# Slide: Check balance
doc <- addSlide(doc, "Title and Content")
doc <- addTitle(doc, "Check Balance Before Matching")
raw_text <- capture.output(check_balance(d = dat, fld_name = 'honesty'))
my_text <- pot(trimws(paste(raw_text, collapse = '\n')))
doc <- addParagraph(doc, value = set_of_paragraphs(my_text),
par.properties=parProperties(text.align="justify"))
# Slide: standarized mean difference
doc <- addSlide(doc, "Title and Content")
doc <- addTitle(doc, "Standardized Mean Difference")
doc  <- addParagraph(doc,
value = c('SMD is the difference in means between groups, divided by (pooled) standard deviation',
'Value < 0.1 indicates adequate balance',
'Value 0.1 - 0.2 are not too alarming',
'Value > 0.2 indicates serious imbalance'
),
par.properties = parProperties(list.style = 'ordered', level = 1)
)
tab1_pre <- read.csv(file = 'table1_prematch.csv')
# Slide : prematch table1
# +++++++++++++++++++++
doc <- addSlide(doc, "Title and Content")
doc <- addTitle(doc, "SMD Before Matching")
dtab <- vanilla.table(tab1_pre)
dtab <- setZebraStyle(dtab, odd = '#eeeeee', even = 'white')
#dtab <-  bg(dtab, bg = "#E4C994", part = "header")
#dtab <- align(dtab, align = "center", part = "all" )
doc <- addFlexTable(doc, dtab)
# Slide : PSM
# +++++++++++++++++++++
doc <- addSlide(doc, "Two Content")
doc <- addTitle(doc, "Propensity Score")
doc  <- addParagraph(doc,
value = c('Estimate propensity scores by model',
'Usually use logistic regression',
'Also may use other models'
),
par.properties = parProperties(list.style = 'ordered', level = 1)
)
r_code0 <- "psmodel <- glm(tc ~ . - id - ret,
family = binomial(), data = dat)
dat$ps <- psmodel$fitted.values"
doc <- addRScript(doc, text=r_code0)
### Slide : compare common support
doc <- addSlide(doc, "Title and Content")
doc <- addTitle(doc, "Common Support")
# doc <- addPlot(doc, function() print(display_prop(df = dat, target = 'honesty',
#                                                   category = c('No', 'Yes'))))
doc <- addPlot(doc, function() commonsupport())
# doc <- addSlide(doc, "Two Content")
# doc <- addTitle(doc, "Propensity Score Matching")
# doc  <- addParagraph(doc,
#                      value = c('Match on the logit of propensity scores',
#                                'May try greedy match and optimal match and different caliper',
#                                'The goal is to balance confounders across treatment and control groups',
#                                'There are both arguments  in favor of and arguments against PSM'),
#                      par.properties = parProperties(list.style = 'ordered', level = 1)
# )
#
# r_code1 <- "logit <- function(p) {log(p)-log(1-p)}
#
# psmatch <- Match(Tr=dat$tc, M=1, X=logit(dat$ps),replace=FALSE,caliper= 1.3)
#
# matched<-dat[unlist(psmatch[c('index.treated','index.control')]), ]"
#
# doc <- addRScript(doc, text=r_code1)
# Silde  : Check balance
doc <- addSlide(doc, "Title and Content")
doc <- addTitle(doc, "Check Balance After Matching")
doc <- addPlot(doc, function() print(display_prop(df = matched, target = 'prog',
category = c('Management', 'EDD'))))
# Slide: Check balance
doc <- addSlide(doc, "Title and Content")
doc <- addTitle(doc, "Check Balance After Matching")
raw_text <- capture.output(check_balance(d = matched, fld_name = 'prog'))
my_text <- pot(trimws(paste(raw_text, collapse = '\n')))
doc <- addParagraph(doc, value = set_of_paragraphs(my_text),
par.properties=parProperties(text.align="justify"))
# Silde  : Check balance
doc <- addSlide(doc, "Title and Content")
doc <- addTitle(doc, "Check Balance After Matching")
doc <- addPlot(doc, function() print(display_prop(df = matched, target = 'pay_plan',
category = c('1_installment', '3_installment'))))
# Slide: Check balance
doc <- addSlide(doc, "Title and Content")
doc <- addTitle(doc, "Check Balance After Matching")
raw_text <- capture.output(check_balance(d = matched, fld_name = 'pay_plan'))
my_text <- pot(trimws(paste(raw_text, collapse = '\n')))
doc <- addParagraph(doc, value = set_of_paragraphs(my_text),
par.properties=parProperties(text.align="justify"))
# Silde  : Check balance
doc <- addSlide(doc, "Title and Content")
doc <- addTitle(doc, "Check Balance After Matching")
doc <- addPlot(doc, function() print(display_prop(df = matched, target = 'honesty',
category = c('No', 'Yes'))))
# Slide: Check balance
doc <- addSlide(doc, "Title and Content")
doc <- addTitle(doc, "Check Balance After Matching")
raw_text <- capture.output(check_balance(d = matched, fld_name = 'honesty'))
my_text <- pot(trimws(paste(raw_text, collapse = '\n')))
doc <- addParagraph(doc, value = set_of_paragraphs(my_text),
par.properties=parProperties(text.align="justify"))
# Slide: standarized mean difference
tab1_after <- read.csv(file = 'table1_aftermatch.csv')
# Slide : aftermatch table1
# +++++++++++++++++++++
doc <- addSlide(doc, "Title and Content")
doc <- addTitle(doc, "SMD After Matching")
dtab <- vanilla.table(tab1_after)
dtab <- setZebraStyle(dtab, odd = '#eeeeee', even = 'white')
#dtab <-  bg(dtab, bg = "#E4C994", part = "header")
#dtab <- align(dtab, align = "center", part = "all" )
doc <- addFlexTable(doc, dtab)
# Slide: Outcome
doc <- addSlide(doc, "Title and Content")
doc <- addTitle(doc, "Outcome")
raw_text <- capture.output(check_balance(d = matched, fld_name = 'ret', alternative = 'greater'))
my_text <- pot(trimws(paste(raw_text, collapse = '\n')))
doc <- addParagraph(doc, value = set_of_paragraphs(my_text),
par.properties=parProperties(text.align="justify"))
writeDoc(doc, "FDA_Presentation.pptx" )
require(ggplot2)
require(ROCR)
require(dplyr)
data <- read.csv(file = 'C:\\Users\\alin\\Documents\\Data\\FDA2018\\Collection_Risk.csv')
names(data) <- tolower(names(data))
data$id <- seq(1, nrow(data))
data$student_id <- NULL
outcome <- 'risk'
pos <- '1'
data$risk_n <- data$risk
data$risk <- as.factor(data$risk)
train <- data[data$ind <= 10, ]
test <- data[data$ind == 11, ]
num_to_cat <- c('risk', 'in_module', 'in_future', 'in_dissertation')
for (fac in num_to_cat){
data[, fac] <- as.factor(data[, fac])
}
#utility functions to explore single feature v.s. the target
single_cat <- function(dSet, feature, target = 'risk') {
#for categorical feature
print(sum(is.na(dSet[, feature])))
tab <- table(feature = as.factor(dSet[, feature]),
target = dSet[, target])
print(tab)
print(tab[,2]/(tab[, 1] + tab[, 2] ))
}
single_num <- function(dSet, feature, target = 'risk'){
#for numerical feature
print(sum(is.na(dSet[, feature])))
print(summary(dSet[, feature]))
plot(dSet[,feature] ~ dSet[, target])
print(summary(dSet[dSet[, target]  != pos, feature]))
print(summary(dSet[dSet[, target]  == pos, feature]))
}
single_cat(train, 'college')
ggplot(data=train) +
geom_density(aes(x = bb_activity_latest,
color = risk,
linetype = risk ))
summary(train$bb_gip_etc_ratio_std)
ggplot(data=train) +
geom_density(aes(x = cum_gpa,
color = risk,
linetype = risk ))
vars <- setdiff(names(train), c('student_id', 'risk','bb_gip_etc_ratio_std',
'cp_prior3mon_pay_cnt', 'payment_auto_flag',
'payment_auto_flag', 'ind',
'nation_desc', 'id', 'risk_n'))
catVars <- vars[sapply(train[,vars],class) %in%
c('factor','character')]
numericVars <- vars[sapply(train[,vars],class) %in%
c('numeric','integer')]
train0 <- train[train$ind <= 9, ]
valid0 <- train[train$ind == 10, ]
mkPredC <- function(outCol,varCol,appCol) {
pPos <- sum(outCol==pos)/length(outCol)
vTab <- table(as.factor(outCol),varCol)
pPosWv <- (vTab[pos,]+1.0e-3*pPos)/(colSums(vTab)+1.0e-3)
pred <- pPosWv[appCol]
pred[is.na(pred)] <- pPos
pred
}
mkPredN <- function(outCol,varCol,appCol) {
cuts <- unique(as.numeric(quantile(varCol,
probs=seq(0, 1, 0.1),na.rm=T)))
cuts[[1]] <- cuts[[1]] - 0.1
varC <- cut(varCol,cuts)
appC <- cut(appCol,cuts)
mkPredC(outCol,varC,appC)
}
calcAUC <- function(predcol,outcol) {
#calculated auc
perf <- performance(prediction(predcol,outcol==pos),'auc')
as.numeric(perf@y.values)
}
train0_num_sd <- scale(train0[, numericVars])
means <- attr(train0_num_sd, "scaled:center")
stds <- attr(train0_num_sd, "scaled:scale")
train0[, numericVars] <- data.frame(train0_num_sd)
# use the same mean/std to transform valid0
valid0_num <- valid0[, numericVars]
valid0_num <- t(apply(valid0_num, 1, '-', means))
valid0_num <- t(apply(valid0_num, 1, '/', stds))
valid0[, numericVars] <- data.frame(valid0_num)
v <- 'program'
pi <- paste('pred',v,sep='')
train0[,pi] <- mkPredC(train0[,outcome],train0[,v],train0[,v])
valid0[,pi] <- mkPredC(train0[,outcome],train0[,v],valid0[,v])
aucTrain <- calcAUC(train0[,pi], train0[,outcome])
aucCal <- calcAUC(valid0[,pi], valid0[,outcome])
eval <- prediction(train0[,pi], train0[, outcome])
plot(performance(eval,"tpr","fpr"))
print(attributes(performance(eval,'auc'))$y.values[[1]])
eval <- prediction(valid0[,pi], valid0[, outcome])
plot(performance(eval,"tpr","fpr"))
print(attributes(performance(eval,'auc'))$y.values[[1]])
v <- 'ba_credits_passed_prior1yr'
pi <- paste('pred',v,sep='')
train0[,pi] <- mkPredC(train0[,outcome],train0[,v],train0[,v])
valid0[,pi] <- mkPredC(train0[,outcome],train0[,v],valid0[,v])
aucTrain <- calcAUC(train0[,pi], train0[,outcome])
aucCal <- calcAUC(valid0[,pi], valid0[,outcome])
eval <- prediction(valid0[,pi], valid0[, outcome])
plot(performance(eval,"tpr","fpr"))
print(attributes(performance(eval,'auc'))$y.values[[1]])
for(v in numericVars) {
pi <- paste('pred',v,sep='')
train0[,pi] <- mkPredN(train0[,outcome],train0[,v],train0[,v])
valid0[,pi] <- mkPredN(train0[,outcome],train0[,v],valid0[,v])
aucTrain <- calcAUC(train0[,pi],train0[,outcome])
aucCal <- calcAUC(valid0[,pi], valid0[,outcome])
print(sprintf("%s, trainAUC: %4.3f calibrationAUC: %4.3f",
pi,aucTrain,aucCal))
}
for(v in catVars) {
pi <- paste('pred',v,sep='')
train0[,pi] <- mkPredC(train0[,outcome],train0[,v],train0[,v])
valid0[,pi] <- mkPredC(train0[,outcome],train0[,v],valid0[,v])
aucTrain <- calcAUC(train0[,pi], train0[,outcome])
aucCal <- calcAUC(valid0[,pi], valid0[,outcome])
print(sprintf("%s, trainAUC: %4.3f calibrationAUC: %4.3f",
pi,aucTrain,aucCal))
}
logLikelyhood <- function(outCol,predCol) {
sum(ifelse(outCol==pos,log(predCol),log(1-predCol)))
}
selVars <- c()
scores <- c()
baseRateCheck <- logLikelyhood(
valid0[,outcome],
sum(valid0[,outcome]==pos)/length(valid0[,outcome]))
print(baseRateCheck)
for(v in catVars) {
pi <- paste('pred',v,sep='')
liCheck <- 2*((logLikelyhood(valid0[,outcome],valid0[,pi]) -
baseRateCheck))
print(sprintf("%s, calibrationScore: %g", pi,liCheck))
selVars <- c(selVars,v)
scores <- c(scores, liCheck)
}
for(v in numericVars) {
pi <- paste('pred',v,sep='')
liCheck <- 2*((logLikelyhood(valid0[,outcome],valid0[,pi]) -
baseRateCheck) - 1)
print(sprintf("%s, calibrationScore: %g", pi,liCheck))
selVars <- c(selVars,v)
scores <- c(scores, liCheck)
}
varScore <- data.frame(var = selVars, score = scores)
varScore <- varScore[with(varScore, order(-score)),]
varScore
require(ggplot2)
require(ROCR)
require(dplyr)
data <- read.csv(file = 'C:\\Users\\alin\\Documents\\Data\\FDA2018\\Collection_Risk.csv')
names(data) <- tolower(names(data))
data$id <- seq(1, nrow(data))
data$student_id <- NULL
outcome <- 'risk'
pos <- '1'
data$risk_n <- data$risk
data$risk <- as.factor(data$risk)
train <- data[data$ind <= 10, ]
test <- data[data$ind == 11, ]
num_to_cat <- c('risk', 'in_module', 'in_future', 'in_dissertation')
for (fac in num_to_cat){
data[, fac] <- as.factor(data[, fac])
}
#utility functions to explore single feature v.s. the target
single_cat <- function(dSet, feature, target = 'risk') {
#for categorical feature
print(sum(is.na(dSet[, feature])))
tab <- table(feature = as.factor(dSet[, feature]),
target = dSet[, target])
print(tab)
print(tab[,2]/(tab[, 1] + tab[, 2] ))
}
single_num <- function(dSet, feature, target = 'risk'){
#for numerical feature
print(sum(is.na(dSet[, feature])))
print(summary(dSet[, feature]))
plot(dSet[,feature] ~ dSet[, target])
print(summary(dSet[dSet[, target]  != pos, feature]))
print(summary(dSet[dSet[, target]  == pos, feature]))
}
single_cat(train, 'college')
ggplot(data=train) +
geom_density(aes(x = bb_activity_latest,
color = risk,
linetype = risk ))
summary(train$bb_gip_etc_ratio_std)
ggplot(data=train) +
geom_density(aes(x = cum_gpa,
color = risk,
linetype = risk ))
vars <- setdiff(names(train), c('student_id', 'risk','bb_gip_etc_ratio_std',
'cp_prior3mon_pay_cnt', 'payment_auto_flag',
'payment_auto_flag', 'ind',
'nation_desc', 'id', 'risk_n'))
catVars <- vars[sapply(train[,vars],class) %in%
c('factor','character')]
numericVars <- vars[sapply(train[,vars],class) %in%
c('numeric','integer')]
train0 <- train[train$ind <= 9, ]
valid0 <- train[train$ind == 10, ]
mkPredC <- function(outCol,varCol,appCol) {
pPos <- sum(outCol==pos)/length(outCol)
vTab <- table(as.factor(outCol),varCol)
pPosWv <- (vTab[pos,]+1.0e-3*pPos)/(colSums(vTab)+1.0e-3)
pred <- pPosWv[appCol]
pred[is.na(pred)] <- pPos
pred
}
mkPredN <- function(outCol,varCol,appCol) {
cuts <- unique(as.numeric(quantile(varCol,
probs=seq(0, 1, 0.1),na.rm=T)))
cuts[[1]] <- cuts[[1]] - 0.1
varC <- cut(varCol,cuts)
appC <- cut(appCol,cuts)
mkPredC(outCol,varC,appC)
}
calcAUC <- function(predcol,outcol) {
#calculated auc
perf <- performance(prediction(predcol,outcol==pos),'auc')
as.numeric(perf@y.values)
}
train0_num_sd <- scale(train0[, numericVars])
means <- attr(train0_num_sd, "scaled:center")
stds <- attr(train0_num_sd, "scaled:scale")
train0[, numericVars] <- data.frame(train0_num_sd)
# use the same mean/std to transform valid0
valid0_num <- valid0[, numericVars]
valid0_num <- t(apply(valid0_num, 1, '-', means))
valid0_num <- t(apply(valid0_num, 1, '/', stds))
valid0[, numericVars] <- data.frame(valid0_num)
for(v in numericVars) {
pi <- paste('pred',v,sep='')
train0[,pi] <- mkPredN(train0[,outcome],train0[,v],train0[,v])
valid0[,pi] <- mkPredN(train0[,outcome],train0[,v],valid0[,v])
aucTrain <- calcAUC(train0[,pi],train0[,outcome])
aucCal <- calcAUC(valid0[,pi], valid0[,outcome])
print(sprintf("%s, trainAUC: %4.3f calibrationAUC: %4.3f",
pi,aucTrain,aucCal))
}
for(v in catVars) {
pi <- paste('pred',v,sep='')
train0[,pi] <- mkPredC(train0[,outcome],train0[,v],train0[,v])
valid0[,pi] <- mkPredC(train0[,outcome],train0[,v],valid0[,v])
aucTrain <- calcAUC(train0[,pi], train0[,outcome])
aucCal <- calcAUC(valid0[,pi], valid0[,outcome])
print(sprintf("%s, trainAUC: %4.3f calibrationAUC: %4.3f",
pi,aucTrain,aucCal))
}
v <- 'program'
pi <- paste('pred',v,sep='')
# train0[,pi] <- mkPredC(train0[,outcome],train0[,v],train0[,v])
# valid0[,pi] <- mkPredC(train0[,outcome],train0[,v],valid0[,v])
# aucTrain <- calcAUC(train0[,pi], train0[,outcome])
# aucCal <- calcAUC(valid0[,pi], valid0[,outcome])
eval <- prediction(train0[,pi], train0[, outcome])
plot(performance(eval,"tpr","fpr"))
print(attributes(performance(eval,'auc'))$y.values[[1]])
eval <- prediction(valid0[,pi], valid0[, outcome])
plot(performance(eval,"tpr","fpr"))
print(attributes(performance(eval,'auc'))$y.values[[1]])
v <- 'ba_credits_passed_prior1yr'
pi <- paste('pred',v,sep='')
# train0[,pi] <- mkPredC(train0[,outcome],train0[,v],train0[,v])
# valid0[,pi] <- mkPredC(train0[,outcome],train0[,v],valid0[,v])
# aucTrain <- calcAUC(train0[,pi], train0[,outcome])
# aucCal <- calcAUC(valid0[,pi], valid0[,outcome])
eval <- prediction(valid0[,pi], valid0[, outcome])
plot(performance(eval,"tpr","fpr"))
print(attributes(performance(eval,'auc'))$y.values[[1]])
logLikelyhood <- function(outCol,predCol) {
sum(ifelse(outCol==pos,log(predCol),log(1-predCol)))
}
selVars <- c()
scores <- c()
baseRateCheck <- logLikelyhood(
valid0[,outcome],
sum(valid0[,outcome]==pos)/length(valid0[,outcome]))
print(baseRateCheck)
for(v in catVars) {
pi <- paste('pred',v,sep='')
liCheck <- 2*((logLikelyhood(valid0[,outcome],valid0[,pi]) -
baseRateCheck))
print(sprintf("%s, calibrationScore: %g", pi,liCheck))
selVars <- c(selVars,v)
scores <- c(scores, liCheck)
}
for(v in numericVars) {
pi <- paste('pred',v,sep='')
liCheck <- 2*((logLikelyhood(valid0[,outcome],valid0[,pi]) -
baseRateCheck) - 1)
print(sprintf("%s, calibrationScore: %g", pi,liCheck))
selVars <- c(selVars,v)
scores <- c(scores, liCheck)
}
varScore <- data.frame(var = selVars, score = scores)
varScore <- varScore[with(varScore, order(-score)),]
varScore
ggplot(data=train) +
geom_density(aes(x = cum_gpa,
color = risk,
linetype = risk ))
ifelse(3 > 2, 'red', 'black')
ggplot(data=train) +
geom_density(aes(x = cum_gpa,
color = ifelse(risk == 1, 'red', 'black'),
linetype = risk ))
str(dat)
table(dat$tc)
q()
