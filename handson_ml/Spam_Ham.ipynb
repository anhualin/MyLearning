{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore how to build a spam detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, unicode_literals\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "from sys import platform\n",
    "if platform == 'linux':\n",
    "    DATA_PATH = os.path.join(\"/home/alin/handson-ml/datasets\", \"spamham\")\n",
    "else:\n",
    "    DATA_PATH = os.path.join('C:/Users/alin/Documents/SelfStudy/datasets', 'spamham')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%qtconsole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "EASY_HAM_PATH = os.path.join(DATA_PATH, 'easy_ham')\n",
    "HARD_HAM_PATH = os.path.join(DATA_PATH, 'hard_ham')\n",
    "SPAM_PATH = os.path.join(DATA_PATH, 'spam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_one_email(filepath):\n",
    "    with open(filepath, 'r', encoding='latin-1') as fpr:\n",
    "            return fpr.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_data = {'ID':[], 'Email':[], 'Label':[]}\n",
    "\n",
    "for filename in  os.listdir(EASY_HAM_PATH):\n",
    "    spam_data['ID'].append(filename)\n",
    "    spam_data['Label'].append(0)\n",
    "    spam_data['Email'].append(load_one_email(os.path.join(EASY_HAM_PATH, filename)))\n",
    "   \n",
    "\n",
    "for filename in  os.listdir(HARD_HAM_PATH):\n",
    "    spam_data['ID'].append(filename)\n",
    "    spam_data['Label'].append(0)\n",
    "    spam_data['Email'].append(load_one_email(os.path.join(HARD_HAM_PATH, filename)))\n",
    "\n",
    "for filename in  os.listdir(SPAM_PATH):\n",
    "    spam_data['ID'].append(filename)\n",
    "    spam_data['Label'].append(1)\n",
    "    spam_data['Email'].append(load_one_email(os.path.join(SPAM_PATH, filename)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_df = pd.DataFrame(spam_data)\n",
    "\n",
    "X = spam_df['Email']\n",
    "y = spam_df['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle_index = np.random.permutation(y.shape[0])\n",
    "X, y = X[shuffle_index], y[shuffle_index]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import email\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_header(x):\n",
    "    payload = email.message_from_string(x).get_payload()\n",
    "    # if payload is not a string, set it to ''\n",
    "    clean_txt = payload if isinstance(payload, str) else ''\n",
    "    return clean_txt\n",
    "\n",
    "class HeaderRemover(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, header_remove=True):\n",
    "        self.header_remove = header_remove\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        if self.header_remove:\n",
    "            return X.apply(remove_header)\n",
    "        else:\n",
    "            return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UrlCleaner(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, url_clean=True):\n",
    "        self.url_clean = url_clean\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        if self.url_clean:\n",
    "            return X.str.replace('https?://\\S*', 'URL')\n",
    "        else:\n",
    "            return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumCleaner(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, num_clean=True):\n",
    "        self.num_clean = num_clean\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        if self.num_clean:\n",
    "            return X.str.replace('[-\\+\\d\\.,]+', ' NUM ')\n",
    "        else:\n",
    "            return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "analyzer = CountVectorizer().build_analyzer()\n",
    "def stemmed_words(doc):\n",
    "    return (stemmer.stem(w) for w in analyzer(doc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_pipeline(header_remove=True, url_clean=True, num_clean=True, stem=False, stop_words = 'english', lowercase=True, strip_accents = True,\n",
    "                     binary=True):\n",
    "    pipe_items = []\n",
    "    if strip_accents:\n",
    "        accents = 'unicode'\n",
    "    else:\n",
    "        accents = None\n",
    "    if stem:\n",
    "        analyzer = stemmed_words\n",
    "    else:\n",
    "        analyzer = 'word'\n",
    "    spam_pipeline = Pipeline([\n",
    "        ('header_remover', HeaderRemover(header_remove=header_remove)),\n",
    "        ('url_clean', UrlCleaner(url_clean=url_clean)),\n",
    "        ('num_clean', NumCleaner(num_clean=num_clean)),\n",
    "        ('vect', CountVectorizer(lowercase=lowercase, strip_accents=accents, analyzer = analyzer, stop_words=stop_words, binary=binary)),\n",
    "    \n",
    "    ])\n",
    "   \n",
    "    return spam_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "pline = process_pipeline(stem=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1 = pline.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "pline1 = process_pipeline(stem=False)\n",
    "X_train2 = pline1.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
