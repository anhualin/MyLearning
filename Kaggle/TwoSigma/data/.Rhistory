packages <- c("jsonlite", "dplyr", "purrr", "tidytext", "ggplot2", "lubridate")
purrr::walk(packages, library, character.only = TRUE, warn.conflicts = FALSE)
if (Sys.info()[1] == 'Windows'){
setwd('C:/Users/alin/Documents/SelfStudy/MyLearning/Kaggle/TwoSigma/data')
}else{
setwd('/home/alin/MyLearning/Kaggle/TwoSigma/data')
}
data <- fromJSON("train.json")
names(data)
library(tidyr)
library(stringr)
raw_description <- data[c(9,5)] %>%
tibble::as_tibble(.) %>%
mutate(listing_id = unlist(listing_id))
raw_description
raw_description$description[1]
dejunk <- function(a){
a <- gsub('<a\\s+website_redacted', '',a)
a <- gsub('<\\S+\\s*/*>', ' ', a)
a <- gsub('\\S+\\s*@\\s*\\S+', ' ', a)
a <- gsub('\\d+[-]*\\d+[-]\\d+', ' ', a)
a <- gsub('\\W+', ' ', a)
a <- gsub('[[:digit:]]', ' ', a)
}
raw_description <- data[c(9,5)] %>%
tibble::as_tibble(.) %>%
mutate(listing_id = unlist(listing_id), description = dejunk(description))
raw_description
train0 <- raw_description[1:500,]
train0
tidy_train0 <- train0 %>%
unnest_tokens(word, description) %>%
anti_join(stop_words)
word_cnt <- tidy_train0 %>%
count(listing_id) %>%
mutate(word_cnt = n)
word_cnt
senti <- tidy_train0 %>%
inner_join(get_sentiments("afinn")) %>%
group_by(listing_id) %>%
summarise(sentiment = sum(score))
senti
summary(senti$sentiment)
bigrams_separated <- train0 %>%
separate(bigram, c("word1", "word2"), sep = " ")
train0
bigrams_separated <- train0 %>%
separate(description, c("word1", "word2"), sep = " ")
bigrams_separated <- train0 %>%
unnest_tokens(bigram, description, token = "ngrams", n = 2) %>%
separate(bigram, c("word1", "word2"), sep = " ")
bigrams_separated
train0[train0$listing_id == 7087718, 'description']
negation_words <- c("not", "no", "never", "without")
bigrams_separated <- train0 %>%
unnest_tokens(bigram, description, token = "ngrams", n = 2) %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
filter(word1 %in% negation_words) %>%
inner_join(get_sentiments("afinn"), by = c(word2 = "word"))
bigrams_separated
train0[train0$listing_id == 7105389, 'description']
a <- train0[train0$listing_id == 7105389, 'description']
a
a[[1]]
neg_senti <- train0 %>%
unnest_tokens(bigram, description, token = "ngrams", n = 2) %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
filter(word1 %in% negation_words) %>%
inner_join(get_sentiments("afinn"), by = c(word2 = "word"))
neg_senti
neg_senti <- train0 %>%
unnest_tokens(bigram, description, token = "ngrams", n = 2) %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
filter(word1 %in% negation_words) %>%
inner_join(get_sentiments("afinn"), by = c(word2 = "word")) %>%
group_by(listing_id) %>%
summarise(sentiment2 = -2*sum(score))
neg_senti
senti <- tidy_train0 %>%
inner_join(get_sentiments("afinn")) %>%
group_by(listing_id) %>%
summarise(sentiment1 = sum(score))
senti
sentiment <- senti %>%
left_join(neg_senti)
sentiment
b <- NA
max(b,0)
sentiment <- senti %>%
left_join(neg_senti) %>%
mutate(sentiment = (if(is.na(sentiment2)) 0 else sentiment2))
sentiment
sentiment[sentiment$listing_id ==  7105389, 'sentiment'  ]
sentiment[sentiment$listing_id ==  7105389, ]
sentiment[is.na(sentiment$sentiment2), 'sentiment2'] <- 0
sentiment
sentiment[sentiment$listing_id ==  7105389, 'sentiment'  ]
sentiment[sentiment$listing_id ==  7105389,  ]
sentiment <- senti %>%
left_join(neg_senti) %>%
sentiment[is.na(sentiment$sentiment2), 'sentiment'] <- 0
sentiment <- senti %>%
left_join(neg_senti)
sentiment[is.na(sentiment$sentiment2), 'sentiment'] <- 0
sentiment[sentiment$listing_id ==  7105389,  ]
sentiment <- senti %>%
left_join(neg_senti)
sentiment[is.na(sentiment$sentiment2), 'sentiment2'] <- 0
sentiment[sentiment$listing_id ==  7105389,  ]
sentiment
sentiment <- sentiment %>%
mutate(sentiment = sentiment1 + sentiment2) %>%
select(listing_id, sentiment)
sentiment
summary(sentiment$sentiment)
tidy_train <- raw_description %>%
unnest_tokens(word, description) %>%
anti_join(stop_words)
tidy_train
word_cnt <- tidy_train %>%
count(listing_id) %>%
mutate(word_cnt = n)
word_cnt
senti <- tidy_train %>%
inner_join(get_sentiments("afinn")) %>%
group_by(listing_id) %>%
summarise(sentiment1 = sum(score))
senti
nrow(tidy_train)
neg_senti <- train %>%
unnest_tokens(bigram, description, token = "ngrams", n = 2) %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
filter(word1 %in% negation_words) %>%
inner_join(get_sentiments("afinn"), by = c(word2 = "word"))
neg_senti <- raw_description %>%
unnest_tokens(bigram, description, token = "ngrams", n = 2) %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
filter(word1 %in% negation_words) %>%
inner_join(get_sentiments("afinn"), by = c(word2 = "word"))
neg_senti
sentiment <- senti %>%
left_join(neg_senti)
sentiment
senti
neg_senti
neg_senti <- raw_description %>%
unnest_tokens(bigram, description, token = "ngrams", n = 2) %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
filter(word1 %in% negation_words) %>%
inner_join(get_sentiments("afinn"), by = c(word2 = "word")) %>%
group_by(listing_id) %>%
summarise(sentiment2 = -2*sum(score))
sentiment <- senti %>%
left_join(neg_senti)
sentiment
sentiment[is.na(sentiment$sentiment2), 'sentiment2'] <- 0
sentiment <- sentiment %>%
mutate(sentiment = sentiment1 + sentiment2) %>%
select(listing_id, sentiment)
sentiment
summary(sentiment$sentiment)
sentiment[sentiment$sentiment < -671, ]
a <- raw_description[raw_description$listing_id == 6992360, 'description']
a
a[[1]]
b <- data[data$listing_id == 6992360, 'description']
nrow(raw_description)
raw <- train_df %>%
mutate(description = dejunk(description))
x <- raw_description[raw_description$listing_id == 6812142, 'description']
x
x[[1]]
feature_df <- data[c(9,7)] %>%
tibble::as_tibble(.) %>%
mutate(listing_id = unlist(listing_id))
q()
