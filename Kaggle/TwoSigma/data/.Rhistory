Months = sample(4:20, 10, replace=TRUE),
Treated=sample(0:1, 10, replace=TRUE),
Stage = sample(1:4, 10, replace=TRUE),
Continued=sample(0:1, 10, replace=TRUE))
dat
ggplot(dat, aes(Subject, Months)) +
geom_bar(stat="identity", aes(fill=factor(Stage)), width=0.8)
ggplot(dat, aes(Subject, Months)) +
geom_bar(stat="identity", aes(fill=factor(Stage)), width=0.8) +
geom_point(data=dat.m,
aes(Subject, value, colour=variable, shape=variable), size=4) +
geom_segment(data=dat %>% filter(Continued==1),
aes(x=Subject, xend=Subject, y=Months + 0.1, yend=Months + 1),
pch=15, size=0.8, arrow=arrow(type="closed", length=unit(0.1,"in"))) +
coord_flip() +
geom_hline(yintercept=3) +
scale_fill_manual(values=hcl(seq(15,375,length.out=5)[1:4],100,70)) +
scale_colour_manual(values=c(hcl(seq(15,375,length.out=3)[1:2],100,40),"black")) +
scale_y_continuous(limits=c(-1,20), breaks=0:20) +
labs(fill="Disease Stage", colour="", shape="",
x="Subject Recevied Study Drug") +
theme_bw() +
theme(panel.grid.minor=element_blank(),
panel.grid.major=element_blank(),
axis.text.y=element_blank(),
axis.ticks.y=element_blank())
q()
q()
library(data.table)
install.packages("jsonlite")
install.packages(c("dplyr", "purrr", "tidytext"))
install.packages(c("syuzhet", "DT", "randomForest"))
library(data.table)
install.packages(c("data.table", "tibble"))
install.packages(c("tidry", "lubridate"))
q()
92058.46+98458.09 + 11685.20
0.46 + 0.09 + 0.20
92058+98458+11685
202201.75 + 17.13
75+13
options(digits=2)
202201.75 + 17.13
options(digits=10)
202201.75 + 17.13
830.84 + 7257.23 + 6662.12
14750.19 + 5607.49
20357.68 + 5459.62 + 1800
202218.88 - 27617.3
4050*3
174601.58 - 12150
162451.58 * 0.28 - 13014.50
174601.58 + 27617.3
27617.30
27167.3 * 0.8
202218.88
202218.88 - 83800
202218.88 - 159700
42518.88 * 0.25
118418.88 + 10629.72
129048.6 * 0.26
174601.58 + 20357.68
194959.26 - 159700
35259.26 * 0.25
83800 - 8814.82
194959.26 - 74985.18
119974.08 * 0.26
2075*12
24900+375
11685.20 + 92058.46
202218.88 - 110000
93000 * 0.05
32471.94 - 600
407.99 + 10600.89 + 21258.46
32267.34 - 31871.94
202218.88 - 1800
27617.30 - 14750.19
200418.88 - 12867.11
37551.77 * 0.05
1877.5885 + 7072.50
187551.77 * 0.032
8950.09 + 6001.66
14951.75 - 14750.19
q()
q()
q()
q()
q()
q()
text <- c("Because I could not stop for Death -",
"He kindly stopped for me -",
"The Carriage held but just Ourselves -",
"and Immortality")
text
library(dplyr)
library(ggplot2)
text_df <- data_frame(line = 1:4, text = text)
library(tidytext)
text_df %>%
unnest_tokens(word, text)
test_df
text_df
library(janeaustenr)
#library(dplyr)
library(stringr)
?austen_books
a <- austen_books()
str(a)
a
head(a)
a[500:550,]
a <- austen_books() %>% group_by(book)
str(a)
a
?row_number()
?cumsum
?row_number()
?cumsum
a <- austen_books()
str(a)
b <- a[1:100, ]
b
b[50:55,]
g <- mutate(b, cha = str_detect(text, regex("^chapter [\\divxlc]", ignore_case = TRUE)))
g
?regex
g <- mutate(b, cha = str_detect(text, regex("^chapter [ivxlc]", ignore_case = TRUE)))
g
g <- mutate(b, cha = str_detect(text, regex("^chapter [\\d]", ignore_case = TRUE)))
g
g <- mutate(b, cha = cumsum(str_detect(text, regex("^chapter [\\d]", ignore_case = TRUE))))
g
g[1:20,]
?ungroup
original_books <- austen_books() %>%
group_by(book) %>%
mutate(linenumber = row_number(),
chapter = cumsum(str_detect(text, regex("^chapter [\\divxlc]",
ignore_case = TRUE)))) %>%
ungroup()
original_books
tidy_books <- original_books %>%
unnest_tokens(word, text)
str(tidy_books)
tidy_books
?anti_join
data("stop_words")
tidy_books <- tidy_books %>%
anti_join(stop_words)
tidy_books
?count
tidy_books %>%
count(word, sort = TRUE)
?reorder
tidy_books %>%
count(word, sort = TRUE) %>%
filter(n > 600) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n)) +
geom_col() +
xlab(NULL) +
coord_flip()
q()
library(tidytext)
sentiments
get_sentiments("afinn")
get_sentiments("bing")
get_sentiments("nrc")
q()
library(h2o)
q()
q()
q()
x <- c(5,9.2,3,8.51,NA),
x <- c(5,9.2,3,8.51,NA)
mean(x)
mean(x, na.rm = TRUE)
x[0]
x[1]
q()
q()
if (Sys.info()[1] == 'Windows'){
setwd('C:/Users/alin/Documents/SelfStudy/MyLearning/Kaggle/TwoSigma/data')
}else{
setwd('/home/alin/MyLearning/Kaggle/TwoSigma/data')
}
library(data.table)
library(jsonlite)
library(lubridate)
packages <- c("jsonlite", "dplyr", "purrr")
purrr::walk(packages, library, character.only = TRUE, warn.conflicts = FALSE)
# Load data
t1 <- fromJSON("train.json")
vars <- setdiff(names(t1), c("photos", "features"))
t1 <- map_at(t1, vars, unlist) %>% tibble::as_tibble(.)
nrow(t1)
library(caTools)
split <- sample.split((1:nrow(train_df)), SplitRatio = 0.7)
train <- t1[split,]
valid <- t1[!split, ]
install.packages("caTools")
library(caTools)
split <- sample.split((1:nrow(train_df)), SplitRatio = 0.7)
train <- t1[split,]
valid <- t1[!split, ]
split <- sample.split((1:nrow(t1)), SplitRatio = 0.7)
train <- t1[split,]
valid <- t1[!split, ]
t1 <- train
s1 <- valid
t1
s1
row_by_manager_id = aggregate(rep(1, nrow(t1)),by=list(t1$manager_id), sum)
names(row_by_manager_id) <- c("manager_id","count")
row_by_manager_id$freq = row_by_manager_id$count/49352
row_by_manager_id$manager_odds = log(row_by_manager_id$freq/(1-row_by_manager_id$freq))
t1 = merge(t1,row_by_manager_id,by="manager_id")
t1 <- subset(t1,select = -c(count,freq))
# Rate By Level using Building ID
row_by_building_id = aggregate(rep(1, nrow(t1)),by=list(t1$building_id), sum)
names(row_by_building_id) <- c("building_id","count")
row_by_building_id$freq = row_by_building_id$count/49352
row_by_building_id$building_odds = log(row_by_building_id$freq/(1-row_by_building_id$freq))
t1 = merge(t1,row_by_building_id,by="building_id")
t1 <- subset(t1, select = -c(count,freq))
# Rate By Level using Listing ID
row_by_listing_id = aggregate(rep(1, nrow(t1)),by=list(t1$listing_id), sum)
names(row_by_listing_id) <- c("listing_id","count")
row_by_listing_id$freq = row_by_listing_id$count/49352
row_by_listing_id$listing_odds = log(row_by_listing_id$freq/(1-row_by_listing_id$freq))
t1 = merge(t1,row_by_listing_id,by="listing_id")
t1 <- subset(t1, select = -c(count,freq))
t2 <- data.table(bathrooms=unlist(t1$bathrooms)
,bedrooms=unlist(t1$bedrooms)
,building_id=as.factor(unlist(t1$building_id))
,building_odds=as.numeric(unlist(t1$building_odds))
,created=as.POSIXct(unlist(t1$created))
# ,description=unlist(t1$description) # parse errors
# ,display_address=unlist(t1$display_address) # parse errors
,num_features=as.numeric(lengths(t1$features))
,num_photos=as.numeric(lengths(t1$photos))
,latitude=unlist(t1$latitude)
,longitude=unlist(t1$longitude)
,listing_id=unlist(t1$listing_id)
,listing_odds=as.numeric(t1$listing_odds)
,manager_id=as.factor(unlist(t1$manager_id))
,manager_odds=as.numeric(t1$manager_odds)
,price=unlist(t1$price)
,logprice=as.numeric(log(t1$price))
,interest_level=as.factor(unlist(t1$interest_level))
# ,street_adress=unlist(t1$street_address) # parse errors
)
t2[,":="(yday=yday(created)
,month=month(created)
,mday=mday(created)
,wday=wday(created)
,hour=hour(created))]
nrow(s1)
vars <- setdiff(names(s1), c("photos", "features"))
s1 <- map_at(s1, vars, unlist) %>% tibble::as_tibble(.)
# Rate By Level using Manager ID
row_by_manager_id = aggregate(rep(1, nrow(s1)),by=list(s1$manager_id), sum)
names(row_by_manager_id) <- c("manager_id","count")
row_by_manager_id$freq = row_by_manager_id$count/49352
row_by_manager_id$manager_odds = log(row_by_manager_id$freq/(1-row_by_manager_id$freq))
s1 = merge(s1,row_by_manager_id,by="manager_id")
s1 <- subset(s1, select = -c(count,freq))
# Rate By Level using Building ID
row_by_building_id = aggregate(rep(1, nrow(s1)),by=list(s1$building_id), sum)
names(row_by_building_id) <- c("building_id","count")
row_by_building_id$freq = row_by_building_id$count/49352
row_by_building_id$building_odds = log(row_by_building_id$freq/(1-row_by_building_id$freq))
s1 = merge(s1,row_by_building_id,by="building_id")
s1 <- subset(s1, select = -c(count,freq))
# Rate By Level using Listing ID
row_by_listing_id = aggregate(rep(1, nrow(s1)),by=list(s1$listing_id), sum)
names(row_by_listing_id) <- c("listing_id","count")
row_by_listing_id$freq = row_by_listing_id$count/49352
row_by_listing_id$listing_odds = log(row_by_listing_id$freq/(1-row_by_listing_id$freq))
s1 = merge(s1,row_by_listing_id,by="listing_id")
s1 <- subset(s1, select = -c(count,freq))
s2 <- data.table(bathrooms=unlist(s1$bathrooms)
,bedrooms=unlist(s1$bedrooms)
,building_id=as.factor(unlist(s1$building_id))
,building_odds=as.numeric(unlist(s1$building_odds))
,created=as.factor(unlist(s1$created))
# ,description=unlist(s1$description) # parse errors
# ,display_address=unlist(s1$display_address) # parse errors
,num_features=as.numeric(lengths(s1$features))
,num_photos=as.numeric(lengths(s1$photos))
,latitude=unlist(s1$latitude)
,longitude=unlist(s1$longitude)
,listing_id=unlist(s1$listing_id)
,listing_odds=unlist(s1$listing_odds)
,manager_id=as.factor(unlist(s1$manager_id))
,manager_odds=as.numeric(unlist(s1$manager_odds))
,price=unlist(s1$price)
,logprice=as.numeric(log(s1$price))
# ,street_adress=unlist(s1$street_address) # parse errors
)
s2[,":="(yday=yday(created)
,month=month(created)
,mday=mday(created)
,wday=wday(created)
,hour=hour(created))]
train_df <- t1[split,]
valid_df <- t1[!split,
]
t1 <- fromJSON("train.json")
vars <- setdiff(names(t1), c("photos", "features"))
t1 <- map_at(t1, vars, unlist) %>% tibble::as_tibble(.)
split <- sample.split((1:nrow(t1)), SplitRatio = 0.7)
train_df <- t1[split,]
valid_df <- t1[!split, ]
t1 <- train_df
s1 <- valid_df
# Rate By Level using Manager ID
row_by_manager_id = aggregate(rep(1, nrow(t1)),by=list(t1$manager_id), sum)
names(row_by_manager_id) <- c("manager_id","count")
row_by_manager_id$freq = row_by_manager_id$count/49352
row_by_manager_id$manager_odds = log(row_by_manager_id$freq/(1-row_by_manager_id$freq))
t1 = merge(t1,row_by_manager_id,by="manager_id")
t1 <- subset(t1,select = -c(count,freq))
# Rate By Level using Building ID
row_by_building_id = aggregate(rep(1, nrow(t1)),by=list(t1$building_id), sum)
names(row_by_building_id) <- c("building_id","count")
row_by_building_id$freq = row_by_building_id$count/49352
row_by_building_id$building_odds = log(row_by_building_id$freq/(1-row_by_building_id$freq))
t1 = merge(t1,row_by_building_id,by="building_id")
t1 <- subset(t1, select = -c(count,freq))
# Rate By Level using Listing ID
row_by_listing_id = aggregate(rep(1, nrow(t1)),by=list(t1$listing_id), sum)
names(row_by_listing_id) <- c("listing_id","count")
row_by_listing_id$freq = row_by_listing_id$count/49352
row_by_listing_id$listing_odds = log(row_by_listing_id$freq/(1-row_by_listing_id$freq))
t1 = merge(t1,row_by_listing_id,by="listing_id")
t1 <- subset(t1, select = -c(count,freq))
t2 <- data.table(bathrooms=unlist(t1$bathrooms)
,bedrooms=unlist(t1$bedrooms)
,building_id=as.factor(unlist(t1$building_id))
,building_odds=as.numeric(unlist(t1$building_odds))
,created=as.POSIXct(unlist(t1$created))
# ,description=unlist(t1$description) # parse errors
# ,display_address=unlist(t1$display_address) # parse errors
,num_features=as.numeric(lengths(t1$features))
,num_photos=as.numeric(lengths(t1$photos))
,latitude=unlist(t1$latitude)
,longitude=unlist(t1$longitude)
,listing_id=unlist(t1$listing_id)
,listing_odds=as.numeric(t1$listing_odds)
,manager_id=as.factor(unlist(t1$manager_id))
,manager_odds=as.numeric(t1$manager_odds)
,price=unlist(t1$price)
,logprice=as.numeric(log(t1$price))
,interest_level=as.factor(unlist(t1$interest_level))
# ,street_adress=unlist(t1$street_address) # parse errors
)
t2[,":="(yday=yday(created)
,month=month(created)
,mday=mday(created)
,wday=wday(created)
,hour=hour(created))]
vars <- setdiff(names(s1), c("photos", "features"))
s1 <- map_at(s1, vars, unlist) %>% tibble::as_tibble(.)
# Rate By Level using Manager ID
row_by_manager_id = aggregate(rep(1, nrow(s1)),by=list(s1$manager_id), sum)
names(row_by_manager_id) <- c("manager_id","count")
row_by_manager_id$freq = row_by_manager_id$count/49352
row_by_manager_id$manager_odds = log(row_by_manager_id$freq/(1-row_by_manager_id$freq))
s1 = merge(s1,row_by_manager_id,by="manager_id")
s1 <- subset(s1, select = -c(count,freq))
# Rate By Level using Building ID
row_by_building_id = aggregate(rep(1, nrow(s1)),by=list(s1$building_id), sum)
names(row_by_building_id) <- c("building_id","count")
row_by_building_id$freq = row_by_building_id$count/49352
row_by_building_id$building_odds = log(row_by_building_id$freq/(1-row_by_building_id$freq))
s1 = merge(s1,row_by_building_id,by="building_id")
s1 <- subset(s1, select = -c(count,freq))
# Rate By Level using Listing ID
row_by_listing_id = aggregate(rep(1, nrow(s1)),by=list(s1$listing_id), sum)
names(row_by_listing_id) <- c("listing_id","count")
row_by_listing_id$freq = row_by_listing_id$count/49352
row_by_listing_id$listing_odds = log(row_by_listing_id$freq/(1-row_by_listing_id$freq))
s1 = merge(s1,row_by_listing_id,by="listing_id")
s1 <- subset(s1, select = -c(count,freq))
s2 <- data.table(bathrooms=unlist(s1$bathrooms)
,bedrooms=unlist(s1$bedrooms)
,building_id=as.factor(unlist(s1$building_id))
,building_odds=as.numeric(unlist(s1$building_odds))
,created=as.factor(unlist(s1$created))
# ,description=unlist(s1$description) # parse errors
# ,display_address=unlist(s1$display_address) # parse errors
,num_features=as.numeric(lengths(s1$features))
,num_photos=as.numeric(lengths(s1$photos))
,latitude=unlist(s1$latitude)
,longitude=unlist(s1$longitude)
,listing_id=unlist(s1$listing_id)
,listing_odds=unlist(s1$listing_odds)
,manager_id=as.factor(unlist(s1$manager_id))
,manager_odds=as.numeric(unlist(s1$manager_odds))
,price=unlist(s1$price)
,logprice=as.numeric(log(s1$price))
# ,street_adress=unlist(s1$street_address) # parse errors
)
s2[,":="(yday=yday(created)
,month=month(created)
,mday=mday(created)
,wday=wday(created)
,hour=hour(created))]
library(h2o)
h2o.init(nthreads = -1, max_mem_size="10g")
train <- as.h2o(t2[,-"created"], destination_frame = "train.hex")
varnames <- setdiff(colnames(train), "interest_level")
gbm1 <- h2o.gbm(x = varnames
,y = "interest_level"
,training_frame = train
,distribution = "multinomial"
,model_id = "gbm1"
#,nfolds = 5
,ntrees = 750
,learn_rate = 0.05
,max_depth = 7
,min_rows = 20
,sample_rate = 0.7
,col_sample_rate = 0.7
#   ,stopping_rounds = 5
#   ,stopping_metric = "logloss"
#   ,stopping_tolerance = 0
,seed=321
)
test <- as.h2o(s2[,-"created"], destination_frame = "test.hex")
predH2o <- as.data.frame(h2o.predict(gbm1, test))
test_result1 <- cbind(s2, predH2o)
test_result <- test_result1 %>%
select(listing_id, high, medium, low)
test_result <- test_result1 %>%
select(listing_id, interest_level, high, medium, low)
test_result1 <- cbind(s1, predH2o)
test_result <- test_result1 %>%
select(listing_id, interest_level, high, medium, low)
test_result
logloss <- function(result){
score <- 0
for(i in 1:nrow(result)){
score <- score - log(result[i, as.character(result[i, 'interest_level'])])
}
score <- score/nrow(result)
}
print(logloss(test_result))
varnames
notUse <- c('yday', 'month', 'mday', 'wday', 'hour')
varnames <- setdiff(varnames, notUse)
varnames
varnames <- setdiff(colnames(train), "interest_level")
gbm1 <- h2o.gbm(x = varnames, y = "interest_level", train, seed = 10000)
predH2o <- as.data.frame(h2o.predict(gbm1, test))
test_result1 <- cbind(s1, predH2o)
test_result <- test_result1 %>%
select(listing_id, interest_level, high, medium, low)
print(logloss(test_result))
notUse <- c('yday', 'month', 'mday', 'wday', 'hour')
varnames <- setdiff(varnames, notUse)
varnames
gbm1 <- h2o.gbm(x = varnames
,y = "interest_level"
,training_frame = train
,distribution = "multinomial"
,model_id = "gbm1"
#,nfolds = 5
,ntrees = 750
,learn_rate = 0.05
,max_depth = 7
,min_rows = 20
,sample_rate = 0.7
,col_sample_rate = 0.7
#   ,stopping_rounds = 5
#   ,stopping_metric = "logloss"
#   ,stopping_tolerance = 0
,seed=321
)
predH2o <- as.data.frame(h2o.predict(gbm1, test))
test_result1 <- cbind(s1, predH2o)
test_result <- test_result1 %>%
select(listing_id, interest_level, high, medium, low)
print(logloss(test_result))
varnames
notUse <- c('yday', 'month', 'mday', 'wday', 'hour', 'manager_odds', 'building_odds')
varnames <- setdiff(varnames, notUse)
gbm1 <- h2o.gbm(x = varnames
,y = "interest_level"
,training_frame = train
,distribution = "multinomial"
,model_id = "gbm1"
#,nfolds = 5
,ntrees = 750
,learn_rate = 0.05
,max_depth = 7
,min_rows = 20
,sample_rate = 0.7
,col_sample_rate = 0.7
#   ,stopping_rounds = 5
#   ,stopping_metric = "logloss"
#   ,stopping_tolerance = 0
,seed=321
)
predH2o <- as.data.frame(h2o.predict(gbm1, test))
test_result1 <- cbind(s1, predH2o)
test_result <- test_result1 %>%
select(listing_id, interest_level, high, medium, low)
print(logloss(test_result))
varnames
q()
